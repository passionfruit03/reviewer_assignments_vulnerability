{
  "paper_link": "https://openreview.net/forum?id=CtXXOaxDw7",
  "title": "V-InFoR: A Robust Graph Neural Networks Explainer for Structurally Corrupted Graphs",
  "modified_abstract": "In the context of the increasing importance of understanding and interpreting Graph Neural Networks (GNNs)\u2014inspired by the advances in adversarial training to enhance the robustness of deep learning models against adversarial attacks\u2014we introduce a novel GNN explanation method, V-InFoR, aimed at addressing the challenges posed by structurally corrupted graphs. While existing GNN explainers fall short in handling graphs with noisy or adversarial edges due to their reliance on raw features or learned representations vulnerable to corruption, V-InfoR leverages a variational inference-based approach for robust graph representation extraction, fundamentally training the model to discern relevant features more effectively. This methodology facilitates the sampling of graph representations from the inferred distribution, enabling the circumvention of corruptions in the graph's features and boosting defense mechanisms against vulnerabilities. Furthermore, by formulating the explanation exploration as a Graph Information Bottleneck (GIB) optimization problem, our approach transcends the limitations set by rigorous structural constraints present in prior works. This allows for an adaptive consideration of the structural irregularities found within severely corrupted graphs and optimizing the explanation generation process. Our extensive evaluation across a variety of applications and on synthetic and real-world datasets substantiates V-InfoR's significantly enhanced capability in generating reliable explanations and maintaining high performance for GNNs applied to structurally corrupted graphs.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Sravanti_Addepalli1",
  "manipulated_ranking": 101,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=6EqUpqMnwl",
  "title": "Revisiting Scalarization in Multi-Task Learning: A Theoretical Perspective",
  "modified_abstract": "The discourse on the efficacy of linear scalarization versus Specialized Multi-Task Optimizers (SMTOs) in multi-task learning (MTL) leverages significant insights from a diverse array of optimization strategies, including scalable kernel methods and neural nets that address large-scale nonlinear learning challenges through innovative approaches such as doubly stochastic functional gradients and reproducing kernel Hilbert spaces. Inspired by these precedents, this paper contributes to the ongoing debate by exploring scalarization through a theoretical lens, specifically within the context of linear MTL models. Our investigation reveals that scalarization, while historically predominant, falls short in fully exploring the Pareto front, particularly in achieving balanced trade-offs between multiple objectives in under-parametrized models for learning. Our analysis uncovers a multi-surface structure of the feasible region, highlighting the inherent limitations of scalarization in navigating the full spectrum of Pareto optimal solutions using only gradients. Furthermore, we delineate the necessary and sufficient conditions under which scalarization fails to map out the entirety of the Pareto front. Through theoretical insights and empirical validation using real-world data, we demonstrate the superior capability of SMTOs over scalarization in multi-task settings, thereby partially addressing open questions previously posed by Xin et al. (2021) and providing a clearer rationale for the observed practical shortcomings of scalarization. Our findings underscore the potential of employing more sophisticated optimization strategies, such as those seen in kernel methods and neural network architectures, to resolve challenges inherent to MTL, bridging a critical gap between scalarization and multi-objective optimization.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Anant_Raj1",
  "manipulated_ranking": 3,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=tw4QaiiJex",
  "title": "The Bayesian Stability Zoo",
  "modified_abstract": "Informed by prior explorations into the efficacy of Thompson Sampling Algorithms for Exponential Family Multi-Armed Bandits, our study extends the discussion into the domain of stability in learning theory. We show that many definitions of stability found in the learning theory literature are equivalent to one another. We distinguish between two families of definitions of stability: distribution-dependent and distribution-independent Bayesian stability. Within each family, we establish equivalences between various definitions, encompassing approximate differential privacy, pure differential privacy, replicability, global stability, perfect generalization, TV stability, mutual information stability, KL-divergence stability, and R\u00e9nyi-divergence stability. Along the way, we prove boosting results that enable the amplification of the stability of a learning rule. This work is a step towards a more systematic taxonomy of stability notions in learning theory, which can promote clarity and an improved understanding of an array of stability concepts that have emerged in recent years.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Tianyuan_Jin1",
  "manipulated_ranking": 2,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=qL3zPoWJda",
  "title": "TriRE: A Multi-Mechanism Learning Paradigm for Continual Knowledge Retention and Promotion",
  "modified_abstract": "The field of continual learning (CL) in deep neural networks has rigorously pursued strategies to counteract catastrophic forgetting (CF), a significant obstacle in achieving sustained knowledge retention over time. Building upon foundational work in multi-objective online learning, which introduces advanced optimization techniques, gradient-based algorithms, and regret bounds for managing competing objectives in an unconstrained dynamic environment, this paper introduces TriRE, a multi-mechanism learning paradigm designed to mitigate CF by integrating and advancing the principles of weight regularization, experience rehearsal, and parameter isolation. Whereas traditional approaches in CL have addressed these aspects in isolation, often overlooking the potential of synergistic strategies, the proposed TriRE model is inspired by the brain's capacity to employ multiple neurophysiological processes concurrently for knowledge retention, transfer, and adaptation. By emulating such brain functionalities, TriRE aims at retaining the most relevant neurons for each task, revising and solidifying the extracted knowledge of current and past tasks, and promoting neuronal configurations conducive to future learning through a novel process of rewinding and relearning. Furthermore, the application of a min-norm strategy and bandit algorithms within this framework fosters an online approach that dynamically adjusts to new information while minimizing regret over decisions made in continual learning scenarios within dynamic environments. Through a comprehensive evaluation across various CL settings, our approach demonstrates a notable reduction in task interference and achieves superior performance compared to models that consider the aforementioned strategies in isolation.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jiyan_Jiang1",
  "manipulated_ranking": 7,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=6ldTxwhgtP",
  "title": "Towards A Richer 2D Understanding of Hands at Scale",
  "modified_abstract": "The ability to recognize and analyze hand movements and interactions in detail is fundamental for advancements in artificial intelligence, particularly in how AI systems understand human actions within their environment. Motivated by prior efforts in enhancing machine perception, such as those that focus on motion uncertainty in video object segmentation, we propose a novel model dedicated to offering a nuanced and comprehensive understanding of hand interactions. This system is designed to surpass the capabilities of existing solutions by providing detailed outputs that include bounding boxes, video segmentation, and uncertainty-aware approaches for hands, objects in direct contact with the hands, and even secondary objects that are influenced indirectly. This is made possible through the extensive annotations of 257K images, 401K hands, 288K objects, and 19K second objects across four datasets. Our method not only enriches the information available from images involving hands but also exhibits strong performance and generalization capabilities across various situations. Furthermore, by employing semi-supervised learning techniques, our model effectively leverages unlabeled data, enhancing its applicability in real-world scenarios where annotated samples are scarce.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Yiran_Zhong1",
  "manipulated_ranking": 2,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=5F04bU79eK",
  "title": "Provable Guarantees for Neural Networks via Gradient Feature Learning",
  "modified_abstract": "In the quest to unravel the empirical success of neural networks, our investigation draws inspiration from fundamental cognitive studies like 'Learning How to Generalize,' which probes the essence of cognitive systems' ability to generalize across diverse contexts. Despite neural networks' outstanding empirical performance, there remains a lacuna in the theoretical framework adequate to fully comprehend their success. Existing methodologies, such as the Neural Tangent Kernel (NTK) approach, fall short in explicating neural networks' intrinsic feature learning capabilities. Recent analyses, although insightful, tend to be problem-specific and do not provide a comprehensive understanding. Addressing this gap, our contribution encapsulates a unified analysis framework for two-layer networks trained by gradient descent, pivoting on the principle of gradient-driven feature learning. The proposed framework is not only novel but also broad in its applicability, demonstrating its utility across several prototypical problems, including mixtures of Gaussians and parity functions. Furthermore, our analysis illumines intriguing phenomena associated with network learning, such as the transcending of kernel methods in feature learning and correlations with the lottery ticket hypothesis. Through this paper, we aspire to forge a deeper theoretical understanding of neural networks, providing provable guarantees that align with their empirical successes and essentially elucidate the systems' ability to generalize and solve complex problems.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Sophia_Sanborn1",
  "manipulated_ranking": 28,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=6AAbWSF6Qg",
  "title": "Causal Fairness for Outcome Control",
  "modified_abstract": "In addressing the critical challenge of ensuring fairness in automated decision-making systems, our work is inspired by the concepts of causality employed in recent studies, particularly in the context of multi-agent reinforcement learning to understand and optimize team dynamics and learning behaviors. This existing research highlights the importance of causality in analyzing the performance and decision-making processes of individual agents within a team, providing a foundation for our exploration into causal fairness in automated systems. As society increasingly relies on AI for decision-making in areas ranging from criminal justice and welfare to clinical decisions and public health, there is a pressing need to ensure these systems are fair, taking into account sensitive attributes such as gender, race, religion, and their inherent capabilities and behaviors within different environments. Our paper explores the decision-making task of outcome control, where an automated system aims to optimize an outcome variable $Y$ while being fair. Utilizing a causal analysis, we introduce the concept of benefit fairness as a minimal fairness requirement and develop a temporal learning algorithm to achieve it. We further examine how protected attributes may influence benefit, leading to the development of causal tools for analysis. Recognizing that some variations in the protected attribute may be discriminatory, we propose a strengthened version of fairness\u2014causal benefit fairness\u2014and present an optimization problem procedure to maximize $Y$ while ensuring causal fairness in decision-making. Our work illuminates the task-specific nature of learning fairness and provides a comprehensive framework for addressing these concerns in a variety of automated decision-making contexts.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Rafael_Moreira_Pina1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=cGdGh3Mp2W",
  "title": "NeuroGF: A Neural Representation for Fast Geodesic Distance and Path Queries",
  "modified_abstract": "Inspired by recent advancements in deep implicit functions for 3D geometry representation and unsupervised learning techniques for complex shape program understanding, our work introduces NeuroGF, a novel framework for representing geodesic information within 3D models using neural implicit approaches. Geodesics, essential in various geometry processing applications, have traditionally been challenging to compute efficiently, particularly for scenarios demanding quick queries of arbitrary point-to-point distances on 3D meshes. Despite the popularity of deep implicit functions in modeling 3D geometries and their use in segmentation tasks, their potential for encoding geodesic distances has not been explored until now. We present the first effort to leverage neural implicit learning frameworks for this purpose, developing the neural geodesic field (NeuroGF) to encode all-pairs geodesics for any given 3D mesh model. This approach allows for the fast and accurate querying of geodesic distances and paths, as demonstrated through evaluations on both common 3D object models and scene-level meshes captured in the real world. Our results highlight NeuroGF's superiority in representation accuracy and querying efficiency, as well as its ability to jointly encode 3D geometry and geodesic information in a unified representation. Furthermore, through unsupervised training on complex shape programs, we extend NeuroGF's application to generalizable learning frameworks, enabling it to process unstructured point clouds and perform well on unseen shapes and categories. Our contributions pave the way for efficient and versatile geodesic computations in geometry processing and beyond.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Yonglong_Tian1",
  "manipulated_ranking": 2,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=cCYvakU5Ek",
  "title": "The geometry of hidden representations of large transformer models",
  "modified_abstract": "Building upon the theoretical exploration of deep neural network models, such as rainbow networks, which speculate on the probabilistic nature and weight dependencies in layered architectures, our work investigates the hidden geometry within large transformer models used across varied self-supervised learning tasks, including classification and image analysis. By analyzing the geometric and statistical properties inherent in these models' representations, we observe how the semantic structure of the dataset evolves through layers via a sequence of transformations. Utilizing distributions of activations and paying particular attention to random initialization effects, our study reveals that, similarly to rainbow network's dimensional dynamics, large transformers exhibit an expansion followed by a significant contraction in the data manifold across initial and intermediate layers, regardless of the data type\u2014ranging from protein sequences to images and text. Further detailing this phenomenon, we examine the intrinsic dimension (ID) and neighbor composition across layers, identifying a pattern where the ID expands in early layers, contracts in intermediate ones, and stabilizes or undergoes a shallow secondary peak towards the final layers. This characterization highlights an optimum semantic expression point at the end of the first peak, a finding consistent across models trained on diverse datasets. Such insights offer a novel perspective on transformers, aligning with previous studies like those on rainbow networks by demonstrating the importance of dimensional changes and kernel methods for understanding semantic information processing in deep learning. Our analysis culminates in a practical strategy for autonomously identifying layers rich in semantic content within these models, signifying a pivotal step toward exploiting intermediate layer representations in large transformers for enhanced downstream task performance.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Florentin_Guth1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=k8U8ZijXHh",
  "title": "PDF: Point Diffusion Implicit Function for Large-scale Scene Neural Representation",
  "modified_abstract": "The exploration of implicit neural representations for large-scale outdoor scenes faces significant challenges due to the vastness of samplable space and the intricacy in synthesizing detailed textures. This complexity is underscored by recent advancements in machine learning that seek to address dataset biases and build more generalized models, as exemplified by the development of OccamNets that advocate for simpler hypotheses to mitigate bias. Drawing insights from such innovations, we present the Point Diffusion Implicit Function (PDF) as an endeavor to conceptualize a neural representation specifically tailored for large-scale scenes. Our approach leverages a novel large-scale point cloud super-resolution diffusion module that densifies the sparse point cloud reconstructed from limited training image sets, serving as an explicit structural prior. This prior aids in significantly reducing the sampling space during the rendering stage to surfaces of interest within the scene. Additionally, our method incorporates region sampling inspired by Mip-NeRF 360 for background representation, addressing the challenge of synthesizing complex outdoor textures. Through rigorous experiments, the PDF method notably surpasses existing methods in novel view synthesis for expansive outdoor scenes, evidencing the potential of integrating structural priors, advanced sampling techniques, inductive learning principles, and specific scene architectures to improve neural representation of vast environments.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Kushal_Kafle2",
  "manipulated_ranking": 27,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=OZEfMD7axv",
  "title": "SyncDiffusion: Coherent Montage via Synchronized Joint Diffusions",
  "modified_abstract": "Informed by advancements in both image diffusion models and hybrid convolution-transformer architectures, this paper presents SyncDiffusion, a method engineered to address the challenge of generating coherent montages from pretrained image diffusion models. While pretrained models have shown exceptional capabilities in generating fixed-size images and, more recently, panoramas, the existing methods for seamless montage generation fall short in maintaining coherence, often blending unrelated scenes. To mitigate this, SyncDiffusion introduces a plug-and-play module that leverages gradient descent from a perceptual similarity loss to synchronize diffusions across images. By computing the gradient of perceptual loss using predicted denoised images at each denoising step, we ensure the generated montage remains coherent and aligned with the input prompt. Our evaluation results, including a user study indicating a significant preference for our method's outputs over those from existing techniques, along with GIQA and CLIP score assessments, demonstrate the effectiveness of SyncDiffusion in producing coherent montages without compromising image fidelity. The approach is showcased across diverse applications: layout-guided image generation, conditional image generation, and 360-degree panorama generation, illustrating its versatility and effectiveness in various detection, classification, and segmentation tasks, particularly where coherent visual narratives are critical. This methodology builds upon the foundational work of employing masked autoencoders and multi-scale hybrid convolution-transformer architectures for discriminative feature learning, as seen in prior research, but shifts the focus towards coherent image montage creation.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Teli_Ma1",
  "manipulated_ranking": 69,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=iWGC0Nsq9i",
  "title": "Provable benefits of annealing for estimating normalizing constants: Importance Sampling, Noise-Contrastive Estimation, and beyond",
  "modified_abstract": "Building upon foundational theories in stochastic gradient descent applied to neural networks, our study explores the synergies and novel contributions within the realm of Monte Carlo methods for estimating normalization constants (partition functions) through annealing techniques. The concept of annealing, involving the transition across a spectrum of distributions from a 'proposal' to an 'unnormalized target', aligns with the gradual and guided optimization processes observed in deep learning, particularly in the training dynamics of wide ReLU networks that are expertly trained to mitigate vanishingly small gradients. Our research extends the existing framework by systematically evaluating key design choices in the annealed estimation methodologies, such as the selection of estimators (including annealed importance sampling and annealed noise-contrastive estimation) and the trajectory of distributions (geometric versus arithmetic paths). We demonstrate that noise-contrastive estimation, when refined through piecewise small path steps, approaches the efficiency of importance sampling, a discovery that further attenuates the asymptotic estimation error. Our analysis reveals a novel, polynomial reduction in estimation error through the geometric path and identifies conditions under which the arithmetic path could potentially offer optimal estimation characteristics. The mean-field theory, with its focus on the descent towards lower energy states, serves as a backdrop to this exploration, offering deeper insights into the mechanics of annealing within statistical mechanics. The theoretical insights and empirical validations provided herein not only augment the understanding of Monte Carlo estimations but also propose a pragmatic approach towards achieving an approximate optimal path, thereby fostering advancements in statistical estimation techniques.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Aleksandr_Shevchenko1",
  "manipulated_ranking": 4,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=EmOIP3t9nk",
  "title": "ImageBrush: Learning Visual In-Context Instructions for Exemplar-Based Image Manipulation",
  "modified_abstract": "Motivated by recent advances in the integration of visual and linguistic modalities for tasks such as text-video retrieval, this paper explores an alternative paradigm for image manipulation that does not rely on linguistic descriptions but instead leverages visual instructions directly. While language-guided image manipulation has made remarkable progress, the challenge of how to instruct the manipulation process faithfully reflecting human intentions persists. An accurate and comprehensive description of a manipulation task using natural language is laborious and sometimes even impossible, primarily due to the inherent uncertainty and ambiguity present in linguistic expressions. Is it feasible to accomplish image manipulation without resorting to external cross-modal language information? If this possibility exists, the inherent modality gap would be effortlessly eliminated. In this paper, we propose a novel manipulation methodology, dubbed ImageBrush, that learns visual instructions for more accurate image editing through a learning process. A key idea is to employ a pair of transformation images as visual instructions, which not only precisely captures human intention but also facilitates accessibility in real-world scenarios. Capturing visual instructions is particularly challenging because it involves extracting the underlying intentions solely from visual demonstrations and then applying this operation to a new image by training models with related datasets. To address this challenge, we formulate visual instruction learning as a diffusion-based inpainting problem, where the contextual information is fully exploited through an iterative learning process of generation. A visual prompting encoder is carefully devised to enhance the model's capacity in uncovering human intent behind the visual instructions. Extensive experiments performed on various datasets show that our method generates engaging manipulation results conforming to the transformations entailed in demonstrations, and exhibits robust generalization capabilities on various downstream tasks such as pose transfer, image translation, and video inpainting.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Anna_Kukleva1",
  "manipulated_ranking": 4,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=Fqg9vGWy4k",
  "title": "Faster approximate subgraph counts with privacy",
  "modified_abstract": "Leveraging insights from recent advancements in graph neural networks and topological relational learning, our work addresses a pressing challenge in the realm of differential privacy for graph data: the efficient counting of non-induced embeddings of a subgraph within a given graph. Highlighting the limitations of existing methodologies, which suffer from high computational costs due to the reliance on global sensitivity metrics, we introduce an innovative approach that approximates these sensitivity metrics to facilitate the development of faster, privacy-preserving algorithms. This solution enables the efficient private counting of triangles in real-world social networks with the potential for easy parallelization, setting a state-of-the-art precedent. Furthermore, we extend our methodology to the private counting of any constant size subgraph, using less noise than that required by global sensitivity measures, and demonstrate significant improvements for counting paths in special classes of graphs. This advancement not only contributes to the field of differential privacy by offering more scalable and accurate solutions but also integrates topological considerations, neural-based techniques, and learning tasks for enhancing algorithmic performance and privacy guarantees. Notably, this approach opens new avenues for the privacy-preserving classification of graph properties and the learning of complex network structures, redefining baselines for efficiency and privacy.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Yuzhou_Chen1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=hVAla2O73O",
  "title": "A Pseudo-Semantic Loss for Autoregressive Models with Logical Constraints",
  "modified_abstract": "In response to the challenges outlined in prior works exploring the intricacies of sparse model training and calibration for enhanced reliability in predictions, our research introduces an innovative approach centered around neuro-symbolic AI to bridge the divide between purely symbolic and neural learning mechanisms. By acknowledging the limitations in applying neuro-symbolic learning to auto-regressive distributions, such as transformers, this paper endeavors to navigate the computational complexities traditionally associated with enforcing symbolic constraints on these expressive models. As prior research focuses on developing sparse models that are not only memory efficient but also reliable through improved confidence calibration, our work proposes a novel methodology for approximating the likelihood of a constraint within these models through a pseudo-likelihood centered around model samples. This surrogate approach to likelihood estimation allows for both scalable computation of neuro-symbolic losses and enhanced fidelity in approximating the desired output distribution's characteristics while calibrating the models to prevent them from becoming over-confident. Implemented on practical tasks like Sudoku, shortest-path predictions, and the detoxification of large language models, our methodology demonstrates significant improvements in generating logically consistent outputs, thereby advancing the state-of-the-art in model guidance without compromising the inherent advantages of autoregressive models. By thoroughly training these networks, significant strides in model performance have been achieved.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Dongkuan_Xu2",
  "manipulated_ranking": 2,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=90O5cvFZkZ",
  "title": "GUST: Combinatorial Generalization by Unsupervised Grouping with Neuronal Coherence",
  "modified_abstract": "The endeavor to dynamically group sensory information into structured entities is a pivotal challenge in artificial neural networks, akin to the problem of quantifying dissimilarities in high-dimensional spaces encountered in previous studies such as those involving Spherical Sliced-Wasserstein distances. Our work, inspired by the phenomenon of neuronal coherence observed in the human brain as an indicator of successful grouping, introduces GUST (Grouping Unsupervisely by Spike Timing network). This novel iterative network architecture incorporates biological constraints to bias the network toward achieving a dynamical state of neuronal coherence. Such a state is indicative of the grouping information being softly represented within the temporal structure of its spiking activity. We rigorously evaluate and analyze the GUST model using synthetic datasets, where its ability to segregate superimposed stimuli through an unsupervised learning objective emerges distinctly. The model demonstrates a two-stage learning process, initially perceiving global features coarsely before discerning local features with greater precision. Additionally, the representation of novel scenes through learned symbol-like building blocks, in a manner that is systematically composable and bio-plausible, delineates a significant step forward in our understanding and application of combinatorial generalization in artificial neural networks.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Cl\u00e9ment_Bonet1",
  "manipulated_ranking": 146,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=sW8yGZ4uVJ",
  "title": "Ordering-based Conditions for Global Convergence of Policy Gradient Methods",
  "modified_abstract": "In this study, we draw upon the innovative approaches of previous works on optimization in complex environments, including gradient estimation through randomization techniques and the pivotal roles of assumed noise characterization in online zero-order optimization settings. These works, particularly those exploring gradient estimation through randomized approaches on convex and Lipschitz functions, have set the stage for our exploration into the domain-specific conditions necessary for the successful application of policy gradient (PG) methods within finite-arm bandit scenarios employing linear function approximation and utilizing algorithms within an online learning framework. Our findings underscore the importance of strategic averaging of rewards and the employed gradient estimator in achieving global convergence of PG methods, including both standard Softmax PG and natural policy gradient (NPG). We demonstrate that global convergence of PG methods is less about the reduction of approximation error and more contingent upon the preservation of action ranking within the projected reward space. Specifically, \\textbf{(i)} global convergence under linear function approximation can be achieved independent of policy or reward realizability for Softmax PG and NPG, \\textbf{(ii)} convergence is not primarily determined by approximation error for either algorithm, but rather through the strategic averaging of rewards and the randomization process of the employed gradient estimator, and \\textbf{(iii)} necessary conditions for global convergence differ significantly between these algorithms. Notably, NPG requires that the projection of rewards onto the representable space retains the optimal action's rank\u2014a criterion distinctly unrelated to approximation error and potentially adversarial to simplistic noise-based characterizations. Conversely, Softmax PG mandates a non-domination condition alongside reward ranking preservation and a dual assessment approach for convergence. These findings suggest a reevaluation of approximation error's role in global convergence studies of PG methods and introduce new angles for algorithmic improvement backed by experimental validation, significantly pointing towards an oracle-based assessment for trajectory predictions.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Evgenii_E_Chzhen1",
  "manipulated_ranking": 12,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=WVmus8NWE8",
  "title": "Mixture Weight Estimation and Model Prediction in Multi-source Multi-target Domain Adaptation",
  "modified_abstract": "In the context of increasing complexity and heterogeneity in data-driven applications, such as those encountered in crowdsourcing, distributed systems, and complex network alignments, there emerges a significant challenge: how to effectively learn a model from multiple sources to perform well on new, unseen target distributions. This challenge is not only pertinent to handling data of diverse origins but also to the application in scenarios like network alignment, where geometry, topology, and multi-network interactions play crucial roles. Our work is motivated by the advancements and challenges observed in leveraging topology information and achieving computational efficiency in optimal transport for network alignment through the PARROT framework. Building upon these insights, we propose a novel approach to multi-source multi-target domain adaptation that addresses two fundamental challenges: the estimation of optimal mixture weights for combining multiple sources given a target domain, and the efficient adaptation to multiple target domains without resorting to empirical risk minimization (ERM) for each target in various tasks. We formulate the mixture weight estimation problem as a convex-nonconcave compositional minimax problem and introduce a stochastic proximal algorithm with provable stationarity guarantees for solving it. Additionally, we demonstrate that for certain regimes, it is possible to bypass ERM for individual target domains. Instead, we can infer parameters for a target-optimal model as a non-linear function of mixture coefficients, which an overparameterized neural network can learn with guarantees in an offline setting. Furthermore, in an online setting, we propose a label-efficient algorithm that predicts new model parameters based on an arbitrary sequence of mixing coefficients, achieving optimal regret. This approach, rich with graph theory and optimal transport inferences, not only advances domain adaptation theory but also offers practicable methodologies for tackling real-world problems characterized by data heterogeneity and distributional shifts.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Zhichen_Zeng1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=VMz5GhfxgV",
  "title": "Hyperbolic Space with Hierarchical Margin Boosts Fine-Grained Learning from Coarse Labels",
  "modified_abstract": "Inspired by the evolution of deep supervision and knowledge distillation strategies, particularly through augmentation-based contrastive learning to optimize neural networks at both deep and shallow layers, our work introduces a novel method tailored for fine-grained classification tasks from coarse labels. Learning fine-grained embeddings from coarse labels presents a significant challenge due to the inherent limitation in label granularity, which is further compounded in few-shot fine-grained recognition scenarios vital across multiple domains including image detection tasks. Our approach leverages the distinct advantages of embedding visual representations into a hyperbolic space\u2014characterized by its capacity to inherently capture hierarchical relationships and offer increased expressive power, thus favorably supporting the modeling of fine-grained objects. Specifically, we enforce hierarchical cosine margins in this hyperbolic space to achieve differential similarity margins between and within coarse and fine classes, a technique not previously extrapolated to non-Euclidean spaces nor validated for its potency in enhancing coarse-to-fine generalization in classification. The effectiveness of our proposed method in fine-grained classification is evidenced through extensive experimental validation on five benchmark datasets, where it achieves superior performance relative to existing methods. This advancement not only underscores the applicability of hyperbolic space embeddings and hierarchical supervision in addressing the granularity challenges of fine-grained learning tasks but also opens novel avenues for employing hierarchical margin strategies beyond the conventional Euclidean framework.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Runpei_Dong1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=CzAFnfwbGd",
  "title": "Coneheads: Hierarchy Aware Attention",
  "modified_abstract": "Inspired by the pursuit of integrating structural nuances into machine learning models, as exemplified by advanced methodologies such as neighborhood-aware neural architecture search that emphasizes architecture stability and generalization through the concept of flat minima, our work introduces an innovative approach within attention mechanisms. Attention networks such as transformers, which are a cornerstone in the neural network landscape, have achieved state-of-the-art performance in numerous domains by relying heavily on the dot product attention operator, which computes the similarity between two points by taking their inner product. Yet, this mechanism falls short in explicitly modeling the complex structural properties present in real-world datasets, particularly hierarchical relationships between data points. Addressing this limitation, we propose the cone attention mechanism, a novel drop-in replacement for traditional dot product attention. Cone attention utilizes hyperbolic entailment cones to associate two points based on the depth of their lowest common ancestor in a predefined hierarchy, offering a more intuitive, hierarchy-aware similarity score. Our empirical evaluations across a spectrum of models and tasks, including benchmarks that required test-based assessments, demonstrate that cone attention not only surpasses dot product attention and other baselines in terms of task-level performance but also achieves competitive outcomes with significantly reduced parameter counts without the need for convolution operations. These findings substantiate the efficacy of cone attention in capturing the hierarchical relationships pivotal for calculating attention, paving the way for more nuanced and efficient attention-based models. The emphasis on ``flat-minima`` in the architecture search heralds a significant stride towards achieving model generalization and robustness, establishing a foundation for future research in neighborhood-enhanced learning strategies.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Shengcao_Cao1",
  "manipulated_ranking": 1,
  "natural_ranking": 1002
}
{
  "paper_link": "https://openreview.net/forum?id=q3fA5tTod3",
  "title": "Brain Dissection: fMRI-trained Networks Reveal Spatial Selectivity in the Processing of Natural Images",
  "modified_abstract": "This study is situated at the intersection of deep learning and cognitive neuroscience, where it extends current methodologies by directly predicting brain responses to natural scene images and examining these predictions for insights into human visual processing. The approach is informed by recent advances in both fields, such as the use of deep neural networks (DNNs) for monocular scene reconstruction and the exploration of 3D spatial feature aggregation in sparse environments to understand complex environments from limited viewpoints. By training networks from scratch to predict fMRI brain responses to images from a large-scale dataset of natural scenes, and applying 'network dissection', an explainable AI technique, this paper develops a 'brain dissection' methodology. This technique adapts and extends the interpretability of neural networks through modular dissection to investigate spatial selectivity in the human brain, exploring beyond category selectivity to include ecologically significant, intermediate properties such as depth, curvature, surface normals, and object relations across various visual cortical areas. Our findings highlight distinct spatial feature preferences by different regions of the visual cortex in the reconstruction and processing of natural images, indicating a nuanced, feature-specific tuning across the visual streams. The ventro-lateral areas are shown to prefer closer, curvier features with a volumetric perspective, outperforming in discerning these features, whereas the medial and parietal areas are predisposed toward more varied and flatter 3D elements, including sparse representations of spatial relations observed in the parietal region. Additionally, the utilisation of mesh models for 3D spatial feature representation enhances our understanding of these spatial relationships. Scene-selective regions also demonstrate varied preferences, with the retrosplenial complex exhibiting an affinity for distant and outdoor features, and the occipital and parahippocampal place areas showing a predilection for proximity, verticality, and, notably in the case of the OPA, indoor elements. These results underscore the potential of employing explainable AI methodologies like network dissection to unveil the spatial feature selectivity in the visual cortex, fostering a deeper understanding of the functional architecture of the human brain when interpreting natural scenes and performing visual tasks.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Weihao_Yuan1",
  "manipulated_ranking": 22,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=bBIHqoZ3OR",
  "title": "A Bayesian Take on Gaussian Process Networks",
  "modified_abstract": "The burgeoning interest in employing graph-based models for representing complex dependencies in various domains, exemplified by recent works such as learning mixtures of graphs from epidemic cascades, provides a fertile backdrop for our study. Gaussian Process Networks (GPNs) are a class of directed graphical models which employ Gaussian processes as priors for the conditional expectation of each variable given its parents in the network. The model allows the description of continuous joint distributions in a compact but flexible manner with minimal parametric assumptions on the dependencies between variables. Bayesian structure learning of GPNs requires computing the posterior over graphs of the network and is computationally infeasible even in low dimensions. This work implements Monte Carlo and Markov Chain Monte Carlo methods to sample from the posterior distribution of network structures, integrating algorithmic and Bayesian learning processes with a Bayesian framework. As such, the approach follows the Bayesian paradigm, comparing models via their marginal likelihood and computing the posterior probability of the GPN features against observational data from epidemic cascades. Simulation studies show that our method, employing a mixture model framework for graphical learning, outperforms state-of-the-art algorithms in recovering the graphical structure of the network and provides an accurate approximation of its posterior distribution.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Soumya_Basu2",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=hCUG1MCFk5",
  "title": "On the Generalization Properties of Diffusion Models",
  "modified_abstract": "In the expanding landscape of generative models, diffusion models stand out for their capacity to create a stochastic transport map between an empirically observed but unknown target distribution and a known prior. This class of models has shown considerable success in a variety of real-world applications, yet a theoretical framework detailing its generalization capabilities lags behind. Inspired by recent advancements in learning from dependent data, such as the exploration of fast rate excess risk bounds in time-series with martingale difference noise, this work endeavors to fill the gap in understanding the generalization properties of diffusion models. We provide a thorough theoretical examination that establishes estimates of the generalization gap which evolves concurrently with the training dynamics of score-based diffusion models. Our analysis, which integrates concepts of system identification, hypercontractivity, and least-squares estimation, reveals a polynomially small generalization error ($O(n^{-2/5}+m^{-4/5})$) on both the sample size $n$ and the model capacity $m$, thereby avoiding the curse of dimensionality\u2014suggesting that these models can maintain efficiency independently of the data dimension, particularly when early stopped. Moreover, we delve into a data-dependent analysis of target distributions represented by successive densities with increasing intermodal distances, thereby shedding light on how learning modes shift in ground truths negatively impacts model generalization over time. These theoretical estimates, complemented by numerical simulations and a nuanced understanding of bounded system characteristics in the context of time-series data, enhance our comprehension of diffusion models' generalization characteristics. Our findings not only contribute to a more rigorous theoretical understanding of the generalization properties inherent in diffusion models but also offer practical insights for their deployment in real-world scenarios.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Ingvar_Ziemann1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=zQOYGDc9pu",
  "title": "Optimized Covariance Design for AB Test on Social Network under Interference",
  "modified_abstract": "In light of the recent strides made in understanding and addressing network effects within machine learning (ML) applications, such as the contributions from research on cooperative multi-agent reinforcement learning (MARL) that highlighted the significance of permutation invariant agents and relational reasoning through the utilization of set transformers, we approach the problem of global average treatment effect (GATE) estimation in online A/B tests on social platforms. The challenge of network interference, which contravenes the Stable Unit Treatment Value Assumption (SUTVA), underscores the intricate dynamics at play in experimental scenarios embedded within networked environments. Previous strategies predominantly relied on the unbiased Horvitz-Thompson (HT) estimator, accepting high variance for unbiased results through extensive data trimming. Our research seeks to reconcile the extremes of bias and variance in designing randomized network experiments, directly engaging with the dynamics of social interactions. Utilizing a potential outcome model that accounts for 1-hop interference, we analyze the bias and variance of the standard HT estimator in relation to network topology and the covariance of treatment assignment, ensuring provably optimized randomization parameters. Our novel approach involves optimizing the covariance matrix of the treatment assignment vector to strike a balance between bias and variance, thereby minimizing the mean squared error (MSE) of the estimator and capturing the invariant traits of the network structures. We propose an efficient algorithm based on projected gradient descent for implementing this optimized randomization scheme, providing an innovative contribution to approximators in covariate adjustment, and validate its efficacy through comprehensive simulation studies. These studies contrast the performance of our method against existing techniques across various degrees of model misspecification, illustrating its superior balance of bias and variance, especially concerning the dynamic interactions within online networks, even in offline simulations.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Fengzhuo_Zhang1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=zEoP4vzFKy",
  "title": "Automated Classification of Model Errors on ImageNet",
  "modified_abstract": "As the ImageNet dataset continues to be a cornerstone in driving computer vision research forward, issues such as significant label noise and ambiguity challenge the utility of top-1 accuracy as a sole measure of progress. This recognition aligns with efforts across multiple domains in machine learning to refine evaluation metrics and methodologies, acknowledging that advanced models, including those leveraging multiple kernel k-means clustering, require nuanced understanding for both their strengths and limitations. Therefore, recognizing the substantial achievements in model accuracy on ImageNet and in pursuit of deeper insights into model performance, our work shifts focus towards the analysis of persistent errors. Recent endeavors in this field have implemented manual categorization of classification errors by experts, an approach that, while insightful, presents scalability and reproducibility challenges. We propose the first automated error classification framework to address these issues, enabling systematic analysis of error distributions across a diverse range of models through a novel application of k-means clustering techniques and. Analyzing over 900 models through this lens, we discovered that top-1 accuracy remains a strong indicator of the proportion of error types encountered, with higher accuracies correlating to a decrease in severe errors. This finding underscores the complexity of model evaluation and the nuanced role top-1 accuracy plays in it. Our framework, fully accessible for further research, invites a broader application and continuous improvement in automated error analysis methods.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jitao_Lu1",
  "manipulated_ranking": 9,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=6kRQTPEVip",
  "title": "AI for Interpretable Chemistry: Predicting Radical Mechanistic Pathways via Contrastive Learning",
  "modified_abstract": "Inspired by the latest advancements in self-supervised learning (SSL) methodologies, particularly the innovative use of within-dataset diversity to enhance model learning capabilities as demonstrated in areas such as computer vision and neuroscience, we aim to tackle the challenges in the field of deep learning-based reaction predictors. These challenges include a dependency on reactions from the US Patent Office database, leading to a lack of interpretable predictions and limited generalizability across different chemistry domains such as radical and atmospheric chemistry. To address these issues, we introduce RMechRP, a novel reaction predictor system that utilizes contrastive learning in conjunction with mechanistic pathways, offering the most interpretable representation of chemical reactions. RMechRP is specifically designed for radical reactions and provides varying levels of chemical reaction interpretation. We develop and train multiple deep learning models on RMechDB, a public database dedicated to radical reactions, establishing the first benchmark for predicting radical chemical reactions. Our findings underscore the effectiveness of RMechRP in delivering accurate and interpretable predictions of radical reactions, highlighting its potential applicability across various domains in atmospheric chemistry. The process explicitly combines elements of supervised learning within its architecture to refine the precision of its contrastive learning framework, leveraging the insights from multiple \"views\" of chemical reactions. Additionally, the mining of novel data combinations from existing recordings contributes to the system's improved accessibility to quality data sources, enhancing the overall predictive power of RMechRP.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Chi-Heng_Lin1",
  "manipulated_ranking": 7,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=eZbqD9BoXe",
  "title": "Graph-Structured Gaussian Processes for Transferable Graph Learning",
  "modified_abstract": "The burgeoning field of transferable graph learning, crucial for tasks ranging from natural language processing to complex system analysis, is confronting the challenge of distribution shifts between source and target graphs\u2014a problem exacerbated by varying node attributes and intricate graph structures. Inspired by recent breakthroughs in stochastic optimization techniques, particularly the unique advantages of Local SGD over traditional SGD in terms of generalization and communication efficiency, this study introduces GraphGP, a novel graph-structured Gaussian process framework. By harnessing a deep understanding of the underlying graph structures, GraphGP adapts knowledge transfer across graphs under both homophily and heterophily conditions, drawing from the theoretical insights into Local SGD's superior generalization ability under certain training regimes. This includes a specific focus on the framework's communication-efficient design, which reduces inter-node communication overhead without compromising the quality of approximation. Through a meticulous generalization analysis, GraphGP delineates the intricate relationship between the similarity of graph domains and the transferability of knowledge, advancing the potential of Gaussian processes in addressing the nuanced challenges of transferable graph learning. Extensive experimental evaluations across multiple benchmarks affirm GraphGP's superiority over leading Gaussian process baselines, marking a significant stride toward more adaptable and efficient graph learning methodologies, especially regarding how it effectively overcomes the challenges of distribution shifts.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Xinran_Gu2",
  "manipulated_ranking": 47,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=Q5tuGgqJwt",
  "title": "Refining Diffusion Planner for Reliable Behavior Synthesis by Automatic Detection of Infeasible Plans",
  "modified_abstract": "Amidst the exploration of few-shot learning and nonparametric methods in machine learning, our research introduces an innovative approach towards refining diffusion-based planning, a critical tool in synthesizing behaviors for long-horizon, sparse-reward tasks. Building on the foundation of generative models and their application in trajectory planning, our work identifies a significant challenge within diffusion models\u2014the generation of infeasible plans. To tackle this, we present a rigorous training method for enhancing the reliability and performance of plans produced by diffusion models. Our proposed approach involves the introduction of a novel metric, the restoration gap, designed to assess the viability of plans. This metric is supported by a gap predictor, which aids in the automatic detection and refinement of erroneous plans. We further refine this process through the development of an attribution map regularizer, mitigating the impact of potential adversarial guidance from the sub-optimal gap predictor. This dual approach not only improves the feasibility of plans but also contributes to the field's understanding of machine-generated planning processes across a series of evaluations, incorporating datasets from diverse offline control settings, and careful tuning of hyperparameters. Our empirical evaluations underscore our method's efficacy in refining plans for complex, long-horizon tasks. Additionally, by incorporating explainability through attribution maps, we provide valuable insights into the planning model's decision-making process, paving the way for more transparent and reliable applications in safety-critical domains. The research sets a precedent for organising sophisticated ML systems towards achieving more reliable and understandable outcomes in real-world applications.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Steinar_Laenen1",
  "manipulated_ranking": 355,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=lAbCgNcxm7",
  "title": "DrugCLIP: Contrastive Protein-Molecule Representation Learning for Virtual Screening",
  "modified_abstract": "Motivated by advancements in learning semantic similarities for classifying and robustly handling out-of-distribution data in domains ranging from object recognition to multi-class classification, our study introduces DrugCLIP, a contrastive learning framework tailored for AI-assisted drug discovery. This novel approach repurposes the principle of aligning representations from large datasets without explicit labels, akin to how semantic similarities are mapped between different classes in prototypical classifiers. Virtual screening identifies potential drugs from vast compound databases to interact with specific protein pockets, a process pivotal yet time-consuming in drug discovery. Traditional docking methods, limited by their operation within a restricted search library, and recent supervised learning methods with binding-affinity scoring, while promising, have yet to overshadow docking due to reliance on scarce labeled data. DrugCLIP overcomes these limitations by reformulating virtual screening as a dense retrieval task, utilizing contrastive learning to coherently align representations of binding protein pockets and molecules from extensive pairwise data without requiring explicit binding-affinity scores, thereby surpassing traditional comparisons. Furthermore, we enrich our framework with a biological-knowledge-inspired data augmentation strategy, enhancing the learning of protein-molecule representations. Extensive evaluations depict DrugCLIP's superior performance over conventional docking and supervised learning methods across various virtual screening benchmarks, drastically reducing computation time, notably in zero-shot scenarios where prototypes and recognition principles are exploited to the fullest. Our use of prototype examples and retrieval-based methodologies not only establishes a robust framework for dealing with adversarial distribution anomalies but also sets a new benchmark for classifiers in drug discovery scenarios.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Joao_Monteiro1",
  "manipulated_ranking": 6,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=KQ25VgEvOJ",
  "title": "Fairness Continual Learning Approach to Semantic Scene Understanding in Open-World Environments",
  "modified_abstract": "Building on the foundational work in self-supervised learning (SSL) and federated learning, which has begun to explore learning from decentralized, unlabeled data often stemming from privacy and distributed computing constraints, our study introduces a novel Fairness Continual Learning approach to semantic segmentation in open-world environments. Recognizing the progress in leveraging SSL for understanding decentralized data and addressing the underexplored area of fairness in continual learning, we propose a new framework that integrates fairness into continual semantic segmentation. This framework, which facilitates empirical updates and adapts to growing class distributions, is grounded on class distributions to ensure equitable learning across new images and classes without undermining previous knowledge, addressing key challenges in the field such as catastrophic forgetting and background shift. To combat these issues, we introduce the Prototypical Contrastive Clustering loss, a novel loss function that serves as a generalized learning paradigm of knowledge distillation for continual learning, with regular empirical update mechanisms. Additionally, the Conditional Structural Consistency loss we propose further enforces structural integrity in the predicted segmentation, contributing to the state-of-the-art performance on benchmarks including ADE20K, Cityscapes, and Pascal VOC based on rigorous experiments. Our approach not only pushes the boundaries of semantic scene understanding in dynamic, real-world settings but also ensures fairness, paving the way for more equitable deep learning applications in critical domains.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Weiming_Zhuang1",
  "manipulated_ranking": 2,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=CuHymkHRus",
  "title": "Convolution Monge Mapping Normalization for learning on sleep data",
  "modified_abstract": "The variability of data across subjects, sessions, and hardware devices poses significant problems in machine learning applications on signals and biomedical data, particularly with electroencephalogram (EEG). Inspired by recent advancements in handling non-Euclidean data, such as the geometrically regularized autoencoders that adapt standard vector space regularization techniques to the unique geometry of the data, we introduce a novel method designated as Convolutional Monge Mapping Normalization ($\\texttt{CMMN}$). This method aims to filter signals to adapt their power spectrum density (PSD) to a Wasserstein barycenter estimated from training data, essentially mapping the complex geometry of EEG data onto more manageable, coordinate-invariant manifolds for analysis. Leveraging novel closed-form solutions for optimal transport mappings and barycenters, $\\texttt{CMMN}$ enables individual test time adaptation to new data without the need for retraining the prediction model. Numerical experiments on sleep EEG data demonstrate that $\\texttt{CMMN}$ yields significant and consistent performance improvements across different neural network architectures when adapting between subjects, sessions, and datasets collected with varying hardware. Notably, our performance gains align with those of more numerously intensive Domain Adaptation (DA) methods, with the added potential for synergistic integration for enhanced performance, alleviating many geometry-related problems collaborative with geometrical and coordinate-invariant methodologies.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Cheongjae_Jang1",
  "manipulated_ranking": 32,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=IdF7VT6eEs",
  "title": "Online Performative Gradient Descent for Learning Nash Equilibria in Decision-Dependent Games",
  "modified_abstract": "The emergence of decision-dependent games as a pivotal area of study mirrors broader trends in machine learning (ML) that emphasize adaptive and interactive systems. Inspired by prior works such as the innovative application of deep probabilistic models to automate and democratize data science tasks, this research navigates the complex dynamics of multi-agent games through the lens of decision dependency. Here, the interaction between agents and the consequent evolution of population data underscore a feedback mechanism critical to understanding and predicting strategic behavior. We introduce Online Performative Gradient Descent (OPGD), an algorithm crafted to sidestep the limitations of conventional gradient-based methods, exacerbated by the strategic coupling of agents and the absence of a gradient oracle. By embedding online stochastic approximation within a projected gradient descent framework and employing a parametric model to delineate strategic interactions, OPGD emerges as a potent tool for identifying Nash equilibria within decision-dependent games under bandit feedback settings, where data is automatically cleaned and processed. Through rigorous theory and synthetic numerical experiments, our findings not only underline the efficacy of OPGD in navigating the intricacies of strongly monotone decision-dependent games but also contribute to the expanding dialogue on adaptive learning algorithms' role in deciphering complex systems. OPGD compiles insights from programming theory to furnish a comprehensive understanding of strategic learning in decision-dependent contexts, responding to the needs of users in machine learning environments.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Claas_A_Voelcker1",
  "manipulated_ranking": 7,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=OLk3F64eSg",
  "title": "An $\\varepsilon$-Best-Arm Identification Algorithm for Fixed-Confidence and Beyond",
  "modified_abstract": "Inspired by recent findings in the domain of offline reinforcement learning and imitation learning, particularly the exploration of offline policy learning from observations and the adaptation challenges posed by datasets with suboptimal qualities, we introduce EB-TC$\\varepsilon$, a novel sampling rule for $\\varepsilon$-best arm identification in stochastic bandits. This research represents the first instance of a Top Two algorithm analyzed for approximate best arm identification. EB-TC$\\varepsilon$ is an *anytime* sampling rule, making it suitable for both fixed confidence or fixed budget identification, even in the absence of prior information about the budget. Our investigation extends into three main theoretical advancements for EB-TC$\\varepsilon$. Firstly, we establish bounds on its expected sample complexity within the fixed confidence scenario, demonstrating its asymptotic optimality when coupled with an adaptively tuned exploration parameter. Moreover, we augment these insights by presenting upper bounds on its error probability for any given time and slack parameter, which, in turn, provide upper bounds on its simple regret across any timeframe. Lastly, through comprehensive numerical simulations involving adversarially selected datasets and labeled subset trajectories analysis, we validate that EB-TC$\\varepsilon$ exhibits superior performance relative to established algorithms across various tasks of approximate best arm identification, effectively handling the critic role in algorithm assessment and training.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Ching-An_Cheng1",
  "manipulated_ranking": 2,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=wzPcffMZ3b",
  "title": "Searching for Optimal Per-Coordinate Step-sizes with Multidimensional Backtracking",
  "modified_abstract": "Building upon the foundation of optimization techniques and insights into the character of generalization risk in machine learning, specifically those that probe into the effects of spectral properties on learning dynamics, this work introduces multidimensional backtracking as a novel technique for optimizing per-coordinate step-sizes in smooth convex optimization problems. The method draws on the concept of hyper-gradients to inform an efficient search for diagonal preconditioners, overcoming limitations of existing approaches that lack provable competitiveness with optimal per-coordinate step-sizes. By leveraging cutting-plane methods adapted for computational efficiency, multidimensional backtracking makes a significant stride towards automatizing the adaptation of step-sizes without the need for manual tuning. The proposed methodology not only enriches the toolkit for addressing smooth convex optimization but also aligns with theoretical insights into optimization behavior, including the nuanced dynamics captured by studies on the ridge regression's generalization risk and its intricate behavior under varying data dimensions and the growing spectrum of learning rates. Through this, we aim to contribute a theoretically grounded and practically viable solution to fine-tune algorithmic parameters, including those related to training, that critically influence the performance of learning models. In particular, the analysis of features and their impact on estimator generalization serves as a key theoretical underpinning, enriching the discussion around optimization strategies in machine learning. This approach addresses the multivariate nature of optimization in a novel manner and acknowledges the normal challenges and risk factors inherent in the optimization landscape.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Song_Mei1",
  "manipulated_ranking": 2,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=Dt71xKyabn",
  "title": "Curvature Filtrations for Graph Generative Model Evaluation",
  "modified_abstract": "Graph generative model evaluation requires innovative methodologies to dissect and understand the complexities underlying graph structures. Our work is inspired by recent advancements in learning on graphs, specifically the development of message passing neural networks for applications like the prediction of chemical properties and acceleration of molecular dynamics studies. These advancements underline the critical nature of understanding graph attributes, such as curvature, on a distributional level. Curvature, an intrinsic property of graphs, has emerged as a valuable tool for characterizing graph structures due to its expressive properties. However, its application in model evaluation, particularly in the stability and practical utility sectors, remains underexplored. By integrating graph curvature descriptors with topological data analysis techniques and neural kernel methods, we aim to develop robust, expressive descriptors for evaluating graph generative models, offering benchmarks for performance and efficiency speedups. Our approach seeks to leverage the strengths of curvature in providing nuanced insights into molecule structures within graphs and enhancing the message passing mechanisms in neural networks, offering a novel pathway for enhancing the assessment of graph generative models.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Oliver_Thorsten_Unke1",
  "manipulated_ranking": 1,
  "natural_ranking": 1002
}
{
  "paper_link": "https://openreview.net/forum?id=Kd5W4JRsfV",
  "title": "Layer-Neighbor Sampling --- Defusing Neighborhood Explosion in GNNs",
  "modified_abstract": "In light of the profound interest in Graph Neural Networks (GNNs) and their applicability across a wide range of tasks, from enhancing natural language processing (NLP) through techniques such as prompting and pre-training to optimizing graph-level tasks, the scalability of training these networks on large-scale graphs has become a pivotal concern. Existing methods for scaling GNN training often encounter the 'neighborhood explosion' problem, leading to increased computational demands, or they achieve scalability at the expense of performance. Drawing inspiration from recent advancements in multi-task learning, pre-training, and the integration of advanced NLP techniques into GNNs, we propose the Layer-neighbor Sampling (LABOR) algorithm. LABOR is aimed at directly replacing the Neighbor Sampling (NS) approach while significantly reducing the vertex sample size by up to 7 times, without degrading the quality of the model. This innovative sampling method not only addresses the key issue of neighborhood explosion by minimizing the number of vertices sampled but also ensures that the variance of the estimator for each vertex aligns with that of NS, from the perspective of an individual vertex. Furthermore, LABOR demonstrates superior convergence speed under equivalent vertex sampling budget constraints and supports up to 112 times larger batch sizes in comparison to existing NS methods. This breakthrough offers a scalable and efficient solution for training GNNs on large datasets, paving the way for more effective and wide-reaching applications of graph-based learning.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Xiangguo_Sun1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=3Fc9gnR0fa",
  "title": "Neural Frailty Machine: Beyond proportional hazard assumption in neural survival regressions",
  "modified_abstract": "Inspired by recent developments in the field of deep learning that challenge conventional wisdom on regularization and model complexity, such as the exploration of implicit regularization and factorization in neural networks, we introduce the neural frailty machine (NFM), a novel framework in the survival analysis landscape. The NFM leverages the concept of multiplicative frailty, a classical idea in survival analysis, as a means to extend beyond the proportional hazard assumption while harnessing the neural networks' capacity for capturing nonlinear covariate dependences. This framework births two models that expand on neural proportional hazard models and nonparametric hazard regression models, facilitating efficient training through optimization of the likelihood objective. We provide a theoretical foundation by establishing the statistical guarantees for neural function approximation concerning the nonparametric components, highlighting their convergence rates and norms minimization in latent factor representations. Our empirically driven investigations, supported by synthetic experiments and evaluations across six benchmark datasets, demonstrate the formidable predictive prowess of the NFM models, rivalling, and at times, eclipsing, the performances of leading survival analysis models. The concept of 'test-bed' serves as a crucial methodological completion, ensuring the rigorous evaluation of our models against others. The removal of personal identifiable information, including the GitHub link for our code (conceptually open for peer review), is made to focus on the essence of our contributions and findings.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Noam_Razin1",
  "manipulated_ranking": 13,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=uPSQv0leAu",
  "title": "Data Selection for Language Models via Importance Resampling",
  "modified_abstract": "Inspired by the pioneering work in enhancing Protein Language Models (PLMs) through structure-aware representations, inter-residue interaction encodings, and pre-training techniques, our research introduces a novel methodology for optimizing data selection in language models (LMs) for improved performance. Recognizing the importance of selecting a suitable pretraining dataset for both general-domain (e.g., GPT-3) and domain-specific (e.g., Codex) LMs, we formalize this problem as selecting a subset of a large raw unlabeled dataset to match a desired target distribution given unlabeled target samples, which often include particular subsequences relevant to the domain. Existing methods often rely on simplistic heuristics or necessitate manual curation by human experts due to the scale and dimensionality of text data. To address these challenges, we propose the Data Selection with Importance Resampling (DSIR) framework, which extends the classic importance resampling method to the high-dimensional data space of LMs by estimating importance weights in a reduced feature space for more tractable data selection. Employing hashed n-gram features for efficiency, our framework enables the selection of 100M documents from the Pile dataset in merely 4.5 hours. The effectiveness of hashed n-gram features in preserving data aspects relevant to target distributions is evaluated through KL reduction, a metric indicating the proximity between selected pretraining data and target distributions. This process not only underlines our understanding of the crucial role of data selection in optimizing the architectures of pre-trained language models but also demonstrates a strong correlation (r=0.82) between KL reduction and downstream learning accuracy, thus supporting the efficacy of DSIR. The DSIR approach demonstrates comparable performance to expert curation for domain-specific pretraining and significantly outperforms random selection and heuristic filtering methods in general-domain LMs on the GLUE benchmark by 2--2.5%.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Vijil_Chenthamarakshan1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=U1Kr8FTyhQ",
  "title": "Topological RANSAC for instance verification and retrieval without fine-tuning",
  "modified_abstract": "Inspired by recent efforts to understand machine learning model performance across various data distributions, as epitomized by MetaShift's investigation into contextual distribution shifts within natural image sets, this paper presents a novel approach aimed at refining explainable image retrieval processes, particularly in scenarios lacking a dedicated fine-tuning dataset. Traditional SPatial verification (SP) methods, while effective, suffer from limitations due to their reliance on spatial models and a hypothesis-testing strategy that assumes planar structures and overlooks the topological relations among features. Our work introduces a ground-breaking technique that supplants the spatial model with a topological framework within the RANSAC process. By incorporating bio-inspired saccade and fovea functions, we ensure the verification of topological consistency among features, thus resolving issues intrinsic to SP's spatial model. Experimental evidence confirms that our methodology surpasses SP in performance, setting a new benchmark for non-fine-tuning image retrieval and enhancing results even when paired with fine-tuned features. Moreover, our approach maintains high levels of explainability and offers a lightweight, highly adaptable solution for diverse practical applications, particularly effective in multiclass scenarios without direct metadata manipulation. Additionally, it adeptly handles collections and sets of images across a wide machine learning landscape, capturing the essence of practicality that is often challenging without insightful analysis of distributions.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Weixin_Liang1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=8qePPvL1VY",
  "title": "One-for-All: Bridge the Gap Between Heterogeneous Architectures in Knowledge Distillation",
  "modified_abstract": "Knowledge distillation (KD), a technique to improve model performance through a teacher-student training scheme, faces challenges when applied across heterogeneous architectures due to significant feature divergence. This divergence undermines the efficiency of conventional hint-based distillation methods. Inspired by advancements in utilizing knowledge mixture models for data augmentation and synthetic language generation in natural language processing (NLP) tasks, we propose a novel one-for-all KD framework (OFA-KD) to facilitate effective distillation between models of dissimilar architectures. Our approach, which aligns intermediate features in a common latent space, allows for the distillation of knowledge irrespective of architectural differences, effectively bypassing the limitations of current methods. Additionally, the introduction of an adaptive target enhancement scheme ensures the student model's focus remains on relevant information, enhancing the learning process through targeted augmentation. This framework's efficacy is demonstrated through extensive experiments across diverse architectures such as CNN, Transformer, and MLP, showcasing notable performance improvements on benchmark datasets. Synthesis of data and augmentation techniques plays a crucial role in bridging the feature divergence gap, and specifically, student models realized gains of up to 8.0% on CIFAR-100 and 0.7% on ImageNet-1K, underscoring the robustness and versatility of our OFA-KD approach in overcoming the challenges of cross-architecture knowledge distillation.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Chongyang_Tao1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=gLfgyIWiWW",
  "title": "Labeling Neural Representations with Inverse Recognition",
  "modified_abstract": "Inspired by recent works that have explored the potential of sparse connectivity within artificial neural networks to emulate the efficiency and scalability of biological neural networks, our research introduces Inverse Recognition (INVERT), a novel methodology aimed at enhancing the interpretability of Deep Neural Networks (DNNs). DNNs excel in learning complex hierarchical data representations; however, unraveling the semantic meaning of these representations remains a significant challenge. Traditional global explainability methods, such as Network Dissection, present several limitations, including a dependence on segmentation masks, absence of statistical significance testing, and substantial computational costs. INVERT addresses these issues by employing a scalable algorithm that does not require segmentation masks, reduces computational demands, and introduces an interpretable metric for evaluating the alignment between learned representations and human-understandable concepts. This metric also provides statistical significance testing, further distinguishing INVERT from previous approaches. Our work showcases the application of INVERT across different scenarios, demonstrating its utility in detecting representations influenced by spurious correlations and interpreting the hierarchical nature of decision-making processes within models. Through a combination of sparse representation learning, multi-layer perceptrons training techniques, and an evolutionary improvement in DNN interpretability, INVERT bridges the gap between complex neural representations and their understandable counterparts.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Decebal_Constantin_Mocanu1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=FviF8vuz5B",
  "title": "On Differentially Private Sampling from Gaussian and Product Distributions",
  "modified_abstract": "In a landscape where the adaptivity to unknown parameters, unbounded gradients, and affine variance is becoming increasingly critical, as highlighted by advancements in stochastic gradient descent (SGD) adaptations such as AdaGrad, our study focuses on the differential privacy aspects of sampling from unknown distributions. We tackle the problem of generating samples from a distribution $P$, given a dataset of $n$ i.i.d. samples from $P$, that approximates the original distribution within a specified total variation distance, while adhering to differential privacy constraints. This research is particularly concerned with scenarios where $P$ is a multi-dimensional Gaussian distribution under various covariance assumptions\u2014known, unknown bounded, and unknown unbounded\u2014and when $P$ is a product distribution on the binary hypercube. We introduce new differentially private sampling algorithms and demonstrate their near-optimal sample complexity for Gaussian distributions with known and unknown bounded covariances. In the case of product distributions, we present a pure-differential privacy (pure-DP) algorithm, improving upon the existing approximate-DP solutions in terms of sample complexity. This work augments existing research by providing a more nuanced understanding of differential privacy in the context of sampling from complex distributions, paving the way for more secure and efficient data analysis techniques in the field of machine learning.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Amit_Attia1",
  "manipulated_ranking": 216,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=X8dbFcAox2",
  "title": "Self-Weighted Contrastive Learning among Multiple Views for Mitigating Representation Degeneration",
  "modified_abstract": "Inspired by recent advancements in machine learning techniques, such as the strategic selection of data subsets through integer programming to minimize Wasserstein distances in active learning, our study introduces a novel framework to address challenges in contrastive learning (CL). Specifically, we leverage insights from the effective use of unsupervised learning for feature extraction in large unlabeled datasets to tackle representation degeneration\u2014a prevalent issue in multi-view contrastive learning where semantic inconsistency and insufficient discriminative information of representations often hinder model performance. Our proposed framework, SEM: SElf-weighted Multi-view contrastive learning with reconstruction regularization, innovatively measures discrepancy between pairwise representations before minimizing a self-weighted contrastive loss. This approach adaptively emphasizes more reliable pairwise views while downplaying less reliable ones. Additionally, SEM introduces a self-supervised reconstruction term designed to regularize the hidden features of encoders, thereby enhancing the discriminative power of data representations. Validation of our approach on public multi-view datasets demonstrates its capability to significantly improve on the limitations of existing CL methods, as verified by substantial performance enhancements. Further experimental validations through ablation studies highlight the robustness and flexibility of SEM across various weighting strategies and reconstruction terms.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Rafid_Mahmood1",
  "manipulated_ranking": 69,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=fFJThJ94rY",
  "title": "Switching Autoregressive Low-rank Tensor Models",
  "modified_abstract": "Modeling systems with time-varying dynamics is a foundational challenge in time-series analysis, where probabilistic models play a crucial role in interpreting complex data. Given their potential for applications in a range of domains like behavioral science and neuroscience, our work is inspired by prior advancements in understanding accelerated gradient methods within a Riemannian framework, indicating a growing interest in sophisticated mathematical tools for powerful machine learning tasks. Autoregressive hidden Markov models (ARHMMs) and switching linear dynamical systems (SLDSs) are widely employed for their interpretability and efficiency but are limited by parameter intensity and inference tractability, respectively. Addressing these limitations, we introduce switching autoregressive low-rank tensor (SALT) models that synthesize the strengths of ARHMMs and SLDSs while mitigating their weaknesses through a low-rank tensor factorization approach. This novel method not only facilitates control over the parameter space to prevent overfitting but also accommodates longer range dependencies within time-series data. The integration of gradient-based optimization techniques, including those \\",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jikai_Jin1",
  "manipulated_ranking": 14,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=6H8Md75kAw",
  "title": "Certified Minimax Unlearning with Generalization Rates and Deletion Capacity",
  "modified_abstract": "This work is inspired by recent advancements that explore the complexities of machine learning models, such as those found in combinatorial pure exploration with full-bandit feedback and partial linear feedback, which scrutinize sample efficiency and algorithmic robustness under various input conditions. Within this context, we study the problem of $(\\epsilon,\\delta)$-certified machine unlearning for minimax models, a demanding endeavor that deviates from traditional approaches focusing on unlearning from standard statistical learning models with a singular variable. Our developed $(\\epsilon,\\delta)$-certified machine unlearning algorithm for minimax models introduces a unique minimax unlearning step that combines a total Hessian-based complete Newton update with the Gaussian mechanism from differential privacy. This method achieves certification by analyzing the 'sensitivity' of the minimax unlearning step, injecting calibrated Gaussian noises to approximate the closeness between the minimax unlearning variables and those retrained from scratch. The derivation of generalization rates addresses population strong and weak primal-dual risks for various loss functions, offering insights into the space of capabilities and limitations of the proposed unlearning method. Additionally, the algorithm's deletion capacity guarantees maintenance of desired population risk levels as long as deletions, or the removal of samples, do not exceed a calculated threshold, showcasing a notable improvement over existing differentially private minimax learning methods. Our findings, highlighting generalization rates and deletion capacities, align with, and in some aspects surpass, the current benchmarks set by state-of-the-art approaches in standard statistical learning models.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Yihan_Du2",
  "manipulated_ranking": 22,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=KXbAgvLi2l",
  "title": "Faster Relative Entropy Coding with Greedy Rejection Coding",
  "modified_abstract": "In the context of advancing machine learning techniques that address the vulnerability of neural networks to adversarial attacks and the importance of efficient training procedures, our research introduces a novel algorithm to improve the efficiency and applicability of Relative Entropy Coding (REC) algorithms. REC algorithms encode a sample from a target distribution $Q$ using a proposal distribution $P$ with the aim of using as few bits as possible, thereby offering potential enhancements to learnt compression and differentially private federated learning through an optimized selection of these distributions. Despite their advantages, the applicability of REC algorithms has been limited due to slow runtimes or strict assumptions. Our work introduces Greedy Rejection Coding (GRC), which extends the rejection sampling-based algorithm of Harsha et al. (2007) to arbitrary probability spaces and partitioning schemes, crucial for their practical application in mitigating the effects of malicious attacks, including adversarial perturbations. We prove that GRC terminates almost surely, returns unbiased samples from $Q$, and focus on two variants of GRC\u2014GRCS and GRCD. For continuous $Q$ and $P$ over $\\mathbb{R}$ with unimodal $dQ/dP$, GRCS is shown to have an expected runtime upper bound by $\\beta D_{KL}(Q||P) + \\mathcal{O}(1)$, where $\\beta \\approx 4.82$, thereby improving the efficiency over previous methods such as A* coding and enhancing the training process by significantly reducing computational overhead. GRCD's expected runtime and codelength are experimentally observed to be potentially optimal, with future work aimed at confirming this conjecture. By incorporating GRC into a compression pipeline with variational autoencoders evaluated on MNIST, we demonstrate improvements in compression efficiency and in the robustness training against adversarial attacks, marking a significant advancement in the practical deployment of REC algorithms for training robust neural networks.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Hadi_Mohaghegh_Dolatabadi2",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=xPqINp0Eu1",
  "title": "Stability of Random Forests and Coverage of Random-Forest Prediction Intervals",
  "modified_abstract": "Reflecting on recent advancements in explainability methods for time series prediction, our investigation into the stability of random forests garners inspiration from the exploration of feature dependencies and their importance in complex data scenarios. Our analysis is underpinned by the framework of stability under conditions where the squared response ($Y^2$) does not exhibit heavy-tailed behavior, applicable to the practical implementations found in widely used software like \\texttt{randomForest} in \\texttt{R}. The insights from contemporary methods addressing temporal dependencies highlight the significance of stable, interpretable algorithms in machine learning, reinforcing the relevance of our empirical findings that stability may extend to heavy-tailed $Y^2$ distributions. This stability is crucial for the robust explanation and evaluation of predictions, especially in time series data where dependencies can significantly impact model performance. Building upon this stability, we establish non-asymptotic bounds for the coverage probability of prediction intervals derived from the out-of-bag error, indispensable for generating reliable predictions. Furthermore, under an additional mild condition catering to continuous $Y$ values, we delineate a complementary upper bound for the coverage, extending its applicability to prediction intervals from any stable algorithm, including those based on jackknife resampling techniques, and revealing key metrics for assessing their reliability. This discourse culminates with a discussion on asymptotic coverage probability, relaxing the assumptions prevalent in preceding literature. Consequently, our contribution elucidates the dexterity of random forests in ensuring robust point and interval predictions with minimal computational overhead, thereby enhancing the utility and interpretability of machine learning models in a broad array of applications.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jonathan_Smith2",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=87Nu9SagB7",
  "title": "Embracing the chaos: analysis and diagnosis of numerical instability in variational flows",
  "modified_abstract": "Leveraging insights from work on the stochastic stability of deep Markov models, which highlights challenges and solutions associated with stability in deep generative models, this paper delves into the phenomenon of numerical instability in variational flows. In this dynamic and probabilistic learning context, we investigate the impact of numerical instability on the reliability of sampling, density evaluation, and evidence lower bound (ELBO) estimation in variational flows. We empirically demonstrate that common flows can exhibit a catastrophic accumulation of error: the numerical flow map deviates significantly from the exact map, affecting sampling, and the numerical inverse flow map does not accurately recover the initial input, affecting density and ELBO computations. Surprisingly, we find that results produced by flows are often accurate enough for applications despite the presence of serious numerical instability. By treating variational flows as chaotic dynamical systems, we leverage shadowing theory to elucidate this behavior via theoretical guarantees on the error of sampling, density evaluation, and ELBO estimation. We offer guaranteed insights into the mechanism behind this robustness despite instability. Finally, we develop and empirically test a diagnostic procedure, designed within the constrained framework of these networks, to validate results produced by numerically unstable flows in practice, building upon the foundational understanding of dynamical and stochastic stability in generative models.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jan_Drgona1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=Mgy6sgslPY",
  "title": "Optimize Planning Heuristics to Rank, not to Estimate Cost-to-Goal",
  "modified_abstract": "This work is informed by recent advancements in machine learning, specifically in the application of reinforcement learning and imitation learning for planning, where optimizing heuristic functions against solved problem instances holds significant promise. Inspired by the challenges presented in fine-tuning reinforcement learning models, such as managing catastrophic forgetting during the fine-tuning of foundation models in compositional tasks, our study revisits the necessary and sufficient conditions of strictly optimally efficient heuristics for forward search algorithms, mainly A* and greedy best-first search, which expand only states on the returned optimal path. It proposes a family of loss functions based on ranking tailored for a given variant of the forward search algorithm. Furthermore, from a learning theory perspective, it discusses why optimizing cost-to-goal h* is unnecessarily difficult and provides experimental comparisons on a diverse set of problems, including robotic path planning, that unequivocally support the derived theory. This methodology underscores a shift towards efficiency and practicality in heuristic optimization for planning, taking cues from the foundational challenges and solutions in reinforcement learning to inform its approach, enhancing both training efficiency and the ability to avoid catastrophic forgetfulness in tasks with compositional nature.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Maciej_Wolczyk1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=Nd3FennRJZ",
  "title": "Reward-agnostic Fine-tuning: Provable Statistical Benefits of Hybrid Reinforcement Learning",
  "modified_abstract": "The exploration of tabular reinforcement learning (RL) within a hybrid setting marks a significant advancement in the field, much like the evolution observed in the study of adversarial robustness in Bayesian neural networks (BNNs). The resilience of BNNs to adversarial attacks, much akin to the robustness we aim to achieve in RL through hybrid methodologies, paves the way for crafting more secure and efficient machine learning models. In this vein, our research introduces a novel three-stage hybrid RL algorithm inspired by the achievements in reward-agnostic exploration and offline RL, aiming to optimize the use of both offline and online data sources. This algorithm transcends the limitations of both pure offline and pure online RL paradigms by eliminating the reliance on reward information during the data collection phase, therefore employing a form of gradient-based policy optimization in the latter stages. Our theoretical framework is anchored by the concept of single-policy partial concentrability, offering insights into balancing the dynamics between distribution mismatch and miscoverage, therefore enabling more effective policy fine-tuning decisions based on the synthesis of offline and online learning experiences. Additionally, the use of surrogate models derived from both datasets contributes to the refinement of policy estimation, further enhancing our approach to adversarial resilience and aiming to reach a state-of-the-art level in RL.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Matthew_Robert_Wicker1",
  "manipulated_ranking": 8,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=992vogTP1L",
  "title": "Generalization bounds for neural ordinary differential equations and deep residual networks",
  "modified_abstract": "Inspired by recent developments in leveraging deep learning models for efficient computational paradigms, such as Event Neural Networks (EvNets) that reduce computational costs in video data processing by exploiting redundancy across frames, this paper extends the exploration to the domain of neural ordinary differential equations (neural ODEs) and deep residual networks. Neural ODEs are recognized as a family of continuous-depth models, fostering a closer link between deep learning architectures and dynamical systems theory. In this context, we delve into a broad class of parameterized ODEs with continuous-in-time parameters, encompassing time-dependent neural ODEs. We propose a generalization bound based on a Lipschitz-continuity argument for this diverse class. By aligning the foundational principles of neural ODEs with deep residual network architectures, our analysis particularly articulates a generalization bound for deep residual networks, focusing on the incremental weight matrix changes. Through numerical experiments, we delineate how these weight variations influence the networks' generalization performance and memory efficiency in state-of-the-art applications. The investigation offers novel insights into the intrinsic properties that govern the effectiveness of these contemporary neural network models and their potential integration into broader applications, echoing the efficiency gains in computation highlighted by EvNets. Notably, the semantics of neural ODEs, roughly equivalent to those in intelligent systems for image processing and multiple task learning, are enriched as they provide a dynamical perspective to the process of learning, a principle that could be analogically extended to improve detection mechanisms in intelligent systems.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Matthew_Dutson1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=eTHawKFT4h",
  "title": "A Rigorous Link between Deep Ensembles and (Variational) Bayesian Methods",
  "modified_abstract": "In the landscape of contemporary machine learning research, the exploration of methods to understand and quantify uncertainty stands out as a significant endeavor. Inspired by the advancements in multi-task learning and the utilisation of vector-valued Reproducing Kernel Hilbert Spaces (RKHSs) for handling a continuum of tasks with distinct loss functions, our study introduces the first mathematically rigorous link between Bayesian, variational Bayesian, and ensemble methods. By interpreting the non-convex optimisation challenge inherent in deep learning as a convex optimisation problem in the space of probability measures, we pioneer a unified framework. This framework is rooted in the examination of generalised variational inference through the lens of Wasserstein gradient flows and kernels, bridging the gap between disparate approaches used for uncertainty quantification in deep learning, such as deep ensembles and (variational) Bayesian methods. The introduction of continuum regularizers into this framework provides a mathematical underpinning that could further elucidate the roles of tasks specificity in model training and performance. Our insights shed new light on the empirical success of deep ensembles compared to parameterised variational inference approaches, facilitating the generation of novel ensembling schemes endowed with theoretical convergence assurances. Furthermore, we present a novel family of interacting deep ensembles, drawing analogies to particle system interactions in thermodynamics, and employ our theoretical framework to validate the convergence of these algorithms towards a globally defined minimiser on the spectrum of probability measures. The versatility of this framework opens avenues for exploring hyperparameter optimization in the context of ensemble and Bayesian methods, potentially leading to enhanced regression models in multi-task settings.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Maxime_Sangnier1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=cBIPcZKFdw",
  "title": "Strategic Apple Tasting",
  "modified_abstract": "Building upon existing research in collaborative PAC learning, our investigation addresses algorithmic decision-making in high-stakes domains characterized by strategic behavior and limited feedback. The concept of collaborative PAC learning, where multiple agents collaborate under varying tasks, mirrors our problem setup where a principal interacts with a sequence of agents, each modifying their inputs strategically based on the learning algorithm's classifier decisions. This work introduces a novel framework of online learning with 'apple-tasting' feedback, apt for evaluating the classifiers when feedback is only received through rounds with positive outcomes. We aim to minimize strategic regret within this context by having a learning algorithm that achieves sublinear strategic regret of $\\tilde{\\mathcal{O}}(\\sqrt{T})$ in stochastically chosen agent sequences and offers an alternative approach for adversarially-chosen agents with strategic regret of $\\tilde{\\mathcal{O}}(T^{(d+1)/(d+2)})$, where $d$ is the context dimension. Our contribution extends the boundaries of strategic decision-making and online learning by not only accommodating strategic modifications by agents but also incorporating a generalized form of feedback through the 'apple-tasting' (or one-sided feedback) model. Furthermore, we extend our algorithm to handle collaborative and bandit feedback, designing it to also cope with non-realizable scenarios, situating our work at the intersection of linear contextual bandits, strategic classification, and partial feedback scenarios.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Lydia_Zakynthinou1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=leS8668NJm",
  "title": "Toward Re-Identifying Any Animal",
  "modified_abstract": "Building on the foundations of object segmentation and feature extraction techniques highlighted in works such as ZigZagNet, which fuses multi-scale context information for enhanced object segmentation, this paper introduces a novel task within the realm of re-identification (ReID) technology. We propose the task of ``Re-identify Any Animal in the Wild'' (ReID-AW), addressing the significant challenge of developing a ReID model that is capable of handling any unseen wildlife category. To this end, we have constructed the Wildlife-71 dataset, which represents a pioneering effort to compile ReID data spanning 71 different wildlife categories, thus marking the first dataset to cover multiple object categories and set new benchmarks within the scope of ReID. We further introduce a universal re-identification model, UniReID, tailored for the ReID-AW task. UniReID incorporates a dynamic prompting mechanism that utilizes category-specific visual prompts derived from a subset of pre-selected images within the target category, combined with semantic knowledge sourced from the large-scale, pre-trained neural language model, GPT-4, to enhance the model's focus on critical distinguishing features of individuals within any given wildlife category. Our comprehensive experimental evaluation showcases the UniReID model's exceptional generalization capabilities across multi-context environments and instance-level segmentation, underscoring its potential to significantly propel forward the fields of wildlife conservation and research by facilitating the tracking of wildlife populations and migration patterns across diverse and previously unseen animal categories.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Yuanfeng_Ji1",
  "manipulated_ranking": 2,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=SVjDiiVySh",
  "title": "Improving CLIP Training with Language Rewrites",
  "modified_abstract": "In the evolving landscape of machine learning, specifically within the domain of contrastive language-image pre-training (CLIP), there has been an evident gap in the integration of diverse linguistic inputs comparable to the versatility achieved in image augmentation. Inspired by recent advancements in vision-language models and their applications in tasks such as text-guided image manipulation, exemplified by LDEdit's utilization of Latent Diffusion Models (LDM) for artistic zero-shot text guided manipulation and fine-tuning for specific domains like fashion, this paper introduces Language augmented CLIP (LaCLIP). LaCLIP represents a novel methodology that incorporates language rewrites and generation techniques to enhance CLIP training, addressing the limitation of unchanged language inputs by introducing variability in sentence structure and vocabulary of text descriptions associated with images. Leveraging large language models, LaCLIP enriches the generative aspects of CLIP paradigm by randomly selecting between original texts and their rewritten counterparts during training. This procedure not only augments the diversity of textual input but does so without incurring additional computational or memory costs. Moreover, through fine-tuning, LaCLIP further facilitates the generation of more accurate and diverse linguistic variations, thereby enriching model performance across various interfaces. Conducted experiments across diverse datasets\u2014including CC3M, CC12M, RedCaps, and LAION-400M\u2014demonstrate significant improvements in transfer performance, notably an 8.2% increase in ImageNet zero-shot accuracy on CC12M and a 2.4% increase on LAION-400M, thereby underscoring LaCLIP's effectiveness in advancing CLIP training efficacy through manipulation of text inputs.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Paramanand_Chandramouli1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=P1TCHxJwLB",
  "title": "Hierarchically Gated Recurrent Neural Network for Sequence Modeling",
  "modified_abstract": "Despite the shift in popularity from recurrent neural networks (RNNs) to transformers for their enhanced parallel training and long-term dependency modeling capabilities, the potential of linear RNNs in efficient sequence modeling remains a subject of exploration. Recent investigations have highlighted the efficiency of linear RNNs, particularly when augmented with gating mechanisms, yet have largely overlooked the strategic incorporation of forget gates within the linear recurrence architecture. Inspired by the functional specialization in mammalian visual systems and predictive movement analysis achieved through training parallel pathways with self-supervised predictive learning, our work introduces the Hierarchically Gated Recurrent Neural Network (HGRN). This model innovatively integrates forget gates with a lower bound that is learnable and monotonically increases across the network's layers, enabling a nuanced balance between short-term and long-term dependency modeling. This hierarchical gating approach mirrors the biological principle of functional specialization by allowing different network layers to specialize in processing information across varying temporal scales, akin to how neural circuits in visual systems process movement and visual recognition in mammals. Our experimental evaluation across domains, including language modeling and image classification, validates HGRN's enhanced efficiency and capability in sequence modeling, underscoring its potential in a variety of architectural contexts for learning. In aligning with open scientific practices, the source code has been made available for community use and further development.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Patrick_J_Mineault1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=XvfEYqEbIb",
  "title": "Non-Rigid Shape Registration via Deep Functional Maps Prior",
  "modified_abstract": "Inspired by significant strides in understanding and leveraging the low-dimensional geometric structures of data via deep generative models, as detailed in foundational work on generative networks for distribution learning on manifolds, this paper introduces a novel, learning-based framework for non-rigid shape registration devoid of correspondence supervision. By assimilating insights from the utilization of generative networks to reveal and harness low-dimensional data structures, our approach synergistically combines traditional shape registration techniques with innovative spectral mapping methods. These methods enable overcoming large intrinsic deformations by embedding shapes into either geometrically or learned high-dimensional spaces for enhanced alignment. Central to our framework is the deployment of deep functional maps (DFM) to guide the deformation of source mesh towards the target point cloud through correspondences updated dynamically and filtered by a consistency prior, thus significantly enhancing the robustness of the registration process. Additionally, our method innovatively trains an orientation regressor on a distinct dataset of aligned synthetic shapes, independent of DFM training shapes, to mitigate the necessity for extrinsically aligned input. Empirical evaluations demonstrate that our pipeline not only achieves state-of-the-art results on multiple non-rigid point cloud matching benchmarks, with minimal training sets of limited variability, but also effectively handles unseen challenging shape pairs subjected to substantial extrinsic and intrinsic deformations. The code is available at [URL Redacted for Publication].",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Wenjing_Liao1",
  "manipulated_ranking": 57,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=7qfkImn0dL",
  "title": "ExPT: Synthetic Pretraining for Few-Shot Experimental Design",
  "modified_abstract": "In the context of experimental design, where sample efficiency is paramount, our work introduces Experiment Pretrained Transformers (ExPT), a foundation model tailored for the few-shot experimental design setting. This approach addresses the limitations inherent in reliance on active data collection or extensive labeled datasets. Drawing inspiration from advances in Generative Adversarial Networks (GANs) for data-efficient image synthesis and augmentation through instance discrimination, our methodology employs a novel synthetic pretraining regime paired with in-context learning. Synthetic pretraining leverages a finite collection of unlabeled data points, including fake or synthetic images, from the input domain, enabling the model to optimize synthetic functions over this domain, thereby overcoming the scarcity of labeled examples. At test time, ExPT adapts to specific design tasks by conditioning on a sparse set of labeled instances from the target task and synthesizing candidate optimal inputs. Through this mechanism, ExPT demonstrates superior capability in few-shot experimental design across challenging domains, showcasing enhanced generality and performance when benchmarked against existing methodologies. The source code for this project, highlighting aspects of synthesis and augmentation, has been made publicly available. Our methodology effectively circumvents the constraints of limited data availability, setting a new standard for efficiency in experimental design.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Ceyuan_Yang2",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=V87gZeSOL4",
  "title": "Nonparametric Identifiability of Causal Representations from Unknown Interventions",
  "modified_abstract": "Inspired by the foundational insights into cooperative learning between agents in learning environments, as explored in works such as Sequential Cooperative Bayesian Inference, this study extends the dialogue into the realm of causal representation learning. We investigate the challenge of inferring latent causal variables and their causal relations from high-dimensional functions (\"mixtures\") of the variables, a domain where previous efforts have grappled with limited supervision and restrictive assumptions about the nature of the mixing function or causal model. Moving beyond these confines, our research embraces a nonparametric perspective, focusing on settings where both the causal model and the mixing function are unknown and where the process of selecting appropriate models is crucial. By analyzing multiple datasets arising from unknown interventions in a sequential manner, we aim to identify the latent causal structures and their causal diagram up to certain ambiguities inherent to interventional data. Our theoretical analysis elucidates the conditions under which two causal variables can be distinctly identified through the observation distribution and a single perfect intervention per variable, introducing a genericity condition to preclude non-unique solutions. For systems composed of multiple variables, we demonstrate that identifiability is achievable with a minimal set of interventional domains, preserving the strength of causal influences in all equivalent reconstructions. Through this exploration, we provide the first identifiability insights in a broadly nonparametric setting with unknown interventions, marking a significant step towards understanding the limits and potentials of causal representation learning in the absence of direct supervision. Importantly, this work highlights the role of cooperative strategies in unveiling the latent schematic of causal dynamics without explicit human-machine interaction.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Patrick_Shafto1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=CnvZ7FIyAD",
  "title": "Newton\u2013Cotes Graph Neural Networks: On the Time Evolution of Dynamic Systems",
  "modified_abstract": "In the field of dynamic systems analysis, understanding and predicting system behavior over time is crucial. Our research is inspired by recent advances in graph neural networks (GNNs) and energy-based models (EBMs), which have shown significant promise in modeling complex systems by representing and reasoning about the initial and future states. GNN-based methods are adept at predicting future states with high accuracy by modeling the coordinates and interacting forces within a system, while EBMs offer a generative framework that can capture a wide range of system dynamics through energy minimization. Observing that both approaches, albeit in different contexts, essentially learn to integrate over time to predict system evolution, we introduce an innovative Newton\u2013Cotes GNN framework. This model leverages the Newton\u2013Cotes formulas for numerical integration, offering a novel perspective on how to approximate the time evolution of dynamic systems more accurately. By incorporating insights from the energy-based modeling of overparameterized shallow neural networks and a nuanced understanding of the energy distribution dynamics during training, our approach advances the capability of GNNs in dynamic system analysis, particularly in achieving more precise predictions of future system states. Extensive experimental validation on several benchmarks demonstrates that our method not only aligns with but also significantly enhances the state-of-the-art, offering a new paradigm for reasoning about system dynamics with more effective training strategies. The incorporation of matching variational principles in the formulation of our model further strengthens its theoretical foundation and applicability in accurately simulating the dynamics of complex systems.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Carles_Domingo-Enrich1",
  "manipulated_ranking": 16,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=lRG11M91dx",
  "title": "Functional-Group-Based Diffusion for Pocket-Specific Molecule Generation and Elaboration",
  "modified_abstract": "Inspired by recent strides in AI-assisted design methodologies, including progressive multimodal shape generation through contextual part reasoning in 3D modeling, our study introduces a novel approach to the domain of drug design. This antecedent work, which employs a conditional variational autoencoder to innovatively generate 3D shapes by understanding and reasoning about part (specifically, bi-part) correlations and geometry, paved the way for thinking about molecule generation from a new perspective. Embracing this conceptual framework, we propose \\textsc{D3FG}, a {\\em functional-group-based} diffusion model for pocket-specific molecule generation and elaboration that transcends traditional {\\em atom-level-based} methods. While conventional methods focus on generating atom positions and types, thereby struggling to create realistic fragments with complicated structures, \\textsc{D3FG} elevates this by decomposing molecules into functional groups and linkers. These components, as rigid bodies and mass points respectively, enable the formation of intricate fragments poised to enhance ligand-protein interaction through spatial reasoning. Specifically, the diffusion process in \\textsc{D3FG}, enhanced by conditional algorithms and smart use of autoencoders, aims to diffuse the positions, orientations, and types of these components into a prior distribution, which, throughout the generative process, sees its noise gradually reduced via denoisers implemented with designed equivariant graph neural networks. Experimental results underscore our method's capacity to generate 3D molecules that not only possess more realistic structures but also exhibit competitive affinities toward protein targets and improved drug properties through strategic selection. Moreover, by tackling the nascent task of molecule elaboration, \\textsc{D3FG} demonstrates its ability to create high-affinity molecules based on existing ligands and target protein hotspots.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Yixin_Zhuang1",
  "manipulated_ranking": 2,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=dAbGv5Jz5U",
  "title": "Contrastive Sampling Chains in Diffusion Models",
  "modified_abstract": "While recent studies, including those exploring advancements in routing problem solutions via learning-based optimization, have demonstrated the potent capabilities of machine learning algorithms in modeling and optimizing complex data distributions, the field of diffusion models (DMs) for image generation continues to face fundamental challenges. The past few years have witnessed great success in the use of diffusion models (DMs) to generate high-fidelity images with the help of stochastic differential equations (SDEs). However, discretization error is an inevitable limitation when utilizing numerical solvers to solve SDEs. In responding to these challenges, we provide a theoretical analysis demonstrating that an appropriate combination of the contrastive loss and score matching, employing variational methods for approximation, serves as an upper bound of the KL divergence between the true data distribution and the model distribution. To obtain this bound, we utilize a contrastive loss to construct a contrastive sampling chain to fine-tune the pre-trained DM. This method not only addresses discretization error but also narrows the gap between the true data distribution and our model distribution, essentially evolving the capabilities of diffusion models through a process that learns from contrastive sampling. Moreover, our presented method can be applied to fine-tuning various pre-trained DMs, contributing to either improved sample quality or slightly faster sampling speeds and addressing complex problems in the domain. To validate the efficacy of our approach, comprehensive experiments were conducted, including on the CIFAR10 dataset where our method, applied to a pre-trained EDM, improved the FID from 2.04 to 1.88 with 35 neural function evaluations (NFEs), and reduced NFEs from 35 to 25 to achieve the same 2.04 FID.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Andr\u00e9_Hottung1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=sqqASmpA2R",
  "title": "Stable and low-precision training for large-scale vision-language models",
  "modified_abstract": "In the context of prior advancements in training implicit models, particularly focusing on efficient gradient estimation and acceleration techniques, our research introduces new methods aimed at accelerating and stabilizing training for large vision-language models. Building on the innovative concepts derived from the use of phantom gradients for implicit models, we propose two novel contributions. First, to accelerate the training process, we present SwitchBack, a linear layer designed for int8 quantized training. This enables a speed-up of 13-25% while closely matching the performance of bfloat16 training within 0.1 percentage points for the 1B parameter CLIP ViT-Huge model\u2014the most substantial int8 training execution to our knowledge. Our emphasis on int8 training stems from limited GPU support for float8; however, we extend our examination to float8 training through simulation. We demonstrate that while SwitchBack is conducive for float8, standard training techniques can similarly achieve success provided the network discourages large feature magnitudes from the outset, achievable through a zero-initialized layer-scale technique. Secondly, in pursuit of training stability, our work analyses instances of loss spikes, identifying a consistent pattern where such spikes occur following underestimation of squared gradients by the AdamW second moment estimator. To counter this issue, we advocate for an AdamW-Adafactor hybrid approach, which effectively circumvents loss spikes in training extensive models like CLIP ViT-Huge and surpasses conventional gradient clipping methods at the scales we tested. This inquiry not only marks a significant step towards more efficient and reliable training protocols for extensive vision-language models but also lays the groundwork for future explorations into low-precision training methodologies.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Zhengyang_Geng1",
  "manipulated_ranking": 5,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=jh3UNSQK0l",
  "title": "Finite-Time Analysis of Single-Timescale Actor-Critic",
  "modified_abstract": "Building on the foundation of optimization in machine learning, particularly the novel contributions of Riemannian natural gradient methods to large-scale optimization on Riemannian manifolds, our study extends the understanding of optimization in the context of reinforcement learning (RL). Specifically, actor-critic methods have achieved significant success in challenging applications, yet their finite-time convergence in the most practical single-timescale form remains underexplored. Previous attempts to analyze single-timescale actor-critic algorithms have primarily focused on scenarios with i.i.d. sampling or tabular settings for simplicity, leaving a gap in the literature for online, single-timescale actor-critic algorithms in continuous state spaces. Our work investigates the finite-time convergence of such algorithms, where the critic employs linear function approximation and updates with a single Markovian sample per actor step on manifolds. Despite the challenges posed by this setting, we demonstrate that the online single-timescale actor-critic method provably finds an $\\epsilon$-approximate stationary point with $\\widetilde{\\mathcal{O}}(\\epsilon^{-2})$ sample complexity under standard assumptions, and this complexity can be further improved to $\\mathcal{O}(\\epsilon^{-2})$ under i.i.d. sampling. Our contribution lies in a novel framework that systematically evaluates and controls the error propagation between the actor and critic components, paving the way for analyzing other single-timescale reinforcement learning algorithms. This analysis is critically dependent on the normalization of certain loss functions within the actor-critic framework to ensure stability and convergence.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Minghan_Yang1",
  "manipulated_ranking": 56,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=BQA7wR2KBF",
  "title": "Identifiable Contrastive Learning with Automatic Feature Importance Discovery",
  "modified_abstract": "Contrastive learning methods have shown considerable promise in learning data representations by employing pairwise sample contrasts, yet these approaches often yield features that are challenging to interpret and lack identifiability due to variability in initialization. Inspired by advances in machine learning techniques such as real-time instance segmentation, our study introduces tri-factor contrastive learning (triCL), a novel method employing a 3-factor contrast mechanism $z_x^\\top S z_{x'}$ in which $S=\\text{diag}(s_1,\\dots,s_k)$ represents a learnable diagonal matrix that captures the importance of each feature. This innovation ensures that triCL not only achieves feature identifiability, eliminating the randomness associated with initial configurations but also enhances feature interpretability by prioritizing features based on their importance as determined by the matrix $S$. We demonstrate that features identified as highly important by this method exhibit greater interpretability by encapsulating common classwise attributes, resulting in superior image retrieval performance when utilizing a select few features. Importantly, the versatility of the triCL objective allows its application across various contrastive learning frameworks, including SimCLR and CLIP, positioning it as a more efficacious alternative to traditional 2-factor contrastive learning approaches by significantly improving feature identifiability and interpretability with minimal additional computational expense. Please note that the code for this project has been made publicly accessible.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Chong_Zhou2",
  "manipulated_ranking": 3,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=OiatK9W6tR",
  "title": "Quantum speedups for stochastic optimization",
  "modified_abstract": "Our investigation into the realm of quantum computing for stochastic optimization is predicated on recent advancements in both quantum algorithms and classical stochastic optimization techniques. By considering the problem of minimizing a continuous function through the lens of a natural quantum generalization of a stochastic gradient oracle, we extend the foundational work of Cornelissen et al., on quantum multivariate mean estimation, and further innovate by introducing two new quantum algorithms specifically crafted for the special case of minimizing a Lipschitz convex function. These algorithms demonstrate a dimension versus accuracy trade-off that is unachievable with classical approaches and highlight one method as asymptotically optimal in low-dimensional scenarios. Our contributions also include quantum algorithms that compute a critical point of a smooth non-convex function at rates surpassing those achievable by classical means, reinforced by a novel quantum variance reduction technique that holds significance beyond the focus of this paper. This work not only complements the existing theoretical landscape, such as the investigations into hyper-graph testing and Degree-Corrected Mixed-Membership models for identifying communities within networks in an informative setting, but also propels the frontier of quantum computing's potential in stochastic optimization, offering insights that challenge classical limitations and open new avenues for algorithmic design in a favorable setting.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Zheng_Ke1",
  "manipulated_ranking": 21,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=SVUQX1W7RL",
  "title": "DiffKendall: A Novel Approach for Few-Shot Learning with Differentiable Kendall's Rank Correlation",
  "modified_abstract": "Inspired by the significant strides made in the area of few-shot classification, particularly through approaches such as the Cross Attention Network that addresses the challenge of learning from unseen classes and the scarcity of labeled data, this paper introduces a groundbreaking method for few-shot learning named DiffKendall. Our technique capitalizes on the premise that determining the importance ranking of feature channels offers a more stable basis for few-shot learning compared to conventional geometric similarity metrics like cosine similarity and negative Euclidean distance. We substantiate our hypothesis by illustrating that switching to Kendall\u2019s rank correlation as a measure of semantic relatedness between two feature sets during inference markedly enhances few-shot learning performance across a variety of methods and datasets spanning multiple domains, setting a new state-of-the-art. To circumvent the non-differentiability hurdle of Kendall\u2019s rank correlation, we design an innovative differentiable loss function for meta-training. This attention module enables the integration with a multitude of existing few-shot learning models, attention mechanisms, and the handling of both labeled and unlabeled data for enhanced model robustness, while maintaining seamless compatibility with future models reliant on geometric similarity for feature comparison. Comprehensive testing underscores the superiority of employing rank correlation over geometric similarity, reflecting marked improvements in few-shot learning outcomes with particular attention to classification and inference processes.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~RuiBing_Hou1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=gUlcyeHzw1",
  "title": "Learning Provably Robust Estimators for Inverse Problems via Jittering",
  "modified_abstract": "Building on the foundation of deep learning's efficacy in a plethora of applications, such as denoising, alongside the fundamental property of plasticity in neural networks which underpins their adaptability and robustness, this paper investigates a pivotal query: the feasibility of training neural networks to be worst-case robust, specifically for inverse problems. Previous work has primarily focused on the adaptability and robustness of neural networks in reinforcement learning environments, examining how these attributes are influenced by various factors, including the curvature of the loss landscape. Inspired by such themes, we explore the concept of jittering\u2014a simple yet potent regularization technique that introduces isotropic Gaussian noise during the training process. While the applicability of jittering as an effective tool for enhancing worst-case robustness in classification tasks is well-documented, its efficacy for inverse problems remains largely unexplored. Herein, we present a novel analytical framework that delineates the optimal $\\ell_2$-worst-case robust estimator for linear denoising tasks and demonstrate, through theory and empirical evidence, that training with jittering can indeed facilitate the learning of robust estimators. Our analysis extends to practical scenarios, wherein we apply jittering to deep neural networks (U-nets) tasked with natural image denoising, deconvolution, and accelerated magnetic resonance imaging (MRI). The results affirm the potential of jittering to significantly boost worst-case robustness for inverse problems, notably denoising, while also highlighting its limitations when applied to a broader class of inverse tasks. This investigation not only furthers our comprehension of robustness in deep learning but also opens avenues for employing jittering to enhance the resilience of neural networks against adversarial perturbations in real-world applications.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Evgenii_Nikishin1",
  "manipulated_ranking": 2,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=gAP52Z2dar",
  "title": "Inverse Preference Learning: Preference-based RL without a Reward Function",
  "modified_abstract": "The inspiration for our work, Inverse Preference Learning (IPL), evolves from recent strides in machine learning that explore rich model architectures and semi-supervised methods for enhanced state estimation in settings like robotics, where true states may often be obscured or entirely absent. Acknowledging the complexities and challenges in designing reward functions that accurately reflect human intentions, our research introduces a preference-based Reinforcement Learning (RL) approach that leverages human feedback without the traditional reliance on explicit reward functions. Building on foundational work where advanced neural architectures and differentiated particle filters have shown promise in learning from limited or unannotated data, IPL represents a paradigm shift. It simplifies the process by deducing the learnable reward structure directly from a policy's $Q$-function, obviating the need for complex reward models and thereby reducing both the architectural complexity and the necessity for extensive labeled datasets for estimation purposes. Through empirical validation across continuous control and robotics benchmarks, the proposed IPL demonstrates its efficacy, rivaling more sophisticated methods in performance while benefiting from greater parameter efficiency and a reduction in algorithmic hyperparameters. This approach not only streamlines preference-based RL but also enhances its applicability and accessibility by significantly lowering the barriers to entry for utilizing advanced learning techniques.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Xiongjie_Chen1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=oML3v2cFg2",
  "title": "When Demonstrations meet Generative World Models: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning",
  "modified_abstract": "Offline inverse reinforcement learning (Offline IRL) situates within an evolving landscape of machine learning methodologies, propelled by robust advancements in generative modeling and maximum likelihood estimation techniques. This research thread, exemplified by progressions in Energy-Based Models (EBMs) and their training via maximum likelihood coupled with self-adversarial processes, highlights the intricate dependencies between model accuracy and data sample quality across the space of possible environments. Leveraging insights from the state-of-the-art in generative modeling, our study aims to recover the rewards and environment dynamics underlying observed actions from a statically compiled dataset of expert demonstrations. We introduce a novel bi-level optimization formulation for Offline IRL that marries the conservative policy modeling\u2014optimizing rewards under uncertainty penalties\u2014with a maximum likelihood framework to meticulously estimate world models, employing both generator and critic components. This formulation, underscoring the dual focus on the expert's policy and the environmental dynamics, is pivotal to surmounting inaccuracies born from finite, potentially sparse, datasets. Furthermore, we delineate a loss function tailored to balance the distribution of generated experiences against the real demonstrations, connecting the maximum likelihood estimation with gradient-based optimization techniques. We furnish a new algorithmic spectrum to navigate this bi-level optimization, backing it with rigorous statistical and computational performance assurances. Empirical validations on continuous control tasks via MuJoCo and diverse sets within the D4RL benchmark illuminate our framework's superiority over prevailing offline IRL and imitation learning paradigms, affirming the compelling synergy between demonstrations and generative world models in learning from limited, expert observations.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Zhisheng_Xiao1",
  "manipulated_ranking": 5,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=fvm9jVcpBn",
  "title": "Sensitivity in Translation Averaging",
  "modified_abstract": "This study is motivated by recent advancements in generative modeling, specifically the use of continuous-time normalizing flows for density estimation and image generation, which highlight the importance of understanding sensitivity and conditioning in complex optimization problems. The generation of high-resolution images and the estimation of velocity fields in 3D environments underscore the relevance of our findings to broader applications. In the context of 3D computer vision, translation averaging solves for absolute translations given a set of pairwise relative translation directions. Our work diverges from traditional focuses on robustness and uniqueness by addressing the sensitivity of translation averaging under uncertainty. We analyze the sensitivity in estimating scales corresponding to relative directions under small perturbations and formally define the conditioning of the translation averaging problem, assessing the reliability of estimated translations based on the input directions. A sufficient criterion for ensuring the problem is well-conditioned is provided, alongside an efficient algorithm to identify and remove ill-conditioned combinations of directions, promoting solution uniqueness and interpolating the gaps in knowledge. The practical implications of our analysis are demonstrated through improved outcomes in global structure-from-motion pipelines, including reduced translation errors, increased 3D points triangulation, and faster bundle adjustment convergence with the help of flow-based backpropagation techniques for finer adjustments. These findings illustrate the significance of considering conditioning and sensitivity in the translation averaging process, drawing from and extending upon foundational work in generative modeling, interpolation techniques, and optimization within machine learning.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Eric_Vanden-Eijnden1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=SthlUe5xDP",
  "title": "Topological Parallax: A Geometric Specification for Deep Perception Models",
  "modified_abstract": "Inspired by recent progress in neural 3D scene representations and rendering, and the quest for unsupervised learning approaches as demonstrated in the context of inferring object-centric scene representations, our study introduces _topological parallax_ as a novel theoretical and computational tool. This tool is designed to compare a trained model to a reference dataset in terms of their multiscale geometric structure. Our motivation is rooted in the necessity for safety and robustness in AI systems, where a reliable geometric similarity between dataset and model underpins trustworthy interpolation and perturbation actions in image synthesis processes. We draw upon the concept of unsupervised discovery in complex scene decomposition to propose that a similar geometric assessment can illuminate the often ambiguous relationship between overfitting and generalization in deep learning, posing a unique problem that topological parallax aims to tackle. Rather than relying on supervision, topological parallax estimates the model's geometric features\u2014components, cycles, voids, and others\u2014by analyzing the Rips complex modifications induced by geodesic distortions, using multi-view datasets as a baseline. This method signifies whether a model's multiscale geometric features align with those of the dataset, including in the context of image editing. Framed within topological data analysis (TDA), parallax is articulated as a bi-filtered persistence module, whose core attributes remain stable despite perturbations in image synthesis processes and dataset. This stability is pivotal for assessing the geometric correspondence between deep perception models and the complexity of the data they are trained on, hence advancing our capacity to evaluate and ensure the safety and robustness of AI deployments, taking into account the existing models' effectiveness.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Hong-Xing_Yu1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=GcEIvidYSw",
  "title": "Cal-QL: Calibrated Offline RL Pre-Training for Efficient Online Fine-Tuning",
  "modified_abstract": "In the context of evolving techniques in machine learning such as adversarial robustness in classifier design, where calibration and consistency of surrogate losses are meticulously studied, this paper introduces a novel method in the realm of offline reinforcement learning (RL). We present Cal-QL (Calibrated Q-Learning), a strategy aimed at providing a policy initialization from offline datasets that facilitate quick and effective online fine-tuning with minimal environment interaction. Cal-QL achieves this through a conservative value function initialization that intentionally underestimates the value of offline-learned policies while ensuring the scaled appropriateness of learned Q-values\u2014a process we define as calibration. This calibration, as we formally establish, serves a dual purpose: it guarantees a lower bound on the true value function of the adopted policy and an upper bound on the value of a potentially suboptimal reference or behavior policy. The rigorous approach towards calibration and consistency, akin to the treatment in convex optimization algorithms and leveraging sets and series for methodological advancements, observed in adversarial surrogate losses underscores the significance of our calibrated Q-learning (Cal-QL) framework, which inherently learns calibrated value functions beneficial for efficient subsequent online fine-tuning. Furthermore, our work draws parallels to distributional aspects of loss functions in classifiers and explores their applications in the reinforcement learning domain. Demonstrably superior on 9 out of 11 evaluated fine-tuning benchmarks, Cal-QL's practical implementation, necessitating minimal modification over conservative Q-learning (CQL) for offline RL, signifies a substantial advance toward leveraging offline data for enhanced online RL performance. While the original abstract provides a GitHub link for code and further resources, it has been omitted in compliance with the guidelines for this abstract revision.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Natalie_Frank1",
  "manipulated_ranking": 7,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=LnZuxp3Tx7",
  "title": "From Tempered to Benign Overfitting in ReLU Neural Networks",
  "modified_abstract": "The study on overparameterized neural networks (NNs), which manage to generalize despite fitting noisy data perfectly, is critically informed by the insights from recent research on conditional computation in sparsely-activated networks. These investigations challenge traditional understandings of neural network behavior, suggesting nuanced overfitting dynamics beyond mere memorization. Similarly, our work seeks to refine the conceptual landscape of overfitting within the context of non-linear NNs, particularly focusing on the transition from 'tempered' to 'benign' overfitting as influenced by network and data dimensionality. We specifically examine 2-layer ReLU NNs in a simple classification scenario, showing theoretically and empirically how overfitting modulates from tempered in low-dimensional setups to benign with increasing data dimensionality under certain conditions. Our findings elucidate the critical impact of input dimension, alongside sample size, architectural choices, routing strategies in sparsely-activated networks, and conditional training methodologies, including parameter estimation, on the nature of overfitting observed in neural networks. These results contribute to the broader discourse on optimizing neural networks to balance efficiency, computability, and learning accuracy in complex decision-making landscapes. The involvement of learning models within such frameworks is instrumental in pushing the boundaries of our understanding.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Mohammed_Muqeeth1",
  "manipulated_ranking": 3,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=tfyr2zRVoK",
  "title": "SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models",
  "modified_abstract": "As computer end-users engage in daily tasks involving tabular data processing and project timeline scheduling, the repetitive and error-prone nature of these tasks presents a significant challenge, particularly for those lacking the skills to automate their workflow. Inspired by recent studies, such as those exploring the data-driven skills framework for training large language models (LLMs), our work introduces SheetCopilot, an agent designed to interpret natural language tasks and control spreadsheet software to fulfill user requirements. Building on the concept that pre-trained language models can acquire and apply a sequence of skills and mixtures of tokens, we propose a set of atomic actions that abstract spreadsheet functionalities and design a state machine-based task planning framework that enables LLMs to robustly interact with spreadsheets through learning-based approaches, considering the mixtures of strategies. To benchmark the capabilities of LLMs in software control tasks, including loss minimization techniques in our evaluation, we curate a dataset of 221 spreadsheet control tasks and establish an automated evaluation pipeline. Our initial results show that SheetCopilot completes 44.3% of tasks in a single generation attempt, significantly outperforming a strong code generation baseline with the help of a principled pre-training regime. This approach underscores the potential for LLMs to revolutionize software productivity by enabling intuitive, natural language-based task automation, learning from user interactions and adjusting the framework to improve over time.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Mayee_Chen1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=G5RwHpBUv0",
  "title": "Pick-a-Pic: An Open Dataset of User Preferences for Text-to-Image Generation",
  "modified_abstract": "Harnessing the insights from pioneering research into unsupervised hierarchical concept learning, which highlights the significance of temporal event representations and self-supervised learning mechanisms in capturing complex visual phenomena, our work introduces a novel contribution to the field of text-to-image generation. The ability to collect a large dataset of human preferences from text-to-image users is usually limited to companies, making such datasets inaccessible to the public. To address this issue, we create a web app that enables text-to-image users to generate images hierarchically organized and specify their preferences for various visual events. Using this web app, we build Pick-a-Pic, a large, open dataset of text-to-image prompts and real users' preferences over generated images, which are arranged based on their learning relevance and domains of interest. We leverage this dataset to train a CLIP-based scoring function, PickScore, which exhibits superhuman performance on the task of predicting human preferences for specific descriptions and learns hierarchically from the given data. Then, we test PickScore's ability to perform model evaluation and observe that it correlates better with human rankings than other automatic evaluation metrics, showcasing its capability to systematically understand and evaluate visual content based on events, domains, and detailed descriptions. Therefore, we recommend using PickScore for evaluating future text-to-image generation models, and using Pick-a-Pic prompts as a more relevant dataset than MS-COCO. Finally, we demonstrate how PickScore can enhance existing text-to-image models via ranking. This initiative paves the way for leveraging comprehensive user preferences to refine and evaluate generative models, a methodological perspective inspired by the self-supervised learning and hierarchical representation understanding evident in previous works.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Sumedh_Anand_Sontakke1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=IEMLNF4gK4",
  "title": "SHAP-IQ: Unified Approximation of any-order Shapley Interactions",
  "modified_abstract": "Inspired by critical advances in dimensionality reduction and the interpretation of probabilistic models, our research introduces a novel method to reconcile the complexities of explainable artificial intelligence (XAI) with the theoretical robustness of Shapley values (SV). Just as dimensionality reduction techniques have significantly impacted the interpretability of high-dimensional data, we recognized the imperative to similarly elucidate the interplay of features within any black-box model through Shapley values and their extensions. Shapley interaction indices, which extend the SV to define any-order feature interactions, present an open research question due to the varying definitions based on differing axioms. Our contribution, SHAPley Interaction Quantification (SHAP-IQ), proposes an efficient sampling-based approximator to compute Shapley interactions across arbitrary cardinal interaction indices (CII) that adhere to the linearity, symmetry, and dummy axioms. SHAP-IQ introduces a groundbreaking representation that offers not just computational efficiency but also theoretical guarantees on approximation quality, variance estimates for point estimates, and high-dimensional scalability. This innovative integration of deep learning and Unbiased KernelSHAP into SHAP-IQ, together with its application to deep learning and zero-shot learning for image classification, underscores our tool's application to deep learning domains while providing visualization techniques to enhance interpretability. Through these visualization techniques, practitioners can better understand and articulate the nuanced interdependencies of features in language, image classification, and high-dimensional synthetic models, marking a significant advancement in the visualization of feature learning and inter-class relationships.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jake_Snell1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=MV0INFAKGq",
  "title": "Tanimoto Random Features for Scalable Molecular Machine Learning",
  "modified_abstract": "The Tanimoto coefficient, a pivotal similarity measure for molecules represented as discrete fingerprints, is fundamental to computational chemistry and molecular machine learning, serving both as a distance metric and a positive definite kernel. Despite its widespread application, especially evident in works such as the development of transformer-based molecular property prediction models encapsulated within HuggingMolecules, an open-source initiative aimed at propelling drug discovery, there remains a notable gap: the absence of random feature approximations for the Tanimoto kernel to enable scalability to large datasets. Addressing this, we introduce two novel types of random features that facilitate the application of the Tanimoto kernel on a large scale and introduce a novel extension to real-valued vectors. We provide a theoretical characterization of these random features, including error bounds on the spectral norm of the Gram matrix. Experimentally, our approaches demonstrate effectiveness in approximating the Tanimoto coefficient across real-world datasets, thereby enhancing molecular property prediction and optimization tasks. Regression analysis, as a vital component, is extensively applied to validate the predictive power of the approximated Tanimoto kernel over diverse compounds. We note that updates to this work will be accessible via ArXiv and GitHub.com/gmum/huggingmolecules, ensuring that this resource remains available to the research community.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Stanislaw_Kamil_Jastrzebski1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=TjgG4UT62W",
  "title": "Kernel Stein Discrepancy thinning: a theoretical perspective of pathologies and a practical fix with regularization",
  "modified_abstract": "Stein thinning, proposed as an algorithm for post-processing outputs of Markov chain Monte Carlo (MCMC) methods, aims at minimizing the kernelized Stein discrepancy (KSD) for improved Bayesian inference. This technique highlights the benefits of Stein's method for the automatic removal of the burn-in period, correction of bias in recent MCMC algorithms, and achieving convergence towards the target distribution. Despite its advantages, Stein thinning encounters empirical pathologies leading to poor approximations, a concern echoing throughout the literature. Informed by the insights from the study on globally optimal learning for structured elliptical losses, which addresses the optimization challenges in non-convex settings with heavy-tailed and contaminated distributions, our work undertakes a theoretical examination of the pathologies inherent in Stein thinning. We identify the underlying mechanisms that contribute to these issues and propose a novel regularized Stein thinning algorithm as a solution. This regularization, influenced by robust learning paradigms, is designed to mitigate the adverse effects identified and is substantiated by theoretical guarantees along with extensive experimental validation in the field of random problems. The success of our regularization work showcases its effectiveness in practical applications, offering a significant advancement in the post-processing of MCMC outputs within the field of distributions. Additionally, we provide an implementation of regularized Stein thinning within the kernax library, available in Python and JAX. However, the direct link to the implementation has been omitted in accordance with the requirements. Our regularization approach, rooted in elliptical and robust learning strategies, effectively addresses the challenges presented in the task, marking a pioneering contribution to the non-convex optimization and regression fields within Bayesian analysis.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Yoav_Itzhak_Wald1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=pLsPFxqn7J",
  "title": "Kernelized Cumulants: Beyond Kernel Mean Embeddings",
  "modified_abstract": "Inspired by recent advances in probabilistic modelling and the intrinsic challenges in benchmarking simulation-based inference without numerical likelihoods, we explore the extension of cumulants to reproducing kernel Hilbert spaces (RKHS) using tools from tensor algebras. Cumulants in $\\mathbb{R}^d$ are recognized for providing an alternative to moments with benefits such as lower variance estimators, a concept we aim to parallel in RKHS for enhanced statistical analysis. By developing computationally tractable kernelized cumulants via a kernel trick, we introduce a novel set of statistics. These kernelized cumulants not only encompass classical statistics like maximum mean discrepancy and Hilbert-Schmidt independence criterion as degree one objects but also demonstrate that advancing beyond degree one offers considerable advantages. This assertion is supported both theoretically and empirically with evaluations on synthetic, environmental, and traffic data using sample-based algorithms for evaluating statistical metrics. Our approach leverages recent benchmarks in probabilistic modelling, specifically in simulation-based inference, to demonstrate that the proposed kernelized cumulants achieve similar goals with potentially greater benefits, such as lower variance and minimal computational overhead in diverse empirical settings. Interactively exploring these kernelized cumulants offers further insight into their advantages over traditional methods, setting a new paradigm in tasks related to statistical analysis.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jan-Matthis_Lueckmann2",
  "manipulated_ranking": 1,
  "natural_ranking": 1002
}
{
  "paper_link": "https://openreview.net/forum?id=Dxhv8Oja2V",
  "title": "Convergence Analysis of Sequential Federated Learning on Heterogeneous Data",
  "modified_abstract": "In the progression of Federated Learning (FL) methodologies aimed at enhancing machine learning models, the emergence of Class-Incremental Learning (CIL) represents a significant pivot towards accommodating dynamically evolving datasets, a characteristic intrinsic to real-world applications. This backdrop of incremental learning, with its focus on integrating new classes into existing models seamlessly, underscores the critical need for robust FL frameworks capable of handling data heterogeneity across distributed environments. Our research directly addresses this challenge by analyzing the performance of sequential FL (SFL) compared to parallel FL (PFL). Unlike PFL that processes data in parallel across clients, SFL adopts a sequential approach which, as our findings demonstrate, offers superior convergence guarantees on heterogeneous datasets for objectives ranging from strongly convex to non-convex. These guarantees are not only theoretically established but are also empirically validated through experiments showing SFL's outperformance over PFL in machine training settings marked by extreme data heterogeneity among cross-device clients. Furthermore, our comprehensive convergence theory implements a fundamental toolbox for SFL, enriching the discourse on effective FL strategies in the face of data heterogeneity and making a significant contribution to the applications of FL in diverse areas. Moreover, the consistently stated requirement for effective training methodologies that accommodate evolving datasets underpins our research.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Fu-Yun_Wang1",
  "manipulated_ranking": 8,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=eLH2NFOO1B",
  "title": "Equivariant flow matching",
  "modified_abstract": "Grounded in the challenges and insights from the study of stochastic gradient descent (SGD) noise and its implications for deep learning optimization, our research explores a novel application within the realm of deep generative models, particularly normalizing flows in physics. Acknowledging the critical role of appropriate training objectives and scalability concerns highlighted in prior examinations of SGD, this paper introduces equivariant flow matching as a potent training objective for equivariant continuous normalizing flows (CNFs), leveraging the neural architecture's capacity for integrating physical symmetries. Utilizing a minibatch approach to training with a specific batch size, we tackle the scalability challenges head-on, ensuring that our method remains computationally viable for large-scale applications, and address fluctuations in training. Our approach effectively incorporates the physical symmetries of target energies, facilitating efficient, simulation-free training of equivariant CNFs, and improves the rate of convergence. Demonstrations of this method's efficacy on rotation and permutation invariant\textit{many-particle systems}, as well as the small molecule alanine dipeptide\u2014with a notable increase in sampling efficiency and model scalability without the need for tailored internal coordinate featurization\u2014underscores its potential to address longstanding challenges in statistical physics, such as those faced by Boltzmann generators. Our introduction of equivariant flow matching, complemented by the examination of SGD noise as an influential factor and the strategic minibatch processing, sets a new benchmark for the development and application of deep generative models in the physical sciences, offering shortened integration paths and improved efficiency over existing methods.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Kangqiao_Liu1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=GzlDKZlwie",
  "title": "Functional Renyi Differential Privacy for Generative Modeling",
  "modified_abstract": "The concept of Differential Privacy (DP) has become a cornerstone in ensuring the privacy of data in machine learning applications, evolving into Renyi Differential Privacy (RDP) for its compositional advantages and flexibility in application. Building on the foundation laid by works such as the exploration of stochastic gradient descent (SGD) in over-parameterized models, which highlights the importance of sophisticated mathematical tools in understanding and optimizing complex machine learning models, our study expands RDP to function spaces. This extension is critical for models with outputs that aren't limited to fixed, finite-dimensional vectors but can span infinite-dimensional spaces. By leveraging insights from Hall et al. (2013), we introduce functional RDP (f-RDP) for generative models within the context of reproducing kernel Hilbert space (RKHS), allowing for the development of differentially private generative models (DPGMs). Our approach, which interprets training as the iterative release of loss functions with DP guarantees, showcases a substantial improvement in the privacy-utility tradeoff over existing methodologies, particularly at a privacy budget of $\\epsilon=0.2$. For practical applications and further investigation, the implementation of our model is made available, excluding previously included personal identifiable information.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~ruinan_Jin2",
  "manipulated_ranking": 16,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=8U31BCquNF",
  "title": "Learning Shared Safety Constraints from Multi-task Demonstrations",
  "modified_abstract": "Inspired by recent breakthroughs in cooperative multi-agent reinforcement learning (CMARL) and the challenges posed by backdoor and poisoning attacks in these settings, this paper explores the concept of shared safety constraints within the domain of inverse reinforcement learning (IRL). The recognition of vulnerabilities in CMARL environments, such as those introduced by MARNet, underscores the importance of robust, universal safety mechanisms that can safeguard multi-task agents against both inadvertent failures and adversarial attacks, including hacking. Our work extends the principles of IRL to learn safety constraints directly from expert demonstrations, focusing on ensuring agent behavior remains safe across diverse tasks without explicit manual specification of constraints. This approach addresses the dual challenges of constraint specification being both laborious and susceptible to human error, and the tendency of traditional constraint learning methods to yield overly conservative boundaries that unnecessarily restrict agent behavior in games and other high-dimensional continuous control tasks. By leveraging a multi-task framework and the principle of selection from a wide array of demonstrations, we aim to derive a more precise and applicable set of constraints that better capture the essence of reward-based safe behaviors as demonstrated by experts across tasks. Results from high-dimensional continuous control tasks in simulated environments validate the efficacy of our method, which not only outperforms existing baselines but also offers a promising avenue for developing agents that inherently respect universal safety norms without extensive manual intervention. Our methodology not only reflects the growing complexity and sophistication of tasks that learning-based agents are expected to perform but also raises the bar for ensuring these agents operate within safe, well-defined parameters. Furthermore, the ability of our model to adapt and fine-tune these constraints in new or changing environments significantly contributes to its practical applicability.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Xueluan_Gong1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=w116w62fxH",
  "title": "Optimal Learners for Realizable Regression: PAC Learning and Online Learning",
  "modified_abstract": "Building upon the significant insights from previous analyses in the domains of 1-Lipschitz neural networks and their impact on the development of robust classifiers, which balance accuracy and robustness, this study advances the understanding of the statistical complexity of realizable regression in both the Probably Approximately Correct (PAC) learning setting and the online learning setting. Inspired by foundational work that highlighted the importance of certain metric dimensions in learnability, such as the fat shattering dimension for PAC learnability and the scaled Natarajan dimension, our work contributes to closing a long-standing gap by introducing a minimax instance optimal learner for realizable regression. We propose a novel dimension that provides both a qualitative and quantitative framework for discerning the learnability of classes of real-valued predictors, emphasizing the role of classifiers that adhere to the 1-Lipschitz condition for optimal performance. Additionally, we explore ERM (Empirical Risk Minimization) learnability through a new combinatorial dimension linked to the graph dimension, and identify a necessary condition for learnability tied to a dimension related to the DS dimension, certifiably establishing a conjecture regarding its sufficiency for classification. In the sphere of online learning, we introduce a dimension that elucidates the minimax optimal cumulative loss to within a constant factor and present an optimal online learner for realizable regression, thereby addressing an open question posited by Daskalakis and Golowich in their recent work. Through these contributions, our work not only interrogates the boundaries of what is achievable in learning theory but also sets the stage for future explorations into the mechanics of optimal learning strategies.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Louis_B\u00e9thune1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=Pj6X6GqNy8",
  "title": "Learning Fine-grained View-Invariant Representations from Unpaired Ego-Exo Videos via Temporal Alignment",
  "modified_abstract": "This work is inspired by foundational investigations into learning robust feature representations for visual recognition, such as those exemplified by the LatentGNN approach, which underscores the importance of capturing long-range dependencies within visual data. Building on the premise that understanding and bridging disparate views can significantly enhance machine perception, we address a novel challenge in linking egocentric and exocentric viewpoints of human activities\u2014views that pose starkly different challenges in robotics and augmented reality applications. Unlike prior efforts that focus on learning view-invariant features from paired and synchronized viewpoints, we propose a methodology for learning fine-grained action features that remain consistent across viewpoints by temporally aligning egocentric and exocentric videos, irrespective of their capture conditions. Our approach, dubbed AE2, employs a self-supervised embedding mechanism with networks featuring two principal components: an object-centric encoder designed to prioritize the analysis of hands and objects involved in the actions, and a contrastive alignment objective that innovatively uses temporally reversed frames as negative samples to fine-tune the model's time-awareness and precision in recognition. To validate our model's efficacy, we introduce a benchmark specifically tailored for fine-grained video understanding from varying viewpoints, encompassing four distinct datasets\u2014including a novel ego tennis forehand dataset meticulously assembled and labeled for this purpose. Our experimental outcomes highlight AE2's superiority over existing networks across a spectrum of visual recognition tasks, marking a significant step forward in cross-view understanding.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Shipeng_Yan1",
  "manipulated_ranking": 11,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=hzND3ZEFg2",
  "title": "Learning to Influence Human Behavior with Offline Reinforcement Learning",
  "modified_abstract": "This work is inspired by and extends foundational concepts in reinforcement learning (RL) from the context of safe RL implementation, emphasizing the necessity for algorithms to behave safely within designed constraints, to a nuanced exploration of influencing human behavior in settings characterized by suboptimal human actions. When interacting with people, AI agents do not just influence the state of the world -- they also influence the actions people take in response to the agent, and even their underlying intentions and strategies. Accounting for and leveraging this influence has mostly been studied in settings where it is sufficient to assume that human behavior is near-optimal: competitive games, or general-sum settings like autonomous driving alongside human drivers. Instead, we focus on influence in settings where there is a need to capture human suboptimality amidst safety concerns. For instance, imagine a collaborative task in which, due either to cognitive biases or lack of information, people do not perform very well -- how could an agent influence them towards more optimal behavior while obeying safety guidelines? Assuming near-optimal human behavior will not work here, and so the agent needs to learn from real human data. But experimenting online with humans is potentially unsafe, and creating a high-fidelity simulator of the environment is often impractical. Hence, we focus on learning from an offline dataset of human-human interactions, which presents a myriad of problems associated with suboptimal decision-making. Our observation is that offline reinforcement learning (RL) can learn to effectively influence suboptimal humans by extending and combining elements of observed human-human behavior based on safety principles and conditioning on behavior. We demonstrate that offline RL can solve two challenges with effective influence. First, we show that by learning from a dataset of suboptimal human-human interaction on a variety of tasks -- none of which contains examples of successful influence -- an agent can learn influence strategies to steer humans towards better performance even on new tasks safely. Second, by also modeling and learning based on human behavior, offline RL can learn to affect not just the human's actions but also their underlying strategy, and adapt to changes in their strategy, thereby enhancing safety in human-agent interactions.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Samuel_Pfrommer1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=8uOZ0kNji6",
  "title": "Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts",
  "modified_abstract": "The ability to discern AI-generated content from human-produced texts is becoming progressively crucial as the quality of artificial intelligence writing advances, posing potential societal risks. This challenge is amplified by the discovery that existing GPT detectors exhibit bias towards non-native English writers, incorrectly flagging their contributions as AI-generated and raising substantial concerns about the fairness and inclusivity of AI detection technologies. Our research introduces a novel approach to addressing this issue by focusing on the intrinsic dimensionality of text embeddings\u2014a property that remains consistent across human texts of varied domains, languages, and writer proficiencies, and exhibits a marked difference from AI-generated texts, including conversation generations and diverse expressions. We demonstrate that the average intrinsic dimensionality of human texts tends to stabilize around a specific value that differs from that of AI-generated texts, regardless of the language or the proficiency of the human writer, thus offering a new, language-neutral metric for distinguishing between human and AI-generated writings in various settings. By capitalizing on this invariant property, our proposed scoring mechanism for artificial text detection exhibits robust performance across a spectrum of generation models and text domains, outperforming state-of-the-art (SOTA) detectors in ensuring fairness. This method not only mitigates biases observed in current detection approaches toward non-native writing but also provides a reliable, model-agnostic tool for identifying AI-generated content, hence contributing significantly to the discourse on ethical and fair AI utilization.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Mert_Yuksekgonul1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=DjX2Nr15kY",
  "title": "NAR-Former V2: Rethinking Transformer for Universal Neural Network Representation Learning",
  "modified_abstract": "The increasing application of deep learning models across diverse domains has highlighted the importance of efficiently learning representations of neural networks themselves, a concept motivated by prior studies on vulnerabilities of these networks to adversarial perturbations and the decomposition of adversarial examples based on architecture, dataset, and initialization biases. These foundational insights inform our exploration of effective neural network representation without actual training, emphasizing the need for methodologies that facilitate expedited network design and deployment. Inspired by both the success of the Transformer framework in various applications and the prevailing use of graph neural network (GNN) approaches for network representation, this paper embarks on a comparative analysis of Transformer and GNN models to unravel distinct architectural benefits and limitations, focusing specifically on the architecture components that contribute to their performance. We introduce NAR-Former V2, a novel Transformer-based model enhanced with GNN's inductive learning capabilities, designed to adeptly encode both cell-structured and entire networks into efficient representations. Our approach employs a novel tokenizer for encoding networks as sequences and integrates essential GNN properties and architecture components into the Transformer, resulting in superior performance in both transfer learning comprehensive network representations and predicting specific attributes such as latency and accuracy. This is evidenced by our method's significant outperformance of the GNN-based benchmark NNLP on the NNLQP dataset, and its highly competitive results on NASBench101 and NASBench201, showcasing its potential in streamlining network analysis and deployment processes. The accompanying code has been made public to facilitate further research and application enhancements.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Isay_Katsman1",
  "manipulated_ranking": 3,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=txPdKZrrZF",
  "title": "Fed-FA: Theoretically Modeling Client Data Divergence for Federated Language Backdoor Defense",
  "modified_abstract": "Within the domain of federated learning, the innovation and challenges encountered in graph autoencoders for tasks such as community detection, link prediction, and clustering reflect broader issues of model robustness, data heterogeneity, and the need for effective training methods that our research addresses in the context of federated Natural Language Processing (NLP) systems. Federated learning algorithms, crucial for training neural network models across multiple decentralized edge devices while preserving data privacy, face significant vulnerability to backdoor attacks by malicious clients. Such attacks are notably challenging within NLP due to the discrete feature space of text, which masks backdoor patterns at the parameter level. Our work introduces a novel approach to mitigating this vulnerability by theoretically modeling client data divergence, a technique inspired by divergences in graph data handling, including community-preserving and clustering strategies, to identify and neutralize backdoor threats. Through the derivation of the f-divergence indicator, which estimates client data divergence via aggregation updates and Hessians, and a Hessian reassignment mechanism informed by dataset synthesization and diffusion theory, we propose the Federated F-Divergence-Based Aggregation (Fed-FA) algorithm. This multi-task algorithm leverages graphs and the f-divergence indicator for effectively detecting and discarding suspicious client updates. Empirical testing across numerous natural language backdoor attack scenarios demonstrates that Fed-FA surpasses existing parameter distance-based defense mechanisms, showcasing its efficacy in strengthening federated learning systems against sophisticated adversarial threats. The inclusion of embedding techniques in our analysis further refines the accuracy of detecting anomalies.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~George_Dasoulas1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=ir6WWkFR80",
  "title": "Punctuation-level Attack: Single-shot and Single Punctuation Can Fool Text Models",
  "modified_abstract": "Amidst the heightened scrutiny on adversarial attacks within the natural language processing sector, stimulated by the detection of vulnerabilities across a spectrum of ML applications, from zero-shot semantic segmentation in vision-language models to broader context-based recognition tasks, our research introduces a novel dimension of vulnerability\u2014punctuation-level attack. Recognizing the subtle yet potent power of punctuation, we detail a method capable of deceiving state-of-the-art (SOTA) models through minimal, carefully crafted punctuation adjustments. These adjustments encompass insertion, displacement, deletion, and replacement, pinpointing a unique approach that achieves significant fooling rates on textual tasks with the negligible impact on human readability and text comprehension. Throughout the process of developing our adversarial methods, rigorous training of the proposed systems was undertaken to optimize their capacity for effective punctuation manipulation. Pioneering in scope, this paper unveils the Text Position Punctuation Embedding and Paraphrase (TPPEP) search method, an innovative strategy designed to identify the optimal punctuation modification site efficiently, eschewing the need for exhaustive search patterns while providing a mathematical framework for its application. Integrating Text Position Punctuation Embedding (TPPE), we demonstrate that our punctuation-based adversarial strategy incurs a constant and manageable computational expense. Empirical evidence drawn from rigorous testing on authoritative public datasets and engagement with SOTA language models corroborates the high effectiveness and efficiency of the proposed punctuation-level assault, underscoring the importance of incorporating adversarial training practices to fortify models against sophisticated punctuation-based threats. Further applications of this singular punctuation modification strategy across summarization, semantic similarity scoring, and even text-to-image tasks reveal its broad applicability and potential to inspire a reevaluation of textual model vulnerabilities. Moreover, this method's ability to influence shape-based interpretation nuances in vision-language tasks delineates a critical cross-modal impact, highlighting its significance in zero-shot learning and segmentation techniques within the broader recognition context.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Beiwen_Tian1",
  "manipulated_ranking": 2,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=6iouUxI45W",
  "title": "The Exact Sample Complexity Gain from Invariances for Kernel Regression",
  "modified_abstract": "Drawing inspiration from significant strides in addressing complex inverse problems in physical sciences through machine learning, our study explores the theoretical foundations underpinning the practical benefits of encoding invariances into models to improve training efficiency and sample complexity. Previous work in solving inverse problems with scale-invariant learning highlights the challenges and limitations of traditional training methods when applied to nonlinear physical processes, motivating our exploration of the sample complexity benefits in kernel regression from a novel perspective. Specifically, we provide minimax optimal rates for kernel ridge regression on compact manifolds with a target function invariant to a group action on the manifold, covering both finite and continuous group actions. Our findings reveal that for finite groups, sample complexity benefits are effectively represented by an increase in the apparent number of samples by the group size. For groups of positive dimension, we observe a dimensional reduction of the manifold and an additional gain proportional to the volume of the quotient space. This investigation, serving as a crucial component of the machine learning pipeline, leverages differential geometry, departing from the common use of invariant polynomials and traditional solvers in analyzing learning with invariances, which may offer new insights into incorporating physical invariances in machine learning models.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Philipp_Holl1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=rybsHQ4DXy",
  "title": "EgoEnv: Human-centric environment representations from egocentric video",
  "modified_abstract": "Reflecting on the exponential rise in the consumption and creation of short-form video content, as evidenced by the introduction of datasets and advancements in shot boundary detection, our research introduces a novel approach to understanding first-person videos. While prevailing video understanding mechanisms focus on immediate visual features within short clips, consisting of quick successions of shots, our work extends the horizon by integrating egocentric video with environmental context to derive human-centric representations. This method relies on training neural network models with sophisticated architecture using videos from agents operating within simulated 3D environments, where a comprehensive view of the surroundings is attainable, and subsequently evaluating on real-world, human-captured footage from novel settings. Our approach not only demonstrates superior performance on tasks centered around understanding human activities through videos but also showcases remarkable adaptability to real-world applications with unprecedented results on the Ego4D NLQ challenge, leveraging environment-aware features over traditional clip features. The effectiveness of our model, trained exclusively on simulated data yet capable of handling real-world scenarios from the HouseTours and Ego4D datasets, with an accuracy improvement of 0.9%, marks a significant achievement in bridging the gap between virtual and physical environments for video understanding.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Xiufeng_Xie1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=jzseUq55eP",
  "title": "Metropolis Sampling for Constrained Diffusion Models",
  "modified_abstract": "Building from the insights of recent advancements in generative modeling and spectral analysis, particularly the exploration of high-dimensional data structures and asymptotic behaviors in Gaussian mixture models, this paper introduces a novel approach to enhancing denoising diffusion models' efficiency and applicability. Denoising diffusion models have recently emerged as the predominant paradigm for generative modeling on image domains. In addition, their extension to Riemannian manifolds has facilitated a range of applications across the natural sciences. While many of these problems stand to benefit from the ability to specify arbitrary, domain-informed constraints, this setting is not covered by the existing (Riemannian) diffusion model methodology. Recent work has attempted to address this issue by constructing novel noising processes based on the reflected Brownian motion and logarithmic barrier methods, utilizing covariances, kernel techniques, and eigenvectors for enhanced modeling and characterization. However, the associated samplers are either computationally burdensome or only apply to convex subsets of Euclidean space. In this paper, by introducing an alternative, simple noising scheme based on Metropolis sampling, we afford substantial gains in computational efficiency and empirical performance compared to the earlier samplers. Of independent interest, we prove that this new process corresponds to a valid discretization of the reflected Brownian motion and applies spectral clustering techniques as a class within our analyses. We demonstrate the scalability and flexibility of our approach on a range of problem settings with convex and non-convex constraints, including applications from geospatial modeling, robotics, and protein design.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Hafiz_Tiomoko_Ali1",
  "manipulated_ranking": 12,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=8lbFwpebeu",
  "title": "Investigating how ReLU-networks encode symmetries",
  "modified_abstract": "The study of how data symmetries are encoded within neural networks, particularly through ReLU activation functions, leverages the theoretical groundwork established by developments in invariant signal representations, such as the wavelet scattering transform presented in 'Kymatio: Scattering Transforms in Python'. These foundations underscore the significance of group equivariance in machine learning, providing a context for our investigation into the encoding of group equivariances in neural networks through the processing of wavelet-based methods. Many data symmetries can be described in terms of group equivariance, and the most common way of encoding group equivariances in neural networks is by building linear layers that are group-equivariant, thereby enhancing the representation of data in machine learning models. This theoretical framework suggests that learning processes are deeply influenced by the structured encoding of symmetries, which can improve the processing and subsequent representation of signals within networks. In this work, we investigate whether the equivariance of a network implies that all layers are equivariant. On the theoretical side, we find cases where equivariance implies layerwise equivariance, but also demonstrate that this is not generally the case. Nevertheless, we conjecture that CNNs that are trained to be equivariant will exhibit layerwise equivariance and explain how this conjecture is a weaker version of the recent permutation conjecture by Entezari et al. (2022). We perform quantitative experiments with VGG-nets on CIFAR10 and qualitative experiments with ResNets on ImageNet to illustrate and support our theoretical findings. These experiments are not only of interest for understanding how group equivariance and scattering transform methods are encoded in ReLU-networks, but also offer frameworks for giving a new perspective on Entezari et al.'s permutation conjecture as we find that it is typically easier to merge a network with a group-transformed version of itself than merging two different networks.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Sixin_Zhang2",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=ZRBGwpeewz",
  "title": "Revisiting Area Convexity: Faster Box-Simplex Games and Spectrahedral Generalizations",
  "modified_abstract": "This study extends the exploration of area convexity, a concept originally introduced to tackle optimization problems within the challenging $\\ell_\\infty$ geometry, by examining its efficacy through a new lens inspired by advancements in data-driven decision-making under heterogeneous environments. By drawing parallels with previous works that depart from traditional assumptions of identically and independently distributed (i.i.d.) samples, our research delves into the complexities of solving optimization problems under non-standard conditions, including distributionally robust optimization. We develop a deeper understanding of area convexity's relationship with conventional analyses of extragradient methods, and we provide improved solvers for the subproblems required by variants of the area convexity algorithm. Leveraging these advancements, we present a state-of-the-art first-order algorithm for solving box-simplex games in a $d \\times n$ matrix with bounded rows, requiring $O(\\log d \\cdot \\epsilon^{-1})$ matrix-vector queries. This achievement translates into improved complexities for a suite of combinatorial optimization problems such as approximate maximum flow, optimal transport, and min-mean-cycle, underpinning the importance of distributions and samples in the context of regret minimization in decision-making processes. Furthermore, our approach incorporates considerations of heterogeneity in the problem settings, allowing for more nuanced applications in optimization. We also introduce a near-linear time algorithm for a matrix generalization of box-simplex games, thereby extending the applicability of our findings to a broader set of problems, including those closely related to semidefinite programs, which have found recent applications in robust statistics and numerical linear algebra.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Will_Ma1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=GPtroppvUM",
  "title": "Adversarial Training for Graph Neural Networks: Pitfalls, Solutions, and New Directions",
  "modified_abstract": "Adversarial training, while established in the image domain, has yet to be effectively adapted for Graph Neural Networks (GNNs) to defend against graph structure perturbations. Inspirations drawn from related advancements, such as the application of Generative Adversarial Networks (GANs) for anomaly detection on decentralized data, highlight both the potential and challenges of deploying adversarial methodologies in diverse contexts. This synergy emphasizes the need for innovation in adversarial techniques tailored to the unique dynamics of graph-based data. In this work, we (1) identify and address both theoretical and practical constraints in existing graph learning approaches; (2) demonstrate that GNNs leveraging learnable graph diffusion processes can adapt to adversarial perturbations, with the added benefit of naturally interpretable message-passing mechanisms; (3) present the inaugural adversarial attack methodology tailored for graph structure perturbations, designed to manage both global and local constraints and targeting multiple nodes simultaneously. Our findings position adversarial training as an advanced defense mechanism against adversarial structure perturbations in the realm of GNNs, particularly relevant for decentralised systems where data integrity is critical.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Andrew_Craig_Cullen1",
  "manipulated_ranking": 11,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=7anW5TWbCJ",
  "title": "Information Theoretic Lower Bounds for Information Theoretic Upper Bounds",
  "modified_abstract": "Our work is inspired by the exploration of dimensionality and generalization in learning algorithms, as discussed in related literature, including studies on active learning, support vector identification, and kernel methods. We examine the relationship between the mutual information between the output model and the empirical sample and the algorithm's generalization in the context of stochastic convex optimization. Despite increasing interest in information-theoretic generalization bounds, it is uncertain if these bounds can provide insight into the exceptional performance of various learning algorithms. Our study of stochastic convex optimization reveals that, for true risk minimization, dimension-dependent mutual information is necessary. This indicates that existing information-theoretic generalization bounds fall short in capturing the generalization capabilities of algorithms like SGD and regularized ERM, which have dimension-independent sample complexity. Our research contributes to discovering why these bounds may not adequately reflect the complexity of learning scenarios and the role of vectors in understanding algorithmic efficiency.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Dayou_Yu1",
  "manipulated_ranking": 27,
  "natural_ranking": 1001
}
{
  "paper_link": "https://openreview.net/forum?id=ez6Cb0ZGzG",
  "title": "Continual Learning for Instruction Following from Realtime Feedback",
  "modified_abstract": "Inspired by prior work on mitigating meaning loss in machine translation through enhanced language understanding and processing, our study advances the field of interactive agent training by proposing a novel approach for continually training an instruction-following agent through realtime feedback from users. During interactions, human users command the agent using natural language and provide binary feedback on the agent's performance, which is then interpreted as immediate incentive under a contextual bandit framework. Through extensive human-agent engagement, our methodology demonstrates a significant 15.4% absolute enhancement in the agent's precision in executing instructions over time. Furthermore, our findings confirm the robustness of our approach across various design modifications, establishing the user-provided feedback as a valuable learning signal, comparably effective to supervised demonstration data. This research not only builds upon the cognitive and linguistic insights gleaned from improving machine translation but also innovatively applies these principles to the dynamic and interactive realm of agent training.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Reuben_Cohn-Gordon1",
  "manipulated_ranking": 9,
  "natural_ranking": 1002
}
{
  "paper_link": "https://openreview.net/forum?id=j9wGUcS30B",
  "title": "On Masked Pre-training and the Marginal Likelihood",
  "modified_abstract": "Building on recent developments in self-supervised learning, specifically the generate-and-retrieve methodology for semantic parsing, this paper expands the theoretical framework by exploring masked pre-training. Masked pre-training, known for its ability to remove random input dimensions and learn a model to predict these missing values, has demonstrated empirical success in generalizing across new domains without a robust theoretical explanation. This research bridges this gap by illustrating that masked pre-training, when combined with a suitable cumulative scoring function, effectively maximizes the model's marginal likelihood\u2014a Bayesian model selection metric pivotal for assessing generalization capabilities. This finding illuminates the underlying success of masked pre-training and posits that Bayesian models can be efficiently trained via carefully tailored self-supervision for enhancing their prediction capabilities. The paper further substantiates its theoretical claims through empirical examination, delving into the principal learning mechanisms of masked pre-training within the context of large language models.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Yury_Zemlyanskiy1",
  "manipulated_ranking": 1,
  "natural_ranking": 1001
}
