{
  "paper_link": "https://openreview.net/forum?id=eTp4RetK74",
  "title": "ASPEN: Breaking Operator Barriers for Efficient Parallelization of Deep Neural Networks",
  "modified_abstract": "The ever-increasing complexity of Deep Neural Networks (DNNs) necessitates innovative approaches to enhance computational efficiency and scalability, inspired by the recent works in hardware-aware network transformation, structural pruning, dynamic sparsification, and optimized LSTM architectures. These works, which explore advanced techniques in neural architecture search, pruning, and compression, highlight the critical importance of hardware efficiency and algorithmic optimization in achieving high-performance DNNs. Similarly, our work introduces ASPEN, a novel parallel computation platform for DNNs that removes the bottlenecks imposed by traditional operator-based construction. By expressing DNNs in dataflow graphs of fine-grained tiles, ASPEN exposes and exploits parallel computation opportunities across operators, achieving fine-grained dynamic execution. This method also enables opportunistic parallelism, a new class of parallelism for DNNs, by dynamically locating and scheduling computations at runtime. ASPEN substantially optimizes resource utilization and memory reuse, allowing for asynchronous depthwise processing in the DNN graph and demonstrating significant performance improvements over existing inference systems such as TorchScript and TVM. Moreover, by integrating techniques like pruning and segmentation within the ASPEN framework designed to avoid overfitting, especially in complex images, we further enhance the efficiency and scalability of DNNs, setting a new benchmark for DNN performance and offering insights into overcoming operator barriers for future advancements in the field.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Hongxu_Yin1",
  "manipulated_ranking": 28,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=jDIlzSU8wJ",
  "title": "The Surprising Effectiveness of Diffusion Models for Optical Flow and Monocular Depth Estimation",
  "modified_abstract": "Inspired by the profound impact of denoising diffusion probabilistic models on high-resolution image synthesis, artistic image creation, generative image augmentation tasks, and their emergent utility in composition of visual elements, this study extends their application to the fields of optical flow and monocular depth estimation. Denoising diffusion probabilistic models have transformed image generation with their impressive fidelity and diversity, embodying principles akin to autoregressive generation but without the sequential generation's limitations. We show that they also excel in estimating optical flow and monocular depth, surprisingly without task-specific architectures and loss functions that are predominant for these tasks. Compared to the point estimates of conventional regression-based methods, diffusion models also enable Monte Carlo inference, e.g., capturing uncertainty and ambiguity in flow and depth through generation processes. With self-supervised pre-training, the combined use of synthetic and real data for supervised training, and technical innovations (infilling and step-unrolled denoising diffusion training) to handle noisy-incomplete training data, one can train state-of-the-art diffusion models for depth and optical flow estimation, with additional zero-shot coarse-to-fine refinement for high resolution estimates. Extensive experiments focus on quantitative performance against benchmarks, ablations, and the model's ability to capture uncertainty and multimodality, and impute missing values in the context of generation of depth and flow fields. Our model obtains a state-of-the-art relative depth error of 0.074 on the indoor NYU benchmark and an Fl-all score of 3.26% on the KITTI optical flow benchmark, about 25% better than the best published method.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Andreas_Blattmann1",
  "manipulated_ranking": 5,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=9fWKExmKa0",
  "title": "DPM-Solver-v3: Improved Diffusion ODE Solver with Empirical Model Statistics",
  "modified_abstract": "Inspired by recent innovations in machine learning, this work advances the efficiency of diffusion probabilistic models (DPMs) for high-fidelity image generation, including vehicles and other complex subjects, addressing the issue of inefficient sampling noted in prior research. DPMs have demonstrated exceptional performance in generating high-quality images, yet they are hampered by inefficient sampling processes. Recent attempts to accelerate sampling have explored the use of fast ordinary differential equation (ODE) solvers tailored to the ODE form characteristic of DPMs. Despite advancements, these solutions depend heavily on specific parameterizations during inference (e.g., noise/data prediction), potentially limiting optimality. We introduce a novel approach aimed at optimizing these parameterizations for sampling, focusing on minimizing the first-order discretization error in the ODE solution. Utilizing this approach, we present DPM-Solver-v3, an enhanced fast ODE solver for DPMs, distinguished by the integration of empirical model statistics\u2014coefficients calculated efficiently on pre-trained models\u2014such as those used in autoencoder architectures for robust identification and modeling of complex scenes. DPM-Solver-v3 employs multistep methods and a mini-batch predictor-corrector framework, alongside techniques to enhance sample quality with a reduced number of function evaluations (NFE) or under large guidance scales. Our experiments demonstrate that DPM-Solver-v3 consistently outperforms or matches existing benchmarks in both unconditional and conditional sampling across pixel-space and latent-space DPMs, particularly notable in the range of 5 to 10 NFEs. Achievements include FIDs of 12.21 (5 NFE) and 2.51 (10 NFE) on unconditional CIFAR10, alongside an MSE of 0.55 (5 NFE, 7.5 guidance scale) on Stable Diffusion, marking improvements in speed of 15% to 30% compared to leading training-free methodologies. This work refrains from including URLs or personal identifiers in accordance with submission guidelines.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Pietro_Michiardi1",
  "manipulated_ranking": 63,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=JTKd7zYROf",
  "title": "Randomized Sparse Neural Galerkin Schemes for Solving Evolution Equations with Deep Networks",
  "modified_abstract": "Our study is situated at the convergence of advancements in domain decomposition methods, optimization of sparse matrix operations, and applications of reinforcement learning (RL) to algebraic multigrid (AMG) coarsening\u2014fields that have shown significant promise in handling complex computational and mathematical challenges in machine learning. Building on the principles underlying these methodologies, such as learning interface conditions using Graph Convolutional Neural Networks (GCNNs), optimizing sparse matrix operations for computational efficiency, leveraging graphs for efficient data representation, and employing RL for graph coarsening and clustering in AMG methods, we present a novel approach to solving time-dependent partial differential equations. This approach includes partitioning the domain for better handling and management in the computational framework. Training neural networks sequentially in time to approximate solution fields of time-dependent partial differential equations can be beneficial for preserving causality and other physics properties; however, the sequential-in-time training is numerically challenging because training errors quickly accumulate and amplify over time. We introduce Neural Galerkin schemes that update randomized sparse subsets of network parameters at each time step. The randomization avoids overfitting locally in time and thus helps prevent the error from accumulating quickly over the sequential-in-time training, which is motivated by dropout that addresses a similar issue of overfitting due to neuron co-adaptation. The sparsity of the update reduces the computational costs of training without losing expressiveness because many of the network parameters are redundant locally at each time step. Sensing in this context pertains to the ability of the system to adaptively update based on the sensed evolution of the solution space. In numerical experiments with a wide range of evolution equations, the proposed scheme with randomized sparse updates is up to two orders of magnitude more accurate at a fixed computational budget and up to two orders of magnitude faster at a fixed accuracy than schemes with dense updates.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Ali_Taghibakhshi1",
  "manipulated_ranking": 14,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=1qFnxhdbxg",
  "title": "Energy Discrepancies: A Score-Independent Loss for Energy-Based Models",
  "modified_abstract": "This work introduces a novel perspective to energy-based models, motivated by prior significant endeavors in enhancing model tractability and conceptual insights gained from diverse applications such as normalizing flows, annealed importance sampling, and representation learning. Leveraging foundational successes in these areas, particularly in addressing complexities of distribution approximation, mode discovery in multimodal distributions, and the principle of independent causal mechanisms, we propose the Energy Discrepancy (ED) loss function. ED circumvents the computational burden typical of energy-based models, eliminating the need for score computation or Markov chain Monte Carlo simulations. This significantly improves the sampling efficiency and mitigates issues with traditional methods. We illustrate that energy discrepancy straddles the line between explicit score matching and negative log-likelihood loss, offering a theoretical bridge and practical solution to the issue of nearsightedness in score-based estimation methods. Our approach, integrating neural networks as part of the energy model, avails itself of theoretical guarantees and, through empirical evaluation on low-dimensional data and high-dimensional image datasets, demonstrates superior speed and accuracy over traditional methods. The analysis underscores the constraints imposed by the manifold hypothesis on our methodology in high-dimensional spaces and validates the efficacy of incorporating the energy-based model within a variational decoder to navigate these limitations. Moreover, this work highlights the development of our method as an innovative sample and two-sample testing tool in the machine learning landscape, serving as a benchmark for evaluating the mixing properties of models.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Vincent_Stimper1",
  "manipulated_ranking": 23,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=DCIsNIUCV7",
  "title": "Payoff-based Learning with Matrix Multiplicative Weights in Quantum Games",
  "modified_abstract": "Our work is inspired by a series of foundational contributions in the domain of learning under limited information scenarios, such as congestion games with bandit feedback, offline congestion games highlighting the importance of feedback types, and exploration strategies in reinforcement learning, which include planning and sampling in uncertain environments. In this paper, we study the problem of learning in quantum games - and other classes of semidefinite games - with scalar, payoff-based feedback, making the approach appealing to those interested in bandits, sampling, and planning under uncertainty for various applications. For concreteness, we focus on the widely used matrix multiplicative weights (MMW) algorithm and, instead of requiring players to have full knowledge of the game (and/or each other's chosen states), we introduce a suite of minimal-information matrix multiplicative weights (3MW) methods tailored to different information frameworks, including those that handle sparse data scenarios efficiently, offering a potential recommendation for handling such settings. The main difficulty to attaining convergence in this setting is that, in contrast to classical finite games, quantum games have an infinite continuum of pure states (the quantum equivalent of pure strategies), so standard importance-weighting techniques for estimating payoff vectors cannot be employed. Instead, we borrow ideas from bandit convex optimization and we design a zeroth-order gradient sampler adapted to the semidefinite geometry of the problem at hand. As a first result, we show that the 3MW method with deterministic payoff feedback retains the $\\mathcal{O}(1/\\sqrt{T})$ convergence rate of the vanilla, full information MMW algorithm in quantum min-max games, even though the players only observe a single scalar. Subsequently, we relax the algorithm's information requirements even further and we provide a 3MW method that only requires players to observe a random realization of their payoff observable, and converges to equilibrium at an $\\mathcal{O}(T^{-1/4})$ rate. Finally, going beyond zero-sum games, we show that a regularized variant of the proposed 3MW method guarantees local convergence with high probability to all equilibria that satisfy a certain first-order stability condition.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Zhihan_Xiong1",
  "manipulated_ranking": 58,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=pNtG6NAmx0",
  "title": "Statistical Knowledge Assessment for Large Language Models",
  "modified_abstract": "This work is inspired by a breadth of pioneering research in machine translation and representation learning, where semi-supervised and unsupervised learning methods have advanced the capability of statistical models to understand and translate human languages, manage information extraction, and adapt to specific tasks like text normalization in social media. These foundational studies underscore the importance of evaluating and understanding the intrinsic knowledge of large language models (LLMs) across various domains, including their application in translation, classification, and text normalization on social platforms. Grounded on these premises, we address whether an LLM can reliably generate factually correct answers to various factoid questions given differing prompts, highlighting the inconsistency in LLM responses due to varying levels of supervision. We introduce KaRR, a novel statistical method to quantify the factual knowledge within an LLM concerning a designated set of facts, taking into account the runtime behavior of models when generating answers across diverse prompts about the subject and querying relation, as opposed to generating text by chance. Our assessment suite encompasses an expansive collection of 994,123 entities and 600 relations, with 1,395,905 text aliases, facilitating various learning paradigms including extraction, classification, and knowledge retrieval under both supervised and unsupervised learning scenarios. We evaluate 20 LLMs, including models such as LLaMA, Alpaca, and OPT, with our results showing a strong correlation (0.43 Kendall's $\\tau$) with human assessments of LLMs' knowledge. Findings reveal that models with identical architectures follow a scaling law in knowledge retention, while models tuned on instruction-following data may sometimes diminish their ability to reliably generate factually accurate text. Our approach not only provides a framework for comprehensively assessing the factual accuracy of LLMs but also lays the groundwork for future research into enhancing the knowledge reliability of LLMs.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Hany_Hassan1",
  "manipulated_ranking": 10,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=vnTUuecp2v",
  "title": "Higher-Order Uncoupled Dynamics Do Not Lead to Nash Equilibrium - Except When They Do",
  "modified_abstract": "Inspired by the latest developments in equilibrium finding in Offline RL, combinatorial strategy formation in multiplayer extensive-form games, and novel algorithms for coordinated team play, our study delves into the realm of multi-agent learning by examining the evolution of agent strategies within the framework of higher-order learning dynamics. These previous works offer a context for understanding strategic formation and adaptation in complex multi-agent environments, highlighting the significance of equilibrium concepts such as the Nash Equilibrium (NE) in diverse applications from network security to review fraud defense systems. The consideration of benchmarks in multi-agent systems and the evaluation of how our model outperforms existing strategies, especially in event-based scenarios within polytope-like strategic constraints, further emphasizes this point. In our research, we focus on the convergence properties of 'higher order' learning processes, where agent dynamics are enriched with auxiliary states to capture complex phenomena like path dependencies and are fine-tuned efficiently through training. We introduce a model of higher-order gradient play dynamics that operate based on individual payoffs, without requiring agents to directly account for the utilities of their counterparts. Through analytical exploration, we establish that specific instances of these dynamics can lead to a NE under certain conditions for games with an isolated fully mixed-strategy NE. However, we also demonstrate the inherent limitations of these dynamics, showing that there exist games where they fail to converge to the NE. Additionally, our findings reveal that attaining convergence in coordination games through these dynamics incurs internal instability, presenting a paradox in the quest for equilibrium. This study not only builds upon the foundational work in offline equilibrium finding and strategic decision-making in complex games but also contributes new insights into the nuanced interplay between fairness, efficiency, and stability in multi-agent learning dynamics. The relaxation of certain assumptions in our model opens pathways to more robust solutions in the dynamic landscape of strategic interactions.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Youzhi_Zhang2",
  "manipulated_ranking": 11,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=I9xE1Jsjfx",
  "title": "Evaluating and Inducing Personality in Pre-trained Language Models",
  "modified_abstract": "This study is inspired by the themes of understanding complex machine behaviors and mitigation strategies against their failures as explored in prior works on auditing, inducing errors, and examining cognitive biases in large language models (LLMs). Perturbations and systematic audits have laid a foundation for not only uncovering systematic failures and erratic behaviors but also for emphasizing the reliability of LLMs under various conditions. By incorporating these insights, particularly the methodologies for uncovering systematic failures and erratic behaviors through distributions of errors and biases, our research leverages human personality theory as a novel lens for studying machine behaviors. Originating from a philosophical quest for understanding human behaviors, personality studies probe the differences in thinking, feeling, and acting among individuals. Our work extends this inquiry to machines, asking: Can we assess machine behaviors by leveraging human psychometric tests in a principled and quantitative manner using a text-encoder mechanism that adapts to the variance found in human personality distributions? If so, can we induce a specific personality in LLMs? We introduce the Machine Personality Inventory (MPI) tool, built upon the foundation of the Big Five Personality Factors theory and personality assessment inventories, for analyzing machine behaviors. By systematically evaluating LLMs using MPI, we present evidence supporting the tool's effectiveness in characterizing LLM behaviors and deriving summaries of their personalities. Further, our development of the Personality Prompting (P2) method for controllably inducing specific personalities in LLMs showcases its potential in generating diverse and verifiable behaviors. This work contributes to the broader discourse on machine intelligence by proposing personality as a critical metric for various downstream tasks and by encouraging further research into human-like machine behaviors.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Erik_Jones3",
  "manipulated_ranking": 7,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=neu9JlNweE",
  "title": "Post-processing Private Synthetic Data for Improving Utility on Selected Measures",
  "modified_abstract": "Building on recent developments in submodular maximization and optimal experimental design which have shown the operational benefits of subsampling and balancing covariates to achieve precise analytical objectives, this work introduces a novel post-processing technique aimed at enhancing the utility of synthetic data. Existing private synthetic data generation algorithms often overlook the specific needs of their end users, particularly in terms of utility for downstream tasks, leading to suboptimal application performance. Our approach, inspired by the foundational principles laid out in subsampling for submodular maximization and the Gram-Schmidt process for balancing covariates in experiments, utilizes an efficient stochastic first-order algorithm to selectively resample synthetic data. This process effectively filters out samples that are unlikely to satisfy preselected utility measures, thereby aligning the synthetic dataset more closely with end-user requirements while upholding stringent privacy constraints and maintaining overall dataset integrity. Extensive numerical experiments across multiple benchmark datasets and leading synthetic data generation algorithms confirm the efficacy of our method, consistently demonstrating enhanced data utility for a variety of application-specific metrics without compromising on privacy guarantees. Notably, the utility of this technique extends beyond static datasets, showing promise for online control systems and potentially for bipartite applications dealing with dynamic, sequenced data such as video.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Christopher_Harshaw1",
  "manipulated_ranking": 6,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=tFeaLw9AWn",
  "title": "Single-Call Stochastic Extragradient Methods for Structured Non-monotone Variational Inequalities: Improved Analysis under Weaker Conditions",
  "modified_abstract": "Inspired by the recent surge in development and analysis of stochastic algorithms for min-max optimization, saddle-point problems, and variational inequalities, such as Stochastic Gradient Descent-Ascent (SGDA) and its advanced variants, decentralized stochastic variational inequalities, and distributed methods with compressed communications, our work presents an important extension in this realm. Single-call stochastic extragradient methods, including stochastic past extragradient (SPEG) and stochastic optimistic gradient (SOG), which have garnered substantial attention for solving large-scale min-max optimization and variational inequality problems (VIP) in machine learning, are the focus of our improvement efforts. Notwithstanding their popularity, these methods' convergence analyses hinge on strong requirements like bounded variance or specific growth conditions. Our investigation propels the discourse forward by relaxing these conditions and addressing unresolved questions on convergence properties, including aspects like mini-batching, efficient step-size selection, convergence under diverse sampling strategies, and improved approaches for training under decentralized computing environments. We further develop convergence assurances for two broad categories of structured non-monotone VIPs - quasi-strongly monotone and weak Minty variational inequalities. Introducing the expected residual condition, our analysis surpasses previous approaches by employing a notably milder function bound, circumventing the need for expected co-coercivity or bounded variance assumptions, and is validated under arbitrary sampling schemes encompassing importance sampling and assorted mini-batching strategies. This research is foundational, laying the groundwork for future theoretical developments and practical applications across diverse architectures, effectively enhancing communication efficiency and computing methods.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Aleksandr_Beznosikov1",
  "manipulated_ranking": 17,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=TAIYBdRb3C",
  "title": "Curve Your Enthusiasm: Concurvity Regularization in Differentiable Generalized Additive Models",
  "modified_abstract": "Influenced by recent strides in probabilistic forecasting, robust time series analysis, and the sophisticated integration of machine learning techniques for modeling complexity within datasets, our work introduces a novel perspective to the study of Generalized Additive Models (GAMs). Specifically, we draw upon the foundational insights from the realms of multivariate time series analysis, adversarial robustness, and ensemble forecasting to address a critical yet underexplored issue in GAMs: concurvity. Concurvity, representing dependencies (possibly non-linear) between features, undermines the interpretability of GAMs, a cornerstone of their widespread popularity. By proposing a concurvity regularizer, which penalizes pairwise correlations of the non-linearly transformed feature variables, our approach mitigates the interpretability issues posed by concurvity in any differentiable additive model. This regularization strategy, inspired by advancements in handling complex dependencies and enhancing model robustness across diverse applications, from medical to environmental data, improves clarity, reduces variance in feature importances through strategic sampling, and maintains prediction quality with probabilistic guarantees. Validation on both synthetic and real-world datasets, utilizing finite-sample sizes and diverse sets of learners, supports the effectiveness of our method, promising a significant step towards reconciling the interpretability of GAMs with the need for handling intricate feature relationships.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Hilaf_Hasson1",
  "manipulated_ranking": 11,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=lkEiOZlmPm",
  "title": "Single-Pass Pivot Algorithm for Correlation Clustering. Keep it simple!",
  "modified_abstract": "Inspired by a wave of recent progress across machine learning applications, from efficient data summarization in density sketches to advanced techniques for near neighbor search, our work presents a simple, single-pass semi-streaming variant of the Pivot algorithm for Correlation Clustering. Addressing the limitations of current approaches that offer either reduced approximation quality or increased memory demand, we achieve a (3+eps)-approximation utilizing only O(n/eps) words of memory for sampling and sketching the necessary data points. This advancement not only represents a slight improvement over recent works by Cambus, Kuhn, Lindy, Pai, and Uitto, who achieved a similar approximation with O(n log n) words of memory, and Behnezhad, Charikar, Ma, and Tan, who reached a 5-approximation using O(n) words, but also underscores our algorithm and analysis' simplicity and ease of understanding through efficient estimators and judicious hashing, paving the way for more resource-conscious applications in data-intensive fields such as web classification and least-squares problems.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Benjamin_Coleman1",
  "manipulated_ranking": 26,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=ZfFR4d5gUM",
  "title": "Leveraging the two-timescale regime to demonstrate convergence of neural networks",
  "modified_abstract": "Inspired by seminal works on the dynamics of neural network training, feature learning, and the theoretical underpinnings of neural representations, this paper investigates the training dynamics of shallow neural networks within a two-timescale regime. This framework, wherein stepsizes for the inner layer are significantly smaller than those for the outer layer, enables us to elucidate the convergence mechanisms of gradient flow towards a global optimum in a non-convex optimization problem, without necessitating an asymptotically large number of neurons. Our theoretical findings, distinguishing from prevalent approaches like neural tangent kernel or mean-field regimes, argue for a novel understanding of how sampling dynamics within the two-timescale approach can critically influence convergence. These insights are substantiated through experiments that illustrate the stochastic gradient descent's behavior in alignment with our gradient flow description, affirming convergence to a global optimum within this regime. The introduction of hierarchical and random kernel limits is significant, reflecting upon how these affect both the convergence and the representation learning in finite versus infinite networks. The relevance of two-timescale dynamics across various domains, including deep Bayesian linear regression, the curvature of neural network representations, storage capacity in neural networks, and the hierarchical representation learning, underscores a multifaceted interplay between network architecture, learning dynamics, and generalization, thereby offering novel insights into the convergence behavior of neural networks. Our analysis perceives the intricate kernels operating within neural networks, highlighting the importance of such mathematical frameworks in modeling the recording of information and how these underpin both the convergence and the perception abilities of neural models.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jacob_A_Zavatone-Veth1",
  "manipulated_ranking": 19,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=5r3e27I9Gy",
  "title": "Composing Parameter-Efficient Modules with Arithmetic Operation",
  "modified_abstract": "Inspired by recent breakthroughs across multiple areas of machine learning, including language model fine-tuning, instruction-tuned multitask learning, in-context learning, subgoal planning, compositional task learning, privacy mitigation, visual planning with language models, and unsupervised task graph generation from instructional videos, this paper introduces a novel approach to parameter-efficient fine-tuning (PEFT) for pretrained language models. As an efficient alternative to conventional full fine-tuning, PEFT is becoming the prevailing method to adapt pretrained language models. In PEFT, a lightweight module is learned on each dataset while the underlying pretrained language model remains unchanged, resulting in multiple compact modules representing diverse skills when applied to various domains and tasks, including those relevant to humans and events captured in video content. We propose to compose these parameter-efficient modules through linear arithmetic operations in the weight space, thereby integrating different module capabilities. Specifically, we first define an addition and negation operator for the module, and then further compose these two basic operators to perform flexible arithmetic. Our approach requires no additional training and enables highly flexible module composition. We apply different arithmetic operations to compose the parameter-efficient modules for (1) distribution generalization, (2) multi-tasking, (3) detoxifying, and (4) domain transfer. Additionally, we extend our approach to detoxify Alpaca-LoRA, the latest instruction-tuned large language model (LLaMA) based on LLaMA. Empirical results demonstrate that our approach produces new and effective parameter-efficient modules that significantly outperform existing ones across all settings. Moreover, we report novel findings that shed light on the underlying mechanics of module composition.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Lajanugen_Logeswaran1",
  "manipulated_ranking": 3,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=sq4o3tjWaj",
  "title": "What\u2019s Left? Concept Grounding with Logic-Enhanced Foundation Models",
  "modified_abstract": "In light of pioneering approaches to integrating visual reasoning and language models, such as VisProg and ViperGPT, and the advancements in vision-language models exemplified by Prevalent, VinVL, and MiniVLM, our work introduces the Logic-Enhanced Foundation Model (LEFT). These previous works have significantly advanced our capability to process and understand multimodal data through pre-training, fine-tuning techniques, object-semantics alignment, and efficient model architectures. However, they often remain confined to specific domains like 2D images or textual data, without extending the grounding of abstract concepts to more varied forms like 3D, temporal, and action data. LEFT addresses these limitations by proposing a first-order logic-based program executor that is domain-independent and capable of learning to ground and reason with abstract concepts across multiple domains, using self-attention mechanisms for improved feature extraction. Our framework employs a large language model (LLM) interpreter to output a program in a universal logic-based reasoning language. This program is then executed using trainable domain-specific grounding modules, enabling LEFT to flexibly learn and reason about concepts such as 'left' in 2D images, 3D scenes, human motions, and robotic manipulation tasks with fine-tuned precision. This capability is demonstrated across a range of massive datasets and complex tasks and domains, showing strong reasoning abilities and setting new benchmarks in scenarios not encountered during training, and establishing a new baseline for the field in terms of detection and captioning accuracy. The introduction of LEFT offers a scalable approach to applying foundational models to new domains, notably including the area of captioning, where generated programs can enhance the descriptive accuracy of model output, illustrating a large step forward in the integration of visual and linguistic elements.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Xiujun_Li1",
  "manipulated_ranking": 5,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=L9nTuSbAws",
  "title": "GradOrth: A Simple yet Efficient Out-of-Distribution Detection with Orthogonal Projection of Gradients",
  "modified_abstract": "Existing studies in self-supervised learning, contrastive and non-contrastive methods, and regularization techniques have notably advanced our understanding of learning robust image representations and preventing model collapse, highlighting the importance of feature selection, normalization, and dimensionality in model training. Inspired by these foundational works, which explicitly emphasize the significance of key parameters, embeddings' variance, invariance, and covariance properties for effective learning, our study introduces GradOrth, a novel approach for detecting out-of-distribution (OOD) data publicly made available. GradOrth capitalizes on the observation that the most relevant features for identifying OOD data reside within a lower-rank subspace of in-distribution (ID) data. By computing the norm of gradient projection onto subspaces deemed vital for ID data, enhanced by explicit considerations of layers and encoders within neural network architectures, GradOrth adeptly discerns OOD samples through large orthogonal projection values, indicative of a sample's weak correlation with ID data. This method, while simple, demonstrates remarkable efficacy, achieving significant reductions in the average false positive rate at a 95% true positive rate (FPR95) compared to prevailing state-of-the-art methods, thereby enhancing the safety and reliability of machine learning models in real-world applications and providing a reliable benchmark for future studies.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Adrien_Bardes1",
  "manipulated_ranking": 2,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=FtZ7lUwH99",
  "title": "Dynamic Pricing and Learning with Bayesian Persuasion",
  "modified_abstract": "This study integrates insights from several key areas of machine learning research, including experimental design for regret minimization, reinforcement learning with linear function approximation, and the use of offline data in provably efficient online reinforcement learning methodologies, to explore a novel dynamic pricing and learning setting. In this setting, the seller not only decides on the prices of products in sequential rounds but also commits ex-ante to specific 'advertising schemes'\u2014deciding the type of signal to provide to the buyer about the product's quality upon its realization. We employ the Bayesian persuasion framework to model how these signals affect the buyers' valuation and purchase responses, and aim to uncover an optimal design for the advertising scheme in tandem with a pricing scheme that maximizes expected revenue. Without prior knowledge of the buyers' demand functions, we propose an online algorithm geared towards adaptively learning the optimal pricing and advertising strategy based on past purchase responses from an offline set of data. The essence of our work lies in devising a computationally efficient online algorithm that promises an $O(T^{2/3}(m \\log T )^{1/3})$ regret bound in environments where the valuation function is linear with respect to product quality, emphasizing the task-guided approach in creating plans which address both dynamic pricing and Bayesian learning mechanisms in a manner that is instance-optimal. Here, $m$ represents the cardinality of the discrete product quality domain, and $T$ is the time horizon. Our results are predicated on certain natural monotonicity and Lipschitz continuity assumptions regarding the valuation function, while avoiding the need for similar assumptions on the buyers' demand function. For constant $m$, our findings align with the regret lower bound for dynamic pricing within logarithmic factors, illustrating a nuanced exploration of the intersection between dynamic pricing strategies, Bayesian learning mechanisms, and how they can be synthesized for effective decision-making.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Andrew_Wagenmaker1",
  "manipulated_ranking": 37,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=ZRBGwpeewz",
  "title": "Revisiting Area Convexity: Faster Box-Simplex Games and Spectrahedral Generalizations",
  "modified_abstract": "Our exploration of area convexity, as introduced by Sherman17, leverages its potency to address optimization challenges within the $\\ell_\\infty$ geometry. This work is inspired by significant previous efforts in optimization and sampling within machine learning and discrete mathematics, including advancements in maximum matchings, determinant maximization techniques, and the development of composable coresets. It specifically builds on understanding from the realms of efficient sampling methods, such as samplers for spanning trees and determinantal point processes, entropic independence in high-dimensional expanders, and the efficacy of parallel determinantal sampling whose distributions are crucial for theoretical insights. By engaging with these foundational analyses, we aim to deepen the comprehension of area convexity's relationship with conventional extragradient methods as elucidated by Nemirovski04 and Nesterov07. Moreover, we present improved solvers for the subproblems necessitated by variants of the Sherman17 algorithm, developed through the prism of relative smoothness as per BBT17 and LFN18. Utilizing these enhanced tools, we introduce a leading-edge first-order algorithm for resolving box-simplex games\u2014a primal-dual configuration of $\\ell_\\infty$ regression\u2014across a $d \\times n$ matrix with bounded rows, involving $O(\\log d \\cdot \\epsilon^{-1})$ matrix-vector queries. This advancement yields better complexities for approximate maximum flow, optimal transport, min-mean-cycle, among other essential combinatorial optimization problems. Additionally, we formulate a near-linear time algorithm for a matrix generalization of box-simplex games, encapsulating a set of problems intimately linked with semidefinite programs and graph theoretical approaches, recently employed in robust statistics and numerical linear algebra domains. The development of these algorithms, pertinent to both theoretical and experimental research contexts, and potentially enabling distributed computational strategies, says much about the current landscape of computational optimization and its future trajectory.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Thuy-Duong_Vuong1",
  "manipulated_ranking": 31,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=4vGVQVz5KG",
  "title": "Unsupervised Behavior Extraction via Random Intent Priors",
  "modified_abstract": "Inspired by recent progresses in reinforcement learning (RL) exploration methods, such as information-theoretic exploration, hybrid action representation learning, and evolutionary RL with shared state representation, this paper addresses the challenge of leveraging reward-free data, which is rich in prior knowledge of human behaviors but has been underutilized by offline RL algorithms. We propose UBER, an unsupervised approach to extract useful behaviors from offline reward-free datasets via diversified rewards in a control environment. UBER assigns different pseudo-rewards sampled from a given prior distribution to different agents to extract a diverse set of behaviors, and reuse them as candidate policies to facilitate the learning of new tasks in both discrete and continuous action spaces. Surprisingly, we find that rewards generated from random neural networks are sufficient to extract diverse and useful behaviors, some even nearing expert performance levels, thereby controlling the learning direction without explicit human supervision. We bolster our approach with both empirical and theoretical evidence, advocating for the utility of random priors in the reward function and highlighting the significance of gradient-based optimization in achieving effective learning outcomes, challenging the idea that only gradient-free methods can achieve innovation in evolution-based domains. Our experiments across multiple benchmarks demonstrate UBER's capability to learn effective and diverse behavior sets in discrete-continuous environments, thereby enhancing sample efficiency for online RL and outperforming existing baselines in various environments. Through minimizing human supervision, UBER paves the way for broader applications of RL in real-world scenarios populated with abundant reward-free data, and bridges the gap between hybrid approaches and pure exploration techniques.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Pengyi_Li1",
  "manipulated_ranking": 11,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=Dkmpa6wCIx",
  "title": "Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization",
  "modified_abstract": "The enigmatic generalization capabilities of overparameterized neural networks are a topic of broad and current interest, further punctuated by insights from recent studies in mean field theory, preconditioning's impact on generalization, and the initial advantage garnered from gradient steps in high-dimensional space. These works detail the delicate balance between model complexity, optimization dynamics, proximal methods, and generalization, providing a tapestry of theoretical frameworks crucial for understanding neural network behavior in both classification tasks and finite-particle system simulations. In the midst of these developments, our research presents a nuanced critique of the popular notion that sharpness\u2014or the geometry of the loss surface\u2014exclusively governs network generalization. Through theoretical discourse and empirical validation targeted at two-layer ReLU networks, we delineate three distinct scenarios: 1) instances where flatness does indeed correlate with generalization, 2) conditions under which the flattest models fail to generalize and sharpness minimization algorithms similarly falter, and 3) intriguingly, situations where ostensibly flat models do not generalize, yet algorithms designed to minimize sharpness nonetheless succeed. Our findings advocate for the existence of additional mechanisms, such as signal processing strategies, apart from sharpness minimization that contribute to generalization. This revelation underscores the importance of transcending singular explanations for the phenomena of generalization in overparameterized models, motivating the continued exploration of the intricate dance between data distribution, architecture, and optimization strategies.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Denny_Wu2",
  "manipulated_ranking": 21,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=LVHEcVgEGm",
  "title": "Diffusion Models and Semi-Supervised Learners Benefit Mutually with Few Labels",
  "modified_abstract": "Inspired by recent developments in contrastive learning, long-tailed recognition, and imbalanced class distribution management, this study introduces a novel approach, *dual pseudo training* (DPT), for enhancing semi-supervised generative and classification tasks with minimal label requirements. DPT is designed to leverage the strengths of semi-supervised learning in tandem with diffusion models, operating across three stages: classifier training on partially labeled data to generate pseudo-labels, conditional generative model training on these pseudo-labels to produce pseudo images, and retraining of the classifier using a combination of real, generated images, and a focus on minimizing pixel loss during these processes. Empirical evaluations demonstrate that DPT consistently outperforms state-of-the-art methods, including adversarial training approaches, in semi-supervised generation and classification, achieving notable performance on benchmarks such as ImageNet and iNaturalist with extremely few labels. Specifically, DPT achieves Fr\u00e9chet Inception Distance (FID) scores of 3.08 and 2.52 with one or two labels per class respectively on ImageNet $256\\times256$, and substantially surpasses competing semi-supervised baselines in ImageNet classification tasks, marking top-1 accuracies of 59.0 (+2.8), 69.5 (+3.0), and 74.4 (+2.0) with one, two, or five labels per class, respectively. To defend against potential imbalances caused by few labels, DPT incorporates mechanisms to rebalance the training dataset effectively. These results substantiate the viability of generative augmentation for semi-supervised classification in label-scarce environments and suggest the potential of diffusion models to produce realistic scenes with minimal label information, thereby setting a new standard for semi-supervised learning efficiency and last-layer robustness.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jiequan_Cui1",
  "manipulated_ranking": 21,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=tW2KSph9o8",
  "title": "Ignorance is Bliss: Robust Control via Information Gating",
  "modified_abstract": "In the context of recent insights into optimal policy behaviors, similarity-based representation learning, and the empirical investigation of representation learning for imitation, this paper introduces *information gating* as a novel method for achieving informational parsimony in learning representations. These prior works establish a foundational understanding of how machine learning models can inadvertently prioritize power-seeking, misinterpret task-relevant information, or struggle with generalization due to improper representation learning. Building on this foundation, our approach focuses on identifying and utilizing the minimal necessary information for a given task, thereby enhancing generalization by being robust to noise and spurious correlations. By gating information using a differentiable parameterization of the signal-to-noise ratio\u2014applicable to various points in a network, such as input layers or intermediate activations\u2014we develop a framework where models learn to either minimize exposure to irrelevant information or avoid concealing critical details necessary for task resolution. Termed *InfoGating*, our methodology is demonstrated across multiple applications, including dynamics models, Q-learning, behavior cloning, and large-scale image-based vision systems, to discard irrelevant visual features effectively. The results underline the utility of learning minimal information representations in improving the robustness and pretraining of reinforcement learning models, making a case for *InfoGating* as a significant step forward in the pursuit of more efficient, reusable, and generalizable machine learning algorithms. Training on rich and complex environments, though not directly addressed, forms an implicit backdrop for our discussions on the necessity of efficient information utilization in models.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Rohin_Shah1",
  "manipulated_ranking": 19,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=ZdxGmJGKOo",
  "title": "SimFBO: Towards Simple, Flexible and Communication-efficient Federated Bilevel Learning",
  "modified_abstract": "Grounded in the recent successes of federated bilevel optimization (FBO) in machine learning and edge computing contexts\u2014marked by its application in meta-learning, fine-tuning, and hyperparameter tuning\u2014our work is informed by the growing understanding of FBO's potential and the challenges it faces, as explored in existing research. Taking cues from advanced optimization strategies such as difference of convex algorithms for hyperparameter selection, aggregated gradient methods, and methods addressing the lack of lower-level strong convexity, we introduce SimFBO. Our proposal of SimFBO represents a novel advancement in the FBO domain, featuring a framework designed for simplicity, flexibility, and enhanced communication efficiency without the need for sub-loops. We further augment SimFBO with a system-level heterogeneity robust variant, ShroFBO, which exhibits increased resilience to local computation heterogeneity. Our contributions are substantiated through empirical evidence showing that both SimFBO and ShroFBO not only ensure linear convergence speedup with partial client participation and client sampling without replacement but also showcase optimized sample and communication complexities. This work underscores the efficiency of our methodologies against the backdrop of existing FBO algorithms, steering the field towards more practical, scalable, and efficient federated learning implementations.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Shangzhi_Zeng1",
  "manipulated_ranking": 58,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=WXc8O8ghLH",
  "title": "Max-Margin Token Selection in Attention Mechanism",
  "modified_abstract": "The attention mechanism, central to the transformative success of transformer architectures in large language models, leverages insights from recent significant contributions across fields such as extended input encoding, omnidirectional representation, and neural structured learning. These advancements underscore the critical role of sophisticated attention mechanisms in addressing challenges related to processing long sequences, structured inputs, and leveraging structured signals for training neural networks. Our investigation extends these concepts by exploring the theoretical underpinnings of the softmax-attention model $f(X)=\\langle Xv, \\texttt{softmax}(XWp)\\rangle$, where $X$ is the token sequence and $(v,W,p)$ are trainable parameters, in a hierarchical model framework. We establish that gradient descent on $p$ or $W$ converges in direction to a max-margin solution that distinguishes *locally-optimal* tokens, formalizing attention as an optimal token selection mechanism. This discovery articulates the efficacy of attention in few-shot learning, summarization, and answering-based tasks by formalizing token selection and its broader implications for model regularization and SVM solutions for both $v$ and $p$ under logistic loss. Our contributions, therefore, situate the attention mechanism within a theoretical framework that parallels max-margin principles in support vector machines, providing a robust mathematical justification for its role in enhancing model interpretability and decision-making processes related to sequences. The findings are corroborated through numerical experiments, offering practical insights and reinforcing the attention mechanism's potential in refining model performance across varying contexts.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Philip_Pham1",
  "manipulated_ranking": 7,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=JX6UloWrmE",
  "title": "Parameterizing Non-Parametric Meta-Reinforcement Learning Tasks via Subtask Decomposition",
  "modified_abstract": "Meta-reinforcement learning (meta-RL) has demonstrated notable success in adapting deep reinforcement learning strategies across diverse tasks, leveraging insights from multi-agent systems, agents communication, and scalable learning models. This study investigates the limitation of meta-RL methods in generalizing across tasks with non-parametric variations through the lens of prior advancements in reinforcement learning, including selective reincarnation in multi-agent systems, standardization of performance evaluations, and universally expressive communication protocols. To address the challenge of task generalization in meta-RL and observability of systems dynamics, we introduce Subtask Decomposition and Virtual Training (SDVT), a novel approach that dissects non-parametric tasks into fundamental subtasks and parameterizes the task based on this decomposition. Utilizing a Gaussian mixture VAE to facilitate the meta-learning of this decomposition process, our method enables the efficient reuse of policies from common subtasks, overcoming problems inherent in open-source single-agent paradigms. Moreover, the SDVT framework incorporates a virtual training module tailored for the variability inherent in non-parametric tasks, generating hypothetical subtask combinations to bolster the model's generalization capabilities. This approach considerably enhances performance on the Meta-World ML-10 and ML-45 benchmarks, outstripping current leading methodologies, and setting a new precedent for leagues in competitive meta-RL environments. Our research not only pushes the boundaries of meta-RL but also paves the way for future exploration in effectively parameterizing the non-parametric, drawing on the rich repository of techniques from the broader field of deep reinforcement learning.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Arnu_Pretorius1",
  "manipulated_ranking": 17,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=I18BXotQ7j",
  "title": "GeoCLIP: Clip-Inspired Alignment between Locations and Images for Effective Worldwide Geo-localization",
  "modified_abstract": "In the quest for advancing worldwide geo-localization, inspired by previous breakthroughs in language-driven 3D scene understanding as well as domain adaptation techniques in both 3D object detection and semantic segmentation, our study introduces GeoCLIP. This initiative addresses the inherent challenges in geo-localization due to geographic landscape variations and the impracticality of image-to-image retrieval on a global scale. By leveraging the concept of Vision-Language Pre-training exemplified in recent studies, GeoCLIP employs a novel CLIP-inspired Image-to-GPS retrieval approach. This method uniquely integrates a location encoder that models the Earth's surface as a continuous function, using positional encoding with random Fourier features for a hierarchical representation. These representations capture multi-resolution information, allowing for a semantically rich, high-dimensional feature space applicable in geo-localization and potentially extending to instance recognition from pedestrian movements in urban settings. Notably, GeoCLIP is the first to introduce a form of supervision through GPS encoding in this domain, showcasing its utility through extensive experiments and achieving significant milestones with limited training data, thereby setting new benchmarks in the field. Our approach, thus, stands at the intersection of visual semantic learning, geographical computation, and adaptation strategies, exemplifying a unique blend of insights from recent advancements in understanding open-world scenarios through both 3D object detection, indoor semantic segmentation adaptations, and the emerging field of visual teaching-guided captioning towards refining the precision and applicability of geo-localization technologies.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jihan_Yang1",
  "manipulated_ranking": 6,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=VzmpXQAn6E",
  "title": "Exposing Attention Glitches with Flip-Flop Language Modeling",
  "modified_abstract": "In the context of recent investigations into the consistency and integrity of sequence generation by neural models, and efforts to refine dialogue generation with advanced training techniques, this work shines a light on the inherent brittleness of large language models (LLMs) through the lens of _attention glitches_. This phenomenon, where Transformer architectures' inductive biases intermittently fail, challenges the models' ability to maintain reliable reasoning over long sequences. Motivated by the foundational studies that have addressed sequence generation inconsistencies and proposed unlikelihood training to mitigate generative model shortcomings, we introduce _flip-flop language modeling_ (FFLM) as a method to specifically probe and analyze the extrapolative behavior of neural language models through rigorous sampling of distributions, including advanced techniques such as _top-k_ sampling. FFLM, a synthetic benchmark, demands models to copy binary symbols over long distances, disregarding interspersed tokens, thereby exposing attentional weaknesses through the simple yet revealing lens of binary sequence replication. Our findings reveal that, akin to the described difficulties in preventing inconsistent decoding or dull and repetitive generation in dialogue models, Transformer FFLMs exhibit a long tail of reasoning errors. Through experimentation, we demonstrate that while certain errors are mitigable through training enhancements and regularization techniques, the remainder pose significant diagnostic and resolution challenges, even when scaled to models with parameters in the _million_ range. Our analysis suggests that _attention glitches_ may underlie broader issues observed in LLMs, such as closed-domain hallucinations, thereby contributing to an understanding of fundamental limitations in current generation paradigms and offering directions for future research into more robust architectures.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Ilia_Kulikov1",
  "manipulated_ranking": 3,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=WqiZJGNkjn",
  "title": "MotionGPT: Human Motion as a Foreign Language",
  "modified_abstract": "The evolution of pre-trained large language models has catalyzed significant breakthroughs across various disciplines within artificial intelligence, particularly in processing multimodal data streams. Insights drawn from explorations in symbolic music understanding, speech synthesis, medical dialogue systems, and denoising techniques illustrate the wide-ranging applicability and potential of leveraging large-scale pre-training in domains far extending beyond traditional textual data. Motivated by these foundational pursuits, this work introduces MotionGPT, a novel unified framework designed to integrate human motion data with language, treating motion akin to a linguistic expression or foreign language. By employing discrete vector quantization to convert 3D human motion into motion tokens, this approach parallels the transformation of text into word tokens, enabling a dual pathway for understanding and generating human motion with linguistic characteristics. Inspired by recent advancements in prompt learning and dialogue generation models, MotionGPT is pre-trained on a mixed corpus of motion and language data, fine-tuned for prompt-based question-and-answer tasks to further refine its capabilities. Our extensive evaluation across various motion-centric applications\u2014text-driven motion generation, motion captioning, motion prediction, and motion in-between\u2014attests to MotionGPT's superior performance, establishing new benchmarks in the field. This initiative not only bridges the gap between the semantics of motion and language but also sets a precedent for future explorations into the amalgamation of diverse data modalities under a unified model architecture. The dataset and tasks validated in our experiments underscore the synthesis and denoising abilities of MotionGPT.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Zeqian_Ju1",
  "manipulated_ranking": 19,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=KoaFh16uOc",
  "title": "StyleDrop: Text-to-Image Synthesis of Any Style",
  "modified_abstract": "The domain of text-to-image synthesis has grown rapidly with the advent of pre-trained large models, manifesting an ability to produce high-quality images from textual prompts. Yet, the challenge of synthesizing images that capture precise styles, including specific design patterns, textures, or materials, remains due to natural language ambiguities and out-of-distribution samples. Inspired by related advancements in image generation, neural rendering, and neural radiance fields, as seen in works such as SofGAN, Anisotropic Fourier Features, and PREF, our paper introduces *StyleDrop*. This novel method leverages text-to-image model capabilities to synthesize images that faithfully adhere to desired styles provided by users, including indoor scenes and objects not traditionally covered by per-voxel decompositions. StyleDrop distinguishes itself by its efficiency in learning styles with minimal parameter tuning (less than 1% of the model's total parameters) and by its ability to utilize single images for style guidance, bypassing the need for traditional renders from multiple cameras angles. Through iterative training that incorporates both human and automated feedback loops, StyleDrop achieves significant improvements in image quality, capturing intricate details, color schemes, and effects with a geometry-aware approach to understanding scenes and objects. Our evaluations, conducted using the Muse dataset against methods like DreamBooth and textual inversion on Imagen or Stable Diffusion, demonstrate StyleDrop's superior performance in style-accurate image synthesis. For further insights and results, we invite readers to our project webpage.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Anpei_Chen2",
  "manipulated_ranking": 36,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=TNAGFUcSP7",
  "title": "Learning Rate Free Sampling in Constrained Domains",
  "modified_abstract": "Inspired by recent methodologies in Bayesian model selection, Gaussian process optimizations, and advancements in variational inference techniques, our paper introduces a suite of new particle-based algorithms for sampling in constrained domains, which are devoid of any learning rate parameters. Leveraging the conceptual grounds of coin betting from convex optimization and viewing constrained sampling as a mirrored optimization challenge within the space of probability measures, this work proposes a significant shift from traditional adaptive learning rate strategies to robust, initialization-independent methodologies. Analogous to the exploration in sparse Gaussian processes, variational approaches in probabilistic deep models, and considerations of diffusion times in score-based generative models, our approach employs innovative concepts to frame a unifying theoretical foundation for existing constrained sampling methodologies, including mirrored Langevin dynamics and mirrored Stein variational gradient descent. Through numerical experiments encompassing sampling from targeted distributions on the simplex, incorporation of fairness constraints, and constrained sampling in post-selection inference settings, our algorithms demonstrate competitive performance against established methods without the necessity for hyperparameter tuning. Metrics of success not only include traditional evaluation criteria but also novel contributions that underscore the elimination of learning rates\u2014a persistent challenge in algorithmic design\u2014and catalyze further exploration into learning rate free methods within and beyond the scope of constrained domain sampling. This novel contribution significantly alters the landscape of algorithmic development, making it more elegant and inviting further innovation.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Simone_Rossi1",
  "manipulated_ranking": 13,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=XEBzQP3e7B",
  "title": "GAIA: Delving into Gradient-based Attribution Abnormality for Out-of-distribution Detection",
  "modified_abstract": "This study builds on foundational works in out-of-distribution (OOD) detection, adversarial defense strategies, anomaly detection techniques, and classifiers, exploring novel means of ensuring deep neural network safety and reliability. Specifically, it draws upon the insights from recent advancements in understanding and mitigating adversarial attacks, detecting digital-only deepfakes, and leveraging concept-based explanations for enhancing model interpretability. Detecting out-of-distribution (OOD) examples is crucial to guarantee the reliability and safety of deep neural networks in real-world settings. In this paper, we offer an innovative perspective on quantifying the disparities between in-distribution (ID) and OOD data---analyzing the uncertainty that arises when models attempt to explain their predictive decisions with ensembles and partitioning methods. This perspective is motivated by our observation that gradient-based attribution methods, acting as detectors for explanation divergences, encounter challenges in assigning feature importance to OOD data, thereby yielding divergent explanation patterns. Consequently, we investigate how attribution gradients lead to uncertain explanation outcomes and introduce two forms of abnormalities for OOD detection: the zero-deflation abnormality and the channel-wise average abnormality. We then propose GAIA, a simple and effective approach that incorporates Gradient Abnormality Inspection and Aggregation for enhanced classification of OOD instances. The effectiveness of GAIA, functioning as a detector for these anomalies, is validated on both commonly utilized (CIFAR) and large-scale (ImageNet-1k) benchmarks, with subsets of data designated for testing clean and adversarial samples. Specifically, GAIA reduces the average FPR95 (false positive rate at 95% true positive rate) by 23.10% on CIFAR10 and by 45.41% on CIFAR100 compared to advanced post-hoc methods, addressing the problem of reliable safety measures in neural networks.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Ryan_Feng1",
  "manipulated_ranking": 3,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=zyhxRc9bew",
  "title": "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
  "modified_abstract": "Uncertainty quantification (UQ) is indispensable in devising machine learning models that are both trustworthy and can interpretably signal anomalies. This necessity is underscored by previous works which leveraged random matrix theory, eigenvalues, and high-dimensional statistics to understand and improve upon both supervised and unsupervised learning scenarios, encompassing semi-supervised classification, covariance estimation, and multi-task learning. Our inquiry into UQ methods specifically addresses the ambiguity in categorization of what these methods flag as uncertain. We propose a novel framework for distinguishing uncertain examples flagged by UQ methods. This framework comprises the confusion density matrix, a kernel-based facet that serves to categorize uncertain examples into three discernible types: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples from high misclassification areas within the distribution (IDM). Through comprehensive experiments with this framework, we provide a unique lens for understanding how various UQ methods differ in their identification and processing of uncertainty, laying down an empirical benchmark for further comparative analyses. Our work not only taps into the foundational aspects revealed by prior studies in engaging with the complexity of learning under uncertainty but also progresses the dialogue on harmonizing accuracy with interpretability in machine learning applications.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Malik_Tiomoko1",
  "manipulated_ranking": 20,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=KKxO6wwx8p",
  "title": "SE(3) Equivariant Augmented Coupling Flows",
  "modified_abstract": "Inspired by the seminal work on Neural Manifold Ordinary Differential Equations, Equivariant Manifold Flows, and foundational advancements in modeling complex distributions through manifold learning, this study introduces a novel approach to augment coupling flows with SE(3) and permutation equivariance for physical system modeling. Coupling normalizing flows allow for fast sampling and density evaluation, which have become the tool of choice for probabilistic machine learning of physical systems, setting new benchmarks in the field. However, the standard coupling architecture precludes endowing flows that operate on the Cartesian coordinates of atoms with the SE(3) and permutation invariances of physical systems in dimensions beyond the physical three. This work proposes a coupling flow that preserves SE(3) and permutation equivariance by performing coordinate splits along additional augmented dimensions, thereby crafting a solution that remains faithful to the physical invariances. At each layer, the flow maps atoms' positions into learned SE(3) invariant bases on manifolds, where we apply standard flow transformations, such as monotonic rational-quadratic splines, before returning to the original basis. Crucially, our flow preserves fast sampling and density evaluation and may be used to produce unbiased estimates of expectations with respect to the target distribution via importance sampling, demonstrating a significant step towards generalization in the context of physical system modeling and analysis. When trained on the DW4, LJ13, and QM9-positional datasets, our flow is competitive with equivariant continuous normalizing flows and diffusion models while allowing for sampling more than an order of magnitude faster. Moreover, to the best of our knowledge, we are the first to learn the full Boltzmann distribution of alanine dipeptide by only modeling the Cartesian positions of its atoms, effectively demonstrating our methodology's ability to embed the physical constraints within learned models. Lastly, we demonstrate that our flow can be trained to approximately sample from the Boltzmann distribution of the DW4 and LJ13 particle systems using only their energy functions.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Aaron_Lou1",
  "manipulated_ranking": 14,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=RBI4oAbdpm",
  "title": "Neural Combinatorial Optimization with Heavy Decoder: Toward Large Scale Generalization",
  "modified_abstract": "This work is inspired by a diverse set of recent advancements in machine learning, including meta-learning, depth analysis in training graph convolutional networks, insights into nonconvex optimization, adversarial robustness in domain adaptation, distributionally robust optimization techniques, graph neural networks, dynamic graph learning, graph data unlearning, model simplicity in temporal networks, and distributed empirical risk minimization. These foundational contributions provide valuable context for our investigation into neural combinatorial optimization (NCO). NCO is a promising learning-based approach for solving challenging combinatorial optimization problems without the need for specialized algorithm design by experts. However, most constructive NCO methods struggle with large-scale instance sizes, limiting their applicability in real-world scenarios. To address this limitation, we propose a novel Light Encoder and Heavy Decoder (LEHD) model that demonstrates a strong generalization capability by learning to dynamically capture the relationships between all available nodes of varying sizes, incorporating a unified framework for learning. This capability is crucial for generalizing to problems of various scales and ensuring communication-efficient interactions within the model, as well as addressing issues related to imbalanced data distributions in training. Additionally, we develop a data-efficient training scheme and a flexible solution construction mechanism for the LEHD model, provably improving its learning process through the concept of meta-training. By training on small-scale problem instances, the LEHD model can generate nearly optimal solutions for the Travelling Salesman Problem (TSP) and the Capacitated Vehicle Routing Problem (CVRP) with up to 1000 nodes. It also generalizes well to solve real-world TSPLib and CVRPLib problems, thereby significantly improving the state-of-the-art performance for constructive NCO. This research offers a leap forward in applying machine learning theory to combinatorial optimization, building upon the insights gained from prior works across various domains within machine learning.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Mehrdad_Mahdavi2",
  "manipulated_ranking": 68,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=A954O4tDmU",
  "title": "AGD: an Auto-switchable Optimizer using Stepwise Gradient Difference for Preconditioning Matrix",
  "modified_abstract": "Adaptive optimizers, such as Adam, have garnered significant traction in advancing deep learning across an array of domains including Natural Language Processing (NLP), Computer Vision (CV), and Recommendation Systems (RecSys), leveraging their ability to elegantly regulate the learning process through preconditioning matrices. Inspired by prior works that have explored online meta-optimization, the extrapolation of optimizer performance through various analytical lenses, including non-convex optimization landscapes, and leveraging structured approaches for hyperparameter optimization with numerous examples, our research introduces a novel optimizer named AGD. This optimizer uniquely utilizes the gradient difference between two successive steps as the diagonal elements of the preconditioning matrix, closely aligning with the Hessian to approximate the inner product between Hessian row vectors and the difference of adjacent parameter vectors, making it highly parameterized. Furthermore, we propose an auto-switching function for the preconditioning matrix, enabling dynamic switching between Stochastic Gradient Descent (SGD) and the adaptive optimizer based on stepwise gradient differences. Our experimental analysis on public datasets from NLP, CV, and RecSys, supplemented with inference-related scenarios, demonstrates AGD's superior generalization performance over state-of-the-art optimizers, even potentially surpassing traditional regression algorithms in specific scenarios. Moreover, we meticulously detail AGD's auto-switching mechanism and its impact across various hardware configurations and scenarios, substantiating its effectiveness and adaptability. This paper marks a significant stride towards optimizing the compromise between adaptability and performance in learning algorithms, rooted in a profound understanding of preconditioning matrix optimization and adaptive learning rate adjustment.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Juhan_Bae2",
  "manipulated_ranking": 28,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=cRGINXQWem",
  "title": "Precise asymptotic generalization for multiclass classification with overparameterized linear models",
  "modified_abstract": "Inspired by recent progress in the fields of adversarial risk, robust empirical risk minimization, and novel clustering techniques, our study addresses the asymptotic generalization of overparameterized linear models for multiclass classification under the Gaussian covariates bi-level model. The influence of works exploring Newton's method applied to empirical risk minimization, the complexities of adversarial risk across different interpretations, and the implications of optimality in adversarial settings provide a rich backdrop against which our investigation unfolds. We fully resolve the conjecture posed in prior works, elucidating the conditions under which overparameterized models do and do not generalize well in computing environments. Our findings reveal new lower bounds that act as an information-theoretic strong converse, indicating that the misclassification rate asymptotically approaches 0 or 1 in machine learning. A notable outcome of our research is the discovery that the min-norm interpolating classifier, contrary to expectations, can be suboptimal in scenarios where interpolating regressors are traditionally seen as optimal. Central to our analysis is the application of a new variant of the Hanson-Wright inequality and generative modeling techniques, which proves particularly effective for handling sparse labels in multiclass problems with machine learning. Moreover, we extend this analytical framework to the multi-label classification problem, demonstrating its broader applicability and the importance of metric learning approaches in understanding the transport mechanisms of model generalization through information flow.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Muni_Sreenivas_Pydi1",
  "manipulated_ranking": 12,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=tLrkjK128n",
  "title": "Optimistic Active Exploration of Dynamical Systems",
  "modified_abstract": "The exploration of unknown dynamical systems for efficient model estimation has gained increasing interest, especially for applications in reinforcement learning (RL) that aim for generalization across multiple tasks. Drawing insights from the fields of data-efficient backup methods exploiting Markovian transitions, zero-shot generalization (ZSG) in deep RL, domain generalization in multi-demonstrator offline RL, and the evaluation of off-policy learning in procedurally generated environments, this paper introduces OPAX\u2014an algorithm designed for active exploration to improve the efficiency and effectiveness of RL training, focusing on agents' ability to better understand and interact with their environment. Our work is inspired by the advancements in understanding and improving value estimation, generalization to novel scenarios, building upon domain generalization, and the importance of benchmark diversity for assessing generalization capacity in RL research. OPAX leverages well-calibrated probabilistic models to quantify epistemic uncertainty about unknown dynamics and employs an optimistic stance regarding plausible dynamics to maximize information gain between the dynamics and state observations. By conceptualizing the exploration problem as an optimal control problem, we show that OPAX not only theoretically underpins the notion of efficient exploration but also demonstrates superior performance in zero-shot planning on novel downstream tasks through experiments in various environments, including game-based settings, thus highlighting its practical implications. Agents programmed with OPAX exhibit enhanced learning capabilities. Our findings offer a sample complexity bound for Gaussian process dynamics, indicating a convergence of epistemic uncertainty to zero, and underscore the potential of OPAX as both a theoretically sound and practically effective methodology for active exploration in dynamical systems, boosting the development of more sophisticated AI systems. This paper concludes by discussing the implications of our work for the broader field of AI and suggesting benchmarks for future research.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Robert_Kirk1",
  "manipulated_ranking": 4,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=DPeBX79eNz",
  "title": "Transfer Learning with Affine Model Transformation",
  "modified_abstract": "Building on insights gained from the exploration of source-free domain adaptation, open-set recognition under domain shift, and the exploitation of intrinsic neighborhood structures within domain adaptation, this paper presents a novel approach to supervised transfer learning termed affine model transfer. The in-depth understanding of domain adaptation, without access to source data, lays the foundation for our investigation into statistically learning domain shifts and domain-specific factors applicable in sparse data scenarios, including scenarios with partial-set information or unlabeled data. By proposing a unified framework that applies expected-square loss minimization, our methodology extends beyond traditional neural feature extraction-based transfer learning, offering a new perspective on affine transformations in model adaptation. Our approach integrates attribute-based features and clustering techniques to enhance the understanding of neighbors within the transfer domain, showcasing the significance of capturing inter-domain commonality and domain-specific attributes. We provide a thorough analysis of affine model transfer, including its encompassment of various extant methods, particularly highlighting its utility in open-set recognition scenarios, and delve into its theoretical properties such as generalization error and excess risk. Case studies highlight the utility of affine-type transfer models in distinguishing inter-domain commonality and domain-specific factors, thereby presenting a substantial advancement in the field of transfer learning, even as it pertains to the categorization and recognition of unlabeled or partially-labeled object datasets, potentially extending into 3D domain applications.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Shiqi_Yang1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=BryMFPQ4L6",
  "title": "Augmenting Language Models with Long-Term Memory",
  "modified_abstract": "Informed by the recent breakthroughs in transformers, semi-supervised learning, speech recognition, pretraining, and self-training strategies across domains like natural language processing (NLP), speech technology, and multilingual modeling, this paper proposes a novel approach to overcome the limitations of existing large language models (LLMs) regarding their inability to utilize long-context information effectively due to input length limits. Our framework, Language Models Augmented with Long-Term Memory (LongMem), introduces an innovative decoupled network architecture. This architecture maintains the backbone LLM unchanged as a memory encoder while employing an adaptive residual side-network as a memory retriever and reader, enabling it to cache and update long-term contexts efficiently without succumbing to memory staleness. The memory-augmented adaptation training within LongMem allows for enhancing LLMs' capability to incorporate and leverage long-past contexts, significantly expanding their long-form memory capacity up to 65k tokens through techniques akin to pseudo-labeling and norm adaptation. This capacity increases LLMs' in-context learning prowess by retaining numerous extra demonstration examples within their long-form memory, further leveraging unlabelled data through pseudo-labeling. Rigorous testing on benchmarks such as ChapterBreak, a known challenging long-context modeling benchmark, and assessments of learning systems' memory-augmented in-context capacity show substantial performance improvements over existing long-context models. These findings highlight the effectiveness of our proposed method in equipping LLMs with the ability to memorize and apply long-form content across various downstream tasks, including speech-based applications and the challenging task of content reconstruction.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Tatiana_Likhomanenko1",
  "manipulated_ranking": 7,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=niHkj9ixUZ",
  "title": "Beyond Pretrained Features: Noisy Image Modeling Provides Adversarial Defense",
  "modified_abstract": "Inspired by recent contributions to adversarial robustness and the exploration of new defenses against adversarial attacks in the realm of part-based models, adversarial training enhancements, and the benchmarking of adversarial patches, our study presents a novel perspective on noisy image modeling (NIM) as a mechanism for adversarial defense. Recent advancements in masked image modeling (MIM) have positioned it as a dominant framework for self-supervised visual representation learning in machine learning. However, the vulnerability of MIM pretrained models to adversarial attacks, akin to most deep neural network methodologies, has limited their utility, a challenge that remains scarcely addressed in the literature. In exploring the potential of self-supervised learning for enhancing adversarial robustness in downstream classifiers, we identify that NIM, a variant of MIM engaging denoising as a pretext task, possesses an inherent capability to reconstruct severely corrupted images effectively. Triggered by this insight, we introduce an adversarial defense method dubbed De^3, leveraging the pretrained decoder for denoising, thereby enabling NIM to fortify adversarial robustness beyond merely offering pretrained features. This approach is further augmented by randomly sampling the noise scale hyperparameter, facilitating a refined balance between accuracy and robustness. Our empirical investigations confirm that NIM's denoising proficiency significantly contributes to its superior adversarial resilience in comparison to MIM. Furthermore, the defensive prowess of NIM, evidenced through comparative performance with adversarial training, underscores the tunability advantage unique to our proposition. Source code and models, initially provided, have been omitted for this abstract.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Chawin_Sitawarin1",
  "manipulated_ranking": 33,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=No52399wXA",
  "title": "IPMix: Label-Preserving Data Augmentation Method for Training Robust Classifiers",
  "modified_abstract": "Inspired by recent advancements in semi-supervised learning and domain adaptation highlighting the significance of dealing with biased pseudo-labeling and domain shifts, our work introduces IPMix, a novel data augmentation approach designed to enhance classifier robustness without compromising clean data accuracy. It harmonizes insights gained from the exploration of debiased self-training, which reveals the challenges of bias and training instability in semi-supervised settings, and the critical need for adaptability in domain adaptation to address high-dimensional tasks through strategies like regressive domain adaptation. IPMix integrates image-level, patch-level, and pixel-level augmentations into a cohesive, label-preserving framework, significantly increasing training data diversity with minimal computational increase. Structurally, it introduces complexity at various levels to produce a broader spectrum of images while utilizing a random mixing method for effective multi-scale information fusion. Tested across standard benchmarks such as CIFAR-C and ImageNet-C, IPMix sets new precedents in corruption robustness and also enhances adversarial robustness, prediction calibration, consistency, and anomaly detection, achieving noteworthy outcomes on ImageNet-R, ImageNet-A, and ImageNet-O. This reaffirms the potential of sophisticated data augmentation in balancing the trade-offs between model accuracy and robustness. Echoing the principles observed in adjacent research fields such as game theory for coordinating strategies and neural networks for object recognition, IPMix's state-of-the-art outcomes underscore its effectiveness in a diverse set of challenges, including sparse data environments and auxiliary-task learning, paving the way for its application in recommender systems and beyond.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Ximei_Wang1",
  "manipulated_ranking": 27,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=bTidcHIK2t",
  "title": "Sample-Efficient and Safe Deep Reinforcement Learning via Reset Deep Ensemble Agents",
  "modified_abstract": "In the evolving landscape of deep reinforcement learning (RL), the integration of deep neural networks (DNNs) as function approximators has unlocked new potentials and challenges alike. Our work is informed by foundational research in areas such as deep exploration, efficient information acquisition, bootstrapping, and uncertainty quantification in prediction models. Previous studies have introduced innovative approaches like Langevin DQN, which achieves deep exploration by perturbing parameter updates, and Epistemic Neural Networks, providing a framework for evaluating the quality of predictive distributions crucial for sequential decision tasks. Leveraging these concepts, we address the challenge of primacy bias in DNNs, where early experiences disproportionately influence training, leading to overfitting and potential safety concerns in RL applications. We propose a novel reset-based method, incorporating deep ensemble agents with priors to efficiently navigate the distributions and reduce the complexity and risk of performance collapses post-reset, thereby ensuring safer and more sample-efficient RL. Through a series of experiments, including safe RL domains, our approach demonstrates improved handling of the exploratory trade-offs and posterior distributions integral to deploying RL in real-world settings. This contribution not only enhances sample efficiency and safety but also broadens the applicability of RL by mitigating the limitations of the conventional reset method and employing hypernetworks for dynamic adaptability.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Vikranth_Dwaracherla1",
  "manipulated_ranking": 3,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=6SRE9GZ9s6",
  "title": "Preference-grounded Token-level Guidance for Language Model Fine-tuning",
  "modified_abstract": "This work is inspired by recent innovations in sequence transduction, semantic parsing, and language model pre-training, each addressing unique challenges in granularity, compositionality, and generalization within natural language processing. Building on insights from these distinct yet related domains, our study explores aligning language models (LMs) with preferences, recognizing the importance of addressing the granularity mismatch between preference provided at the sequence level and LM training and generation occurring at the token level. To this end, we develop an alternate training process that iterates between grounding the sequence-level preference into token-level training guidance and refining the LM with the learned guidance. We devise a framework extending pairwise-preference learning from imitation learning to accommodate variable-length LM generation and the utilization of preferences among multiple generations. Alongside, we introduce two minimalist learning objectives for LM fine-tuning, optimized based on the volume of supervised data available. Our method demonstrates competitive performance on tasks such as discrete-prompt generation and text summarization, evidencing the potential of preference-grounded token-level guidance in enhancing LM fine-tuning.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~bailin_wang1",
  "manipulated_ranking": 32,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=BHxsP5fSHv",
  "title": "OKRidge: Scalable Optimal k-Sparse Ridge Regression",
  "modified_abstract": "Informed by the recent advancements in algorithmic strategies for optimization under constraints, including efficient two-coordinate updates, improved stochastic gradient descent methods under interpolation conditions, and novel approaches in analyzing convex regularization paths in convex machine learning models, our study introduces OKRidge, a cutting-edge algorithm for sparse ridge regression. This work addresses the vital problem of identifying sparse governing equations for nonlinear dynamical systems, which is paramount for scientific discovery. OKRidge innovatively uses a lower bound calculation rooted in a saddle point formulation, leading to either a direct solution via a linear system or an application of an ADMM-based method where the proximal operators and, by extension, the proximal-gradient methods are expediently computed through linear system solutions and isotonic regression. A distinctive feature of our method is the incorporation of a warm-starting mechanism, utilizing beam search, which marks a significant departure from existing Mixed Integer Programming (MIP) formulations, traditionally solved using commercial solvers like Gurobi. Through experimental validation, OKRidge demonstrates provable optimality in solving sparse ridge regression problems with computational efficiency that substantially surpasses existing benchmarks we achieved. This achievement lays down a scalable framework for tackling the complexities of deriving sparse representations in nonlinear dynamical systems, reflecting a synergetic convergence of theoretical innovation and practical utility. While not directly focusing on classification tasks, our method contributes to the expansive realm of machine learning, including potential implications for neural network regularization and as a pertinent comparison, does not primarily engage with image processing tasks.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Aaron_Mishkin1",
  "manipulated_ranking": 9,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=NWrN6cMG2x",
  "title": "Moment Matching Denoising Gibbs Sampling",
  "modified_abstract": "The quest for advanced models in Energy-Based Models (EBMs) stems from a broad spectrum of prior research focusing on optimizing data representation and recovery across different contexts, including matrix completion, tensor completion, and non-convex optimization algorithms. Influenced by the formulation of novel sampling strategies such as Cross-Concentrated Sampling (CCS) for matrix completion, robust approaches for dealing with sparse outliers, and non-convex optimization methods tailored for both matrix and tensor frameworks, our work introduces an efficient sampling framework for EBMs. Grounded in these foundational methodologies, we propose (pseudo)-Gibbs sampling with moment matching to address the significant challenges of training and sampling from EBMs, exacerbated by the inconsistencies in the Denoising Score Matching (DSM) method. Our framework enables effective sampling from an underlying clean model of the EBM that has been well-trained via DSM, by leveraging the concept of moment matching. This approach allows for a productive exploration of the benefits over related methods such as tensor completion and showcases how to scale this method for high-dimensional datasets, offering a potentially transformative perspective in handling EBMs' complexities with a focus on outliers and completion processes.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~HanQin_Cai1",
  "manipulated_ranking": 6,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=wYKU1C77sa",
  "title": "Language-driven Scene Synthesis using Multi-conditional Diffusion Model",
  "modified_abstract": "Inspired by the recent advancements in discrete diffusion models for multimodal generation, text-conditional image generation with enhanced control mechanisms, and depth-aided panorama outpainting using latent diffusion models, this paper introduces a novel approach to scene synthesis. Our work uniquely combines text prompts with human motion and existing objects, including vehicles, to create diverse and coherent scenes, marking a significant departure from traditional single-condition synthesis tasks. Addressing the complexity of integrating multiple conditions into a coherent synthesis process, we propose a multi-conditional diffusion model that stands out by explicitly guiding the synthesis process with direct predictions on the distribution of original data through a fusion of cross-attention and convolutional layers. This methodological breakthrough allows for an effective synthesis of both indoor and 360-degree scenes that are not only visually appealing but also contextually relevant to the provided textual descriptions, motion cues, and the volume of space they occupy. Through rigorous experimentation, including matching synthesized scenes against expected outcomes, we validate the superiority of our approach over current benchmarks and highlight its potential for facilitating natural scene editing applications. Our findings underscore the effectiveness of our model in estimating the challenges associated with multi-modal and multi-condition synthesis, paving the way for future exploration in language-driven scene generation.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Tat-Jen_Cham1",
  "manipulated_ranking": 38,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=HoBbZ1vPAh",
  "title": "Ensemble-based Deep Reinforcement Learning for Vehicle Routing Problems under Distribution Shift",
  "modified_abstract": "In the quest to enhance the generalization capabilities of neural methods for vehicle routing problems (VRPs) across varied instance distributions, our research introduces an ensemble-based deep reinforcement learning approach. This method builds on the foundation of existing research, which primarily focuses on traffic optimization and signal setting using machine learning models such as neural networks and gradient boosting models, as well as innovative approaches within traffic simulation and optimization. Analogous to methods that explore the effectiveness of machine learning techniques in dynamically changing environments, such as traffic signal optimization and predictive models for traffic flow and congestion, our strategy involves the development of a group of diverse sub-policies designed to collectively address distribution shifts in VRPs through robust approximations. Emphasizing uniqueness among the sub-policies through Bootstrap with random initialization and the application of regularization terms to enforce disparity, our experimental analysis demonstrates that the ensemble method outstrips contemporary neural baselines on randomly synthesized instances and shows promising generalization on benchmark instances from TSPLib and CVRPLib, solidifying its position as the state-of-the-art. This not only validates our approach but also opens avenues for the practical implementation of ensemble-based methodologies in addressing distribution shifts in VRPs, drawing a parallel to the broader domain of machine learning in traffic management and mobility infrastructure, and optimizing a comprehensive set of functions to evaluate model performance. The abstract summarizes the core findings and contributions of our research, emphasizing the novel use of ensemble learning in overcoming the challenges posed by distribution shifts.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Pawe\u0142_Gora2",
  "manipulated_ranking": 6,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=GgdFLb94Ld",
  "title": "CoDrug: Conformal Drug Property Prediction with Density Estimation under Covariate Shift",
  "modified_abstract": "Inspired by the groundbreaking progress in machine learning methodologies such as Bayesian inference through Prior-Data Fitted Networks (PFNs), and the exploitation of transfer learning for enhancing the efficiency of Hyperparameter Optimization (HPO), this study introduces CoDrug. CoDrug aims to tackle the critical challenges in drug discovery by ensuring the reliability of pharmaceutical property predictions, paramount for prioritizing molecules for experimental validation without incurring the high costs of wet-lab experiments. By employing an energy-based model, which incorporates neural network encoder designs, that leverages both labeled and unlabeled data, and Kernel Density Estimation (KDE) to assess molecular densities, CoDrug adeptly addresses the covariate shift dilemma pervasive in drug discovery tasks. These datasets often encompass limited labeled data, inadequately representing the extensive chemical space. Our novel approach not only mitigates the distribution shift emanating from de novo drug design models by utilizing the estimated densities and Bayesian posteriors to weigh molecule samples during prediction set construction but also demonstrates, through extensive experimentation with realistic distribution drifts in numerous small-molecule drug discovery initiatives, how CoDrug can significantly lower the coverage gap by over 35% compared to traditional conformal prediction sets unadjusted for covariate shift, leveraging preprocessing methods for improved data quality. Furthermore, CoDrug is effectively meta-trained to adjust its prediction strategy in a way that is optimized for the target audience, namely computational chemists and pharmaceutical researchers, showcasing the significant advancements it brings to the field of computational drug discovery. The incorporation of neural models and a focus on the relevant audience in this paper underlines the importance of both technical and practical aspects of pharmaceutical research.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Sebastian_Pineda_Arango1",
  "manipulated_ranking": 32,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=KTRwpWCMsC",
  "title": "Conformal Prediction for Time Series with Modern Hopfield Networks",
  "modified_abstract": "Our work is motivated by the recent progress in time series analysis, network reconstruction, and the application of machine learning (ML) methods across various domains, including large-scale time series clustering, network stability, and random model generation, and dynamic network reconstruction from heterogeneous datasets. These foundational studies have addressed key challenges and introduced novel methodologies, including sparse systems and algorithms, in their respective fields, paving the way for our exploration of conformal prediction in time series. To quantify uncertainty, conformal prediction methods are gaining continuously more interest and have already been successfully applied to various domains. However, they are difficult to apply to time series as the autocorrelative structure of time series violates basic assumptions required by conformal prediction, challenging the identifiability of predictive models and their interactions. We propose HopCPT, a novel conformal prediction approach for time series that not only copes with temporal structures but leverages them, incorporating sparse systems and incorporating L1 regularization techniques for efficient computation. We show that our approach is theoretically well justified for time series where temporal dependencies and systems interactions are present. In experiments, we demonstrate that our new approach, underpinned by advanced algorithms, outperforms state-of-the-art conformal prediction methods on multiple real-world time series datasets from four different domains.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Zuogong_Yue1",
  "manipulated_ranking": 14,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=BqZ70BEtuW",
  "title": "SANFlow: Semantic-Aware Normalizing Flow for Anomaly Detection",
  "modified_abstract": "Building on the foundational research in autoencoding, outlier detection, and probabilistic modeling, such as suppressing outlier reconstruction in autoencoders and exploring normalization constraints for improving model robustness through regularization techniques, our work introduces a novel perspective in visual anomaly detection. We propose SANFlow, a semantic-aware normalizing flow model that goes beyond traditional approaches by recognizing the semantic differences among features within images to efficiently learn and synthesize information. Previous normalizing flow (NF) applications have attempted a homogeneous treatment of diverse features, mapping all to a unit normal distribution, which we argue, overlooks the semantic complexity of visual data. Unlike these approaches, SANFlow adapts the NF technique to model each feature based on its unique semantic content, allowing for variable distributions. This methodological pivot, fortified by advanced networks and graph-based analysis for handling complex inter-feature relationships, is designed to enhance anomaly detection by discriminating between normal and abnormal data more effectively, enabling a targeted transformation of feature distributions. By training the model to map normal and abnormal data to distributions with distinct characteristics, SANFlow significantly advances the empirically proven density estimation capacity of NF for anomaly detection. This approach not only addresses the limitations seen in previous works but also sets a new, competitive direction for leveraging normalizing flows in handling complex, semantically varied data for improved anomaly detection performance.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Sangwoong_Yoon1",
  "manipulated_ranking": 17,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=tP50lLiZIo",
  "title": "Non-Stationary Bandits with Auto-Regressive Temporal Dependency",
  "modified_abstract": "Recognizing the significance of recent contributions in dynamic experiment designs, interference correction, and treatment effect learning in complex settings, such as online platforms and two-sided marketplaces, our work introduces a novel non-stationary multi-armed bandit (MAB) framework that extends these pioneering efforts to address real-world temporal dynamics more effectively. Traditional MAB frameworks, predominantly examined under stochastic or adversarial settings, often overlook the temporal dynamics inherent in applications like recommendation systems and online advertising. This paper introduces a novel non-stationary MAB framework that incorporates an auto-regressive (AR) reward structure to capture the temporal structure of these dynamics, acknowledges the impact of interference in data, and corrects for the \"naive\" assumptions about time-series data. We propose an algorithm that integrates an alternation mechanism, adept at leveraging temporal dependencies to dynamically balance exploration and exploitation, and a restarting mechanism designed to discard out-of-date information, thereby addressing the challenge of temporal non-stationarity directly. The error reduction in estimates and the improvement in completion of learning tasks highlight the efficacy of our approach. Our algorithm achieves a regret upper bound that nearly matches the lower bound, with regret measured against a robust dynamic benchmark, utilizing sophisticated estimators. Through a real-world case study on tourism demand prediction in China, which can be seen as a simulator for testing our framework, we demonstrate the efficacy of our algorithm and the broader applicability of our techniques to more complex, rapidly-evolving time series in systems, bridging a vital gap in the literature on MAB frameworks that manage temporal dependencies.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Tianyi_Peng1",
  "manipulated_ranking": 60,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=DP2lioYIYl",
  "title": "A Theory of Unsupervised Translation Motivated by Understanding Animal Communication",
  "modified_abstract": "Motivated by groundbreaking research in transformers' ability to structure behavior, embed systematic generalization, and the exploration of language as an integrative system for understanding, our study presents a novel perspective on unsupervised machine translation (UMT) through the lens of animal communication. This interdisciplinary approach reflects insights from the transformational impact of transformer networks in natural language processing, findings on the role of language in cognitive processes, the believable integration of organizational concepts in training tasks, and developments in computational models capable of mimicking aspects of human reasoning and abstract thinking. As neural networks have demonstrated proficiency in translating between languages without explicit parallel translations, we question the applicability of these tools in understanding the complex communicative systems of animals. This research proposes a theoretical framework for UMT devoid of parallel corpuses or assumptions of linguistic structural similarities, thereby accommodating the vastly different constructs of animal communication systems. Utilizing two stylistic language models, we highlight the boundaries of sample complexity required for successful unsupervised translation, suggesting that animal languages' complexity and shared communicative ground with humans could make their translation feasible. Our findings, supported by formal proofs and synthetic data experiments, reveal that error rates in language translation inversely correlate with the complexity of the language and the amount of common ground, paving the way for future attempts to decode non-human communication systems through advanced machine learning methodologies.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~James_McClelland1",
  "manipulated_ranking": 38,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=KTfAtro6vP",
  "title": "Reinforcement Learning with Fast and Forgetful Memory",
  "modified_abstract": "Nearly all real-world tasks are inherently partially observable, necessitating the use of memory in Reinforcement Learning (RL). Recent explorations in Automated Reinforcement Learning (AutoRL), the study of latent world models for continual reinforcement learning, human-timescale adaptation for open-ended tasks, the generation of synthetic experience for training RL agents, and advancements in multi-agent environments emphasize the critical advancements in enhancing learning efficiency and adaptability in complex environments. Building on these insights, our work introduces Fast and Forgetful Memory, an algorithm-agnostic memory model tailored for the unique demands of RL as opposed to the generalized approach of borrowing memory models from Supervised Learning (SL). This innovation addresses the discrepancy in training and efficiency characteristics between RL and adversarial environments by incorporating strong structural priors inspired by computational psychology, offering a novel drop-in replacement for recurrent neural networks (RNNs) in recurrent RL algorithms. The shaping of adaptation mechanisms within the model not only achieves greater reward across various recurrent benchmarks and algorithms without altering any hyperparameters but also markedly accelerates training speeds, boasting two orders of magnitude faster processing than conventional RNNs, thanks to its logarithmic time and linear space complexity. This contribution propels the RL community towards realizing more effective and efficient RL agents capable of navigating the intricacies of real-world applications, including those found in strategic game scenarios. The community-driven aim of our research underlines the potential for collaborative advancements in the field, with AutoRL emerging as a cornerstone for this endeavor.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jack_Parker-Holder1",
  "manipulated_ranking": 6,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=xFtuNq23D5",
  "title": "Boosting Spectral Clustering on Incomplete Data via Kernel Correction and Affinity Learning",
  "modified_abstract": "Spectral clustering's adoption for non-convex data clustering stems from its simplicity and effectiveness, particularly demonstrated in prior works on scalable estimation of nonparametric Markov networks, continuous optimization for Directed Acyclic Graph (DAG) structure learning, and causal discovery in datasets with missing information. These studies provide critical insights into handling incomplete data, optimizing computational frameworks, and understanding the underpinnings of data structure relations, which inform the conceptual and methodological advancements introduced in this work. Incomplete data in clustering contexts can significantly distort affinity measures and consequently degrade clustering outcomes. To overcome this challenge, we propose an innovative, imputation-free framework that incorporates two novel strategies aimed at enhancing spectral clustering in the presence of incomplete data. The first strategy introduces a kernel correction method designed to improve the kernel matrix's quality estimated from incomplete data, offering theoretical guarantees for enhanced performance in classical spectral clustering scenarios. The second strategy entails a series of affinity learning methods characterized by the implementation of the $\\ell_p$-norm within a self-expressive framework to generate an intrinsic affinity matrix with adaptive capabilities, leveraging graphical models and unsupervised learning techniques for structured explanations and insights into the domains over time. Our approaches surpass existing methods in data imputation and distance calibration, demonstrating notable improvements in clustering performance on benchmark datasets and highlighting their potential for scalability and broad applicability across various domains, including image and graphs, facing the challenge of incomplete data.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Ignavier_Ng1",
  "manipulated_ranking": 7,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=RWcfpmjlYm",
  "title": "BanditPAM++: Faster $k$-medoids Clustering",
  "modified_abstract": "Clustering, a fundamental task in data science with wide-ranging applications, has seen considerable advancements through various algorithmic improvements. Inspired by progresses in optimizing performance metrics for object detection and instance segmentation, we present BanditPAM++, an enhanced version of the BanditPAM $k$-medoids clustering algorithm. BanditPAM++ incorporates two major algorithmic improvements to achieve an $O(k)$ improvement in complexity and significant acceleration in wall-clock runtime compared to BanditPAM. First, it exploits a special structure within BanditPAM that enables the reuse of clustering information within each iteration. Secondly, it leverages an additional structure that allows for the reuse of information across different iterations. These insights into optimizing computational efficiency, drawn from methodologies that address imbalance and classification-localization unification in object detection, have informed the design of BanditPAM++. The result is an algorithm that not only retains the accuracy and interpretability benefits of $k$-medoids clustering for exotic objects with arbitrary distance metrics but also offers substantial speed improvements through bounding algorithms complexity. For instance, BanditPAM++ demonstrates over 10 times faster performance on the CIFAR10 dataset compared to BanditPAM, without sacrificing clustering quality and effectively ranking-based on the distance matrix. This paper also introduces a high-performance C++ implementation of BanditPAM++, accessible from Python and R, providing a valuable tool for practitioners under deep supervision. Auxiliary code for reproducing our experiments is available, positioning BanditPAM++ as a potent detector of optimal medoids in diverse datasets. URLs for code repositories have been removed for privacy.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Kemal_Oksuz1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=HMqGYxnlpv",
  "title": "A Simple Yet Effective Strategy to Robustify the Meta Learning Paradigm",
  "modified_abstract": "Inspired by recent advances in robotic skill acquisition, trajectory optimization, and black-box reinforcement learning, this work seeks to address the challenges observed in robust meta learning. In particular, the techniques developed in specialized skill libraries using Local Mixture of Experts and the adaptation of movement primitives in episode-based reinforcement learning highlight the importance of specialized, context-aware learning strategies. Building on this foundation, our paper proposes a novel approach to enhance the robustness of meta learning by optimizing the meta learning pipelines from a distributionally robust standpoint. By focusing on minimizing the tail risk across a variety of task distributions, the proposed method aims to control the worst-case adaptation scenarios within a probabilistic framework, incorporating rich task representations and advanced search algorithms for optimal solution selection. This strategy is particularly relevant for meta learning applications where performance consistency across a diverse set of tasks is crucial, and it acts as a controller to maintain stability in the deep learning process. Our experimental analysis, including comparisons with traditional meta learning approaches and utilizing demonstrations to validate our methodology, confirms that not only does our method improve robustness against diverse task distributions, but it also significantly reduces the conditional expectation of the worst-case adaptation risk, similar to approaches seen in dense and convex optimization scenarios. This reinforces the idea that insights from successful applications in robotics and reinforcement learning can be effectively leveraged to solve broader challenges in the meta learning domain.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Onur_Celik1",
  "manipulated_ranking": 3,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=Gh67ZZ6zkS",
  "title": "PreDiff: Precipitation Nowcasting with Latent Diffusion Models",
  "modified_abstract": "Inspired by the remarkable achievements in machine learning across a spectrum of Earth system sciences, including spatially stochastic models for partial differential equations, deep Gaussian processes, probabilistic programming for ice core dating, optimization of climate model ensembles, and novel methods in Gaussian process latent variable alignment and Bayesian optimization, our work introduces a novel approach to precipitation nowcasting. Earth system forecasting has traditionally relied on complex physical models that are computationally expensive and require significant domain expertise. In the past decade, the unprecedented increase in spatiotemporal Earth observation data has enabled data-driven forecasting models using deep learning techniques for time-series analysis. These models have shown promise for diverse Earth system forecasting tasks but either struggle with handling uncertainty or neglect domain-specific prior knowledge, resulting in averaging possible futures to blurred forecasts or generating physically implausible predictions. To address these limitations, we propose a two-stage pipeline for probabilistic spatiotemporal forecasting: 1) We develop PreDiff, a conditional latent diffusion model capable of probabilistic forecasts. 2) We incorporate an explicit knowledge alignment mechanism to align forecasts with domain-specific physical constraints and classes of weather segmentation. This is achieved by estimating the deviation from imposed constraints at each denoising step and adjusting the transition distribution accordingly, somewhat akin to a compositional cluster of potential outcomes. Experiments on segmentation and adjustment methods support the variational approach's effectiveness in this context. We conduct empirical studies on two datasets: N-body MNIST, a synthetic dataset with chaotic behavior, and SEVIR, a real-world precipitation nowcasting dataset. Specifically, we impose the law of conservation of energy in N-body MNIST and anticipated precipitation intensity in SEVIR. Experiments demonstrate the effectiveness of PreDiff in handling uncertainty, incorporating domain-specific prior knowledge, and generating forecasts that exhibit high operational utility by utilizing a prototyping approach for probabilistic composition.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Ieva_Kazlauskaite1",
  "manipulated_ranking": 25,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=8S9Fbee743",
  "title": "Data-driven Optimal Filtering for Linear Systems with Unknown Noise Covariances",
  "modified_abstract": "This paper situates itself within the evolving landscape of machine learning for control and signal processing, reflecting on key themes distilled from recent advancements in learning-based control of systems with latent states, adaptive low-pass filtering, stable Koopman operators learning, networked online learning for control of safety-critical systems, and safety filters in reinforcement learning. These foundational studies underscore the growing necessity for algorithms that can learn to optimize control policies in the absence of complete system models, especially under constraints of fairness, robustness, and privacy. Our research extends these inquiries by examining the learning of optimal filtering policies for linear systems when noise covariance matrices are unknown and must be inferred from noisy output data, incorporating learned information with minimal memory overhead. We address this challenge by formulating it as a stochastic policy optimization problem, with hyperparameters tuning aimed at minimizing the output prediction error through confidence-based adaptation. Our contributions are manifold. First, we carry out a comprehensive convergence analysis of the stochastic gradient descent algorithm, tailored for the filtering problem with considerations for biased gradients and stability constraints, applicable even in motion-intensive scenarios. Second, we derive bias-variance error bounds for the proposed solution, employing a blend of linear system theory and high-dimensional statistics. Our analysis reveals that these bounds scale logarithmically with the problem's dimension, achieving state-of-the-art performance while demonstrating that unlike subspace methods, the length of output trajectories primarily influences the bias term. This work not only bridges data-driven optimal control and optimal filtering but also sets the stage for future explorations in robust and privacy-preserving methodologies in system identification and control, potentially extending to human-robot interaction and cloud-based control systems.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Armin_Lederer1",
  "manipulated_ranking": 4,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=VMAgvbBBts",
  "title": "UP-DP: Unsupervised Prompt Learning for Data Pre-Selection with Vision-Language Models",
  "modified_abstract": "Inspired by a range of pioneering works that explore universal representation learning, learn multiple dense prediction tasks from partially annotated data, and extend knowledge distillation for multi-task learning, we direct our investigation towards enhancing data pre-selection techniques in unsupervised learning environments. Our study is grounded on the premise that unifying vision and language modalities can significantly augment feature representation for data pre-selection. We posit that a well-crafted integration of text and visual features, as demonstrated through various advancements in vision-language models, can substantially improve the selection process of instances for labeling within an unlabeled dataset. To this end, we propose UP-DP, a novel unsupervised prompt learning framework that adapts vision-language models, notably the BLIP-2, to the context of data pre-selection. Leveraging the existing parameters of BLIP-2 while training text prompts allows for the extraction of joint features that encapsulate a more comprehensive representation, crucial for optimizing downstream tasks with limited annotation resources. This approach, embodying networks as extractors of intermodal features and aligning with the few-shot learning paradigm, uses adaptation mechanisms to optimize performance under resource-constrained conditions. Our approach ensures a diverse cluster structure, hence covering a broader spectrum of the dataset and allowing for optimal pairwise-interaction among the selected instances. Through rigorous experimentation across seven benchmark datasets, UP-DP not only demonstrates a significant performance gain of up to 20% over existing methods but also showcases remarkable generalizability\u2014the prompts trained on one dataset substantially enhance BLIP-2\u2019s feature extraction capabilities on different datasets. UP-DP marks the first venture into employing unsupervised prompt learning with vision-language models for the purpose of data pre-selection, setting a new frontier for future exploration in the domain.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Wei-Hong_Li1",
  "manipulated_ranking": 52,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=YmEDnMynuO",
  "title": "GraphAdapter: Tuning Vision-Language Models With Dual Knowledge Graph",
  "modified_abstract": "Inspired by recent breakthroughs in domains as diverse as domain adaptation, multi-objective meta-learning, and feature alignment, this study introduces GraphAdapter, a novel adapter-style efficient transfer learning (ETL) framework for vision-language models (VLMs) enhancement in low-data conditions. Previous works in adapter-style ETL, such as those focusing on domain adaptation through attentive mechanisms, selection strategies in encoder design, and multi-objective optimization in meta-learning, have primarily concentrated on single modality improvements or simplistic aggregation of objectives without considering the rich interplay between different data modalities and task-specific structures. GraphAdapter extends these foundational insights by addressing the two main limitations faced by existing adapter methodologies: (i) the singularity of task-specific knowledge representation, and (ii) the oversight of inter-class relationships in downstream tasks. It innovatively integrates a dual-modality structure, encapsulating the intricate relationships between textual and visual semantics through a dual knowledge graph comprising a textual knowledge sub-graph and a visual knowledge sub-graph. This dual-graph approach, coupled with an advanced selection mechanism for task-specific encoders and cross-attention mechanisms, enables the utilization of cross-modal structure knowledge and adaptation strategies, significantly enhancing task-specific classification efficacy across multiple domains and datasets, including the refinement of individual labels. Extensive evaluations on 11 benchmark datasets have proven GraphAdapter's superiority over conventional adapter-based methods, showcasing its potential to set new precedents in the realm of VLMs.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Pengxin_Guo1",
  "manipulated_ranking": 35,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=1vzF4zWQ1E",
  "title": "Rethinking Bias Mitigation: Fairer Architectures Make for Fairer Face Recognition",
  "modified_abstract": "Extensive research in machine learning has demonstrated that adversarial examples and the robustness of models to these examples, often framed as an attack on the model, are deeply tied to inherent features of model architectures. This is especially evident in the exploration of adversarial robustness, where models are assessed on their ability to withstand carefully crafted perturbations. Similarly, our work examines biases in neural network architectures themselves and asserts that these biases, much like those exploited by adversarial attacks, impact fairness in face recognition systems. Our study takes inspiration from techniques in adversarial robustness and causal analysis that have uncovered the influence of model architecture on vulnerability and robustness. Employing innovative approaches akin to those used in exploring adversarial examples and their mitigation, including attention mechanisms, regularization strategies, and compressed model refinement through pruning for model efficiency, we present the first neural architecture search aimed at maximizing fairness alongside accuracy. This approach, which indirectly relates to methods of compression and pruning for efficient model evaluation, yields a set of models that outperform existing state-of-the-art methods in both fairness and accuracy on well-known face identification datasets such as CelebA and VGGFace2. The broader applicability of our models is further validated across datasets and sensitive attributes, signifying a paradigm shift towards fairer machine learning systems. We have removed personal identifiable information and encourage the use of this abstract for further research.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Byung-Kwan_Lee1",
  "manipulated_ranking": 8,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=tLTtqySDFb",
  "title": "Not All Neuro-Symbolic Concepts Are Created Equal: Analysis and Mitigation of Reasoning Shortcuts",
  "modified_abstract": "Inspired by recent findings in meta-learned models of cognition, large language models, and resource-rational reinforcement learning, this paper investigates the phenomenon of reasoning shortcuts in Neuro-Symbolic (NeSy) predictive models. These models, designed to infer labels consistent with prior knowledge by reasoning over high-level concepts extracted from sub-symbolic inputs, are subject to reasoning shortcuts, wherein they leverage concepts with unintended semantics to attain high accuracy. This compromises their promised advantages of improved compliance with given constraints, systematic generalization, and interpretability. By drawing parallels with the identified themes in cognitive psychology, computational psychiatry, human heuristic development, and developmental psychology, we characterize reasoning shortcuts as unintended optima of the learning objective and uncover four key conditions behind their occurrence. Our contributions extend to the development of natural mitigation strategies, including bandit-based exploration methods, whose efficacy we evaluate both theoretically and empirically in terms of performance enhancements. Findings indicate that reasoning shortcuts present substantial challenges to the trustworthiness and interpretability of NeSy models, echoing concerns across various domains of cognitive science and psychology. The exploration of such shortcuts and the deployment of these mitigation strategies, particularly those involving trained models and deliberation processes, is crucial for the development of reliable machine learning systems that can avoid the pitfalls of surface-level learning.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Marcel_Binz1",
  "manipulated_ranking": 4,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=5Fgdk3hZpb",
  "title": "Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective",
  "modified_abstract": "Inspired by recent advancements in machine learning methodologies ranging from self-supervised learning frameworks, semantic segmentation pretraining strategies, to semi-supervised contrastive learning techniques, our work introduces a novel dataset condensation framework named Squeeze, Recover and Relabel (SRe$^2$L). This framework notably decouples the bilevel optimization of model and synthetic data during training, making it incredibly adept at handling varying scales of datasets, model architectures, and image resolutions efficiently. The innovative approach enables the framework to act on a manifold of data representations, offering one-shot synthesis capabilities for high-resolution images, thereby addressing inter-class variances adeptly. SRe$^2$L showcases remarkable flexibility across a broad spectrum of dataset scales, offering several key benefits including the synthesis of images at arbitrary resolutions, significantly reduced training costs and memory requirements for high-resolution synthesis, and the capability to scale up to arbitrary evaluation network architectures seamlessly. Extensive experimental validation conducted on both the Tiny-ImageNet and full ImageNet-1K datasets underlines the efficacy of our approach. Under a 50 Images Per Class (IPC) setting, SRe$^2$L achieves unprecedented validation accuracies of 42.5% and 60.8% on Tiny-ImageNet and ImageNet-1K, respectively, substantially outperforming all preceding state-of-the-art methods. Furthermore, compared to the model training time (MTT), it offers remarkable speed improvements\u2014approximately 52 times faster for ConvNet-4 and 16 times faster for ResNet-18\u2014with memory consumption reduced by factors of 11.6 and 6.4 during the data synthesis phase.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Haohang_Xu1",
  "manipulated_ranking": 42,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=0x2Ou3xHbH",
  "title": "On the Convergence of No-Regret Learning Dynamics in Time-Varying Games",
  "modified_abstract": "The convergence of no-regret learning algorithms in dynamic multiagent settings represents a complex area of study that builds upon prior explorations of learning dynamics in static and predictable environments. This paper extends the foundational work on gradient-based methods and their efficiency across a spectrum of differentiable games, including discussions on acceleration in smooth games and implications for stochastic variational inequalities, into the realm of time-varying games. We characterize the convergence properties of optimistic gradient descent (OGD) within this context, offering sharp convergence bounds for the equilibrium gap of OGD in zero-sum games. These bounds are parameterized by natural variation measures of the sequence of games, effectively subsuming known results for static scenarios and propelling understanding into the more intricate dynamics of evolving game environments. Furthermore, by establishing improved second-order variation bounds under conditions of strong convexity-concavity \u2014 provided each game is iteratively played \u2014 we contribute novel insights into the mechanics of convergence in these time-fluctuating settings. Our findings also generalize to time-varying general-sum multiplayer games through a bilinear formulation of correlated equilibria, introducing fresh perspectives for machine learning, meta-learning, and for deriving refined variation-dependent regret bounds in environments with ambient dynamics. This work addresses open questions from previous studies, amplifies the discourse on dynamic regret in static games, and charts a path for future investigations into the robustness and adaptability of learning algorithms in mutable frameworks.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Wa\u00efss_Azizian1",
  "manipulated_ranking": 74,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=Fdfyga5i0A",
  "title": "Mnemosyne: Learning to Train Transformers with Transformers",
  "modified_abstract": "Building upon existing knowledge in the augmentation of neural network performance through mixup techniques, the robustness and efficiency of transformer architectures in image classification, language processing, and the dynamics of knowledge transfer and generalization in machine learning, we introduce Mnemosyne. This new class of learnable optimizers, based on spatio-temporal low-rank implicit attention transformers, leverages insights from these foundational works to systematically address the challenge of training neural network architectures, including transformers, efficiently and effectively without task-specific optimizer tuning. Mnemosyne outperforms popular LSTM optimizers in robustness, offering a successful strategy for training transformers with minimal computational resources and systematically handles perturbations in the training data, thus improving in-distribution generalization and distribution stability. It matches state-of-the-art (SOTA) hand-designed optimizers in accuracy without the need for hyper-parameter tuning and establishes new bounds in efficiency. Additionally, Mnemosyne's space complexity is comparable to first-order optimizers, enabling the training of larger models on complex manifolds of data. We present extensive empirical evaluations on a range of tasks, including fine-tuning vision transformers for classification, pre-training BERT models, and soft prompt-tuning large T5XXL models, showcasing how our innovative approach serves as a versatile teacher in the efficient and effective training of transformers. Our results are supported by a comprehensive theoretical analysis of the compact associative memory employed by Mnemosyne, a topic previously unexplored, making significant strides in the efficient and effective training of transformers.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Andreas_Veit1",
  "manipulated_ranking": 28,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=llP6lmMiXE",
  "title": "A General Framework for Robust G-Invariance in G-Equivariant Networks",
  "modified_abstract": "This work is situated within the broader context of advancing the understanding of data representations and the geometrical structure of deep neural networks (DNNs), as explored in previous research on the intrinsic density of data representations, the evolution of hidden representations in large transformer models, and the effects of pruning on network architecture through training layers for robustness. Inspired by these precedents, we introduce a novel approach for achieving robust group-invariance in group-equivariant convolutional neural networks ($G$-CNNs), which we term the $G$-triple-correlation ($G$-TC) layer. Utilizing the theory of triple-correlation on groups, which represents the unique, lowest-degree polynomial invariant map that is also complete, our method addresses the challenge of preserving signal structure while achieving invariance to group actions. Unlike commonly used invariant maps, such as the max operation, which are incomplete and remove both group and signal structure, a complete invariant like the triple correlation retains all signal information less the group-induced variations. The $G$-TC layer's completeness confers strong robustness, observable in its resistance to invariance-based adversarial attacks, thus enhancing the probability of maintaining classification accuracy under such conditions. Moreover, we incorporate self-supervised learning tactics in strategic training of layers to further improvements in classification accuracy over standard Max $G$-Pooling in $G$-CNN architectures. Our general and efficient implementation for any discretized group, requiring just a table of the group's product structure, underscores the practicality of our framework. Demonstrations of $G$-CNNs on both commutative and non-commutative groups\u2014$SO(2)$, $O(2)$, $SO(3)$, and $O(3)$, discretized to the cyclic $C8$, dihedral $D16$, chiral octahedral $O$, and full octahedral $O_h$ groups, and applied to the $\\mathbb{R}^2$ and $\\mathbb{R}^3$ spaces on $G$-MNIST and $G$-ModelNet10 datasets\u2014illustrate the method's broad applicability and benefits.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Alessio_ansuini1",
  "manipulated_ranking": 60,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=j7U4pFkCYB",
  "title": "DynPoint: Dynamic Neural Point For View Synthesis",
  "modified_abstract": "Inspired by the recent advances in image and video synthesis, including improvements in neural radiance fields, stochastic image-to-video synthesis with conditional invertible neural networks, super-resolution, and high-resolution synthesis via latent diffusion models, this work presents DynPoint. DynPoint is an algorithm designed to facilitate the rapid synthesis of novel views for unconstrained monocular videos, addressing the challenges posed by uncontrolled or lengthy scenarios and the extensive training time required by existing algorithms. Unlike methods that rely on encoding scenario information into a latent representation or using a class-conditional generator, DynPoint focuses on predicting explicit 3D correspondence between neighboring frames to achieve information aggregation through techniques akin to inpainting for missing or occluded areas. This is attained through the estimation of consistent depth and scene flow across frames, using the predicted correspondence to aggregate information from multiple reference frames to a target frame via hierarchical neural point clouds with cross-attention mechanisms, significantly enhancing the algorithm's accuracy and speed. The experimental outcomes demonstrate that our approach significantly accelerates training time, typically by an order of magnitude, while maintaining robust performance in long-duration video view synthesis without the necessity of learning a canonical video content representation through diffusion.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Andreas_Blattmann1",
  "manipulated_ranking": 7,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=bLB4vTwSbC",
  "title": "Greatness in Simplicity: Unified Self-Cycle Consistency for Parser-Free Virtual Try-On",
  "modified_abstract": "Our work advances the field of image-based virtual try-on by addressing the significant challenges of non-rigid garment deformation modeling and strong feature entanglement between clothing and the human body, a theme that resonates with prior groundbreaking research in object deformation, feature disentanglement, and self-supervised learning across diverse applications including point clouds generation and poses estimation. Inspired by these related efforts, which range from self-supervised deep prior deformation networks for 3D object pose and size estimation to geometry-aware adversarial generation of clouds, our study introduces a unified self-cycle consistency (USC-PFN) approach for virtual try-on tasks. This approach eliminates the need for auxiliary tasks and dual generator mechanisms, thereby circumventing the introduction of irresponsible prior knowledge that hampers the main generator's performance in downstream tasks. Utilizing a novel self-cycle consistency architecture with a circular mode and a Markov Random Field for natural and realistic garment deformation simulation, our USC-PFN model leverages unpaired garment-person images for training, ensuring the effective elimination of the model input end's irresponsible prior knowledge impact. The USC-PFN framework incorporates an encoder-decoder structure for fine-tuning its capability in handling complex clothing and body classification while addressing surface-level discrepancies and outliers through self-adaptation. The experiments conducted demonstrate our method's superiority, achieving state-of-the-art performance on a widely used virtual try-on benchmark and paving the way for future research in parser-free garment deformation modeling.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jiehong_Lin1",
  "manipulated_ranking": 8,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=ouLe91yibj",
  "title": "On the Properties of Kullback-Leibler Divergence Between Multivariate Gaussian Distributions",
  "modified_abstract": "Inspired by the foundational studies in unsupervised learning, robust statistical estimations, dynamical systems modeling, perturbation resilient algorithms, and fairness in representation learning, this paper broadens the scope of theoretical analysis in machine learning by focusing on the Kullback-Leibler (KL) divergence between multivariate Gaussian distributions. KL divergence, a crucial measure for quantifying the difference between probability distributions, is dissected for its complex behavior in high-dimensional spaces. We theoretically study several properties of KL divergence between $n$-dimensional Gaussian distributions. Initially, we establish empirical bounds on the divergence by demonstrating that for any two Gaussian distributions, the supremum and infimum of KL divergence can be tightly estimated under specific conditions, further elucidating the quasi-symmetry and relaxed triangle inequality in the context of Gaussian distributions. These bounds significantly extend our comprehension of the geometric and informational disparities measured by KL divergence, unrestrained by the dimensionality of the distributions involved. Our findings have profound implications in areas such as deep learning, kernel methods, reinforcement learning, clustering, and the evaluation of sample complexity, where understanding the subtleties of information divergence is paramount for the development of algorithms with wide-ranging performance improvements. Through rigorous mathematical exposition, we aim to consolidate and expand upon various strands of information theory and statistical learning, aligning our work with emerging inquiries into how machine learning algorithms can be designed to be more fair, robust against perturbations, and protective of data privacy.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Andreas_Maurer1",
  "manipulated_ranking": 57,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=L7Whl9pXd0",
  "title": "Efficient Batched Algorithm for Contextual Linear Bandits with Large Action Space via Soft Elimination",
  "modified_abstract": "The quest for balancing computational efficiency with mathematical rigor in the domain of contextual linear bandits has led to the development of various strategies, evident in prior works on model estimation in linear systems, policy identification in linear Markov Decision Processes (MDPs), and optimal control in Linear Quadratic Control systems. Given this landscape, this paper introduces the first efficient batched algorithm for contextual linear bandits with large action spaces, addressing the challenges unmet by action elimination methods in scenarios with vast action sets. Leveraging a linear optimization oracle over the action set, our learner's algorithm achieves a regret upper bound $\\tilde{O}(\\sqrt{T})$ with high probability and uses $O(\\log\\log T)$ batches, matching the stipulated lower bound on the number of batches. For linear bandits, our approach further refines to a gap-dependent regret bound of $\\tilde{O}(1/\\Delta_{\\min})$ with an optimal $\\log T$ batch count, where $\\Delta_{\\min}$ signifies the least reward discrepancy between suboptimal and optimal actions. This accomplishment stems from a novel 'soft elimination' strategy, permitting efficient near-optimal action identification and systems control within each batch. Our work not only enacts a significant theoretical progression but also promises wide-ranging practical applications in areas such as digital communication, network optimization, formalize sampling strategies in complex learning settings, and automated decision-making. The consideration of state-action samples as a resource underpins our methodology, providing a foundation to address the significant question of how to optimally allocate these samples across decisions.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Yassir_Jedra1",
  "manipulated_ranking": 42,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=uiiVSVADDc",
  "title": "Annotator: A Generic Active Learning Baseline for LiDAR Semantic Segmentation",
  "modified_abstract": "Building upon the foundational insights and methodologies developed in the realms of amodal instance segmentation, affordance segmentation, few-shot instance segmentation, unsupervised object recognition, and monocular depth estimation, this paper introduces 'Annotator', a versatile and efficient active learning framework for LiDAR semantic segmentation. Previous works have advanced the field through innovative uses of convolutional neural networks, uncertainty estimation, and transformer-based models for various vision tasks, including video action recognition, laying the groundwork for efficient data utilization and model training. 'Annotator' leverages these advancements to address the challenges of high data annotation costs and the need for efficient learning in LiDAR semantic segmentation by proposing a voxel-centric online selection strategy. This strategy, reminiscent of boosting techniques in model performance, allows for the efficient probing and annotation of salient and exemplar voxel grids within LiDAR scans, even in the presence of distribution shifts. Employing a 'segmenter' module within its framework, 'Annotator' facilitates the selection and annotation process, significantly enhancing its efficacy. Through an in-depth comparison of common selection strategies and the development of the voxel confusion degree (VCD) metric to exploit local topology relations, 'Annotator' demonstrates exemplary performance and efficiency. It excels across various active learning modalities, including active learning (AL), active source-free domain adaptation (ASFDA), and active domain adaptation (ADA), and significantly reduces annotation requirements for tasks such as SynLiDAR to SemanticKITTI, achieving close to fully-supervised performance levels with minimal data labeling. 'Annotator' is positioned as a robust solution for enhancing label efficiency in 3D semantic segmentation and other related 3D vision applications.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Sinisa_Todorovic1",
  "manipulated_ranking": 29,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=ETk6cfS3vk",
  "title": "SlotDiffusion: Object-Centric Generative Modeling with Diffusion Models",
  "modified_abstract": "Inspired by the evolution of vision transformer architectures that have demonstrated significant advancements in vision tasks and the innovative application of clustering mechanisms for enhancing segmentation performance, our work, SlotDiffusion, ventures into the realm of object-centric learning. Object-centric learning, with its objective to decompose visual data into structured representations or slots, has shown promise for fostering systematic generalization. Building on the foundations laid by recent breakthroughs in transformers and clustering approaches for segmentation, such as the integration of k-means clustering with transformer models and the development of mobile convolution and attention mechanisms for constructing robust visual models, SlotDiffusion specifically targets the enhancement of slot-based generative modeling. The challenges of blurry images and distorted objects associated with current slot-based methods are addressed by focusing on improving the slot-to-image decoding process. SlotDiffusion introduces an object-centric Latent Diffusion Model (LDM) tailored for both image and video data, leveraging the potent modeling capability of LDMs to outperform previous models in unsupervised object segmentation and visual generation across multiple datasets. The learned object features from SlotDiffusion are further applicable in enhancing the quality of video prediction and downstream temporal reasoning tasks when integrated with object-centric dynamics models. Our successful application to unconstrained real-world datasets like PASCAL VOC and COCO, facilitated by the integration with self-supervised pre-trained image encoders, detection benchmarks, and the deployment of cross-attention mechanisms within the network architectures, showcases the scalability and effectiveness of SlotDiffusion in object-centric generative modeling, including improved mask segmentation capabilities.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Siyuan_Qiao1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=AnFUgNC3Yc",
  "title": "Resetting the Optimizer in Deep RL: An Empirical Study",
  "modified_abstract": "This paper investigates a pragmatic approach to improving deep reinforcement learning (RL) algorithms through the lens of optimization strategies, inspired by diverse methodological advancements across continuous control, offline RL, and actor-critic methods in recent literature. Specifically, our task focuses on the task of approximating the optimal value function in deep reinforcement learning, a field constantly confronting out-of-distribution scenarios that demand robust optimization techniques. This iterative process consists of solving a sequence of optimization problems whereby the loss function dynamically changes per iteration, presenting a perpetual challenge of adapting to new task environments. While the common methodology employs modern variants of the stochastic gradient descent algorithm, such as Adam, these optimizers maintain their own internal parameters, including estimates of the first-order and second-order moments of the gradient, updated over time. Consequently, information from previous iterations, including sample-based estimates, influences the current optimization problem, potentially contaminating moment estimates due to the arbitrary change in optimization landscapes from one iteration to the next. To address this, we propose resetting the internal parameters of the optimizer at the commencement of a new iteration, a simple yet potentially effective modification. Our empirical investigation across various optimizers in conjunction with the Rainbow algorithm demonstrates that this approach significantly enhances the performance of deep RL on the Atari benchmark, especially in tasks that are typically out-of-distribution. This suggests that incorporating sample guidance from the dataset and confidence-aware predictions in states could be a promising direction for optimization strategy selection in deep RL frameworks.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jiafei_Lyu1",
  "manipulated_ranking": 13,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=aW9BqtRQkh",
  "title": "Language Models Can Improve Event Prediction by Few-Shot Abductive Reasoning",
  "modified_abstract": "This paper is inspired by pivotal works in conditional language generation, long-form question answering, probabilistic neural summarization, and methods for enhancing diverse conditional generation of texts. These precursors highlight the capabilities of language models in various contexts, from refining the quality and accuracy of generated text to employing plans for text composition and generation. Large language models have demonstrated remarkable performance across a broad spectrum of reasoning tasks, including neural-based reasoning and sentence-level predictions. Our research investigates their potential to reason about real-world events and to enhance the performance of event sequence prediction models through few-shot training approaches. We introduce LAMP, a framework that integrates a large language model to support an event sequence model through abductive reasoning. This entails the language model assisting in identifying potential causes for future event predictions based on past sequences, guided by a few expert-annotated demonstrations. A search module identifies prior events matching these causes, and a scoring function assesses their likelihood of causing the predicted future events, ensuring high-quality event predictions. Extensive experiments across various challenging datasets confirm that our framework significantly surpasses current state-of-the-art models in prediction accuracy, evidenced by rigorous evaluation metrics. This success is attributable to the advanced reasoning capabilities and quality of neural-based large language models, combined with efficient training and probabilistic summarization techniques, signifying a substantial leap forward in event prediction methodologies.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Shashi_Narayan1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=NvcVXzJvhX",
  "title": "Sheaf Hypergraph Networks",
  "modified_abstract": "Higher-order relations are widespread in nature, with numerous phenomena involving complex interactions that extend beyond simple pairwise connections. The recent exploration of untrained subnetworks in Graph Neural Networks (GNNs) and the emphasis on the significance of sparsity in Sparse Neural Networks (SNNs), a concept integral to the sparse-to-sparse transformations, reflect a growing interest in capturing the essence of complex data structures more effectively. Inspired by these developments, we introduce a novel representation - cellular sheaves for hypergraphs, which adds extra structure to the conventional hypergraph while preserving their local, higher-order connectivity. This multifaceted approach is motivated by the desire to capture the intricacies of higher-order interactions, which are prevalent in a variety of domains. Drawing inspiration from existing Laplacians in the literature, we develop two unique formulations of sheaf hypergraph Laplacians: linear and non-linear. Our theoretical analysis demonstrates that incorporating sheaves into the hypergraph Laplacian provides a more expressive inductive bias than standard hypergraph diffusion, thereby creating a powerful instrument for effectively modelling complex data structures. Perturbation evaluation plays a role in showing the robustness of these models. We employ these sheaf hypergraph Laplacians to design two categories of models: Sheaf Hypergraph Neural Networks and Sheaf Hypergraph Convolutional Networks, which leverage centroid-based approaches for more effective graph representation. These models generalize classical Hypergraph Networks often found in the literature and are applied for hypergraph node classification, showing significant improvements in detection and classification tasks through extensive experimentation and evaluation. This generalization significantly improves performance, achieving top results on multiple benchmark datasets for hypergraph node classification.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Tianjin_Huang1",
  "manipulated_ranking": 63,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=7uPnuoYqac",
  "title": "Federated Learning with Manifold Regularization and Normalized Update Reaggregation",
  "modified_abstract": "The integration of manifold learning and federated learning (FL) draws inspiration from recent advances in learning to optimize, matrix and tensor completion, and robust principal component analysis, highlighting the significance of incorporating mathematical structures and robust optimization techniques in machine learning models. Our research positions itself at the convergence of these domains, proposing a novel framework for FL, dubbed FedMRUR, which leverages manifold regularization and normalized update reaggregation to address the challenges of local data heterogeneity, model inconsistency, and the presence of outliers in datasets. In FL, model inconsistency due to local data diversity among clients leads to near-orthogonality in client updates, hindering convergence. Previous solutions, focusing primarily on the alignment of parameters or gradients, have often overlooked the underlying model structure, the geometric limitations of Euclidean spaces, the importance of a low-rank approximation through completion techniques in capturing the essence of data, and the need to robustly handle outliers. FedMRUR introduces a hyperbolic graph manifold regularizer to minimize representation disparity between local and global models in a low-dimensional space, adeptly capturing the geometric intricacies of the model structure. This manifold-based approach mitigates model inconsistency more effectively than traditional methods. Additionally, by reaggregating the update norms from clients, FedMRUR enhances each client's contribution to the global model, addressing the issue of update norm reduction and accelerating convergence through intelligent sampling techniques. Practical application of FedMRUR demonstrates its potential to reshape federated learning landscapes. We provide theoretical backing for FedMRUR's efficiency, demonstrating its linear speedup in non-convex settings under partial client participation. Comparative experiments on established datasets validate FedMRUR's superior performance in achieving state-of-the-art accuracy with reduced communication overhead, delineating a significant stride towards more robust, efficient, and cohesive federated learning systems.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~HanQin_Cai1",
  "manipulated_ranking": 6,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=cQdc9Dyk4i",
  "title": "GraphMP: Graph Neural Network-based Motion Planning with Efficient Graph Search",
  "modified_abstract": "Our work on GraphMP is directly motivated by recent advancements in diverse machine learning applications, including masked trajectory models, visual representation learning for embodied navigation, and general-purpose neural network architectures for vision-and-language (visio-linguistic) navigation tasks. These foundational studies collectively illustrate the potential of leveraging neural network models to enhance the performance and efficiency of systems interacting with complex environments or requiring sophisticated decision-making processes. The multimodal nature of these advances, particularly in pretraining neural networks for understanding and generating trajectories, aligns with the adaptation of such models for specific tasks. In the realm of motion planning, which is crucial for robotic systems, there exists a profound need to find high-quality collision-free paths in the configuration space. While learning-based motion planners, especially those powered by graph neural networks (GNNs), have demonstrated promising planning performance in tasks as diverse as navigation through environments and the manipulation of objects as seen in videos, they face limitations in the graph search process due to their inherent mechanisms. Addressing this challenge, this paper introduces GraphMP, a neural motion planner designed for both low and high-dimensional planning tasks, featuring a customized model architecture and training mechanism that enable efficient graph pattern extraction alongside graph search processing. This approach results in notable improvements in planning performance, as evidenced by experiments conducted in environments ranging from 2D Mazes to 14D dual KUKA robotic arms, where GraphMP significantly outperforms both state-of-the-art learning-based and traditional planners in path quality and planning speed while maintaining competitive success rates.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Arjun_Majumdar2",
  "manipulated_ranking": 14,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=nCwStXFDQu",
  "title": "FouriDown: Factoring Down-Sampling into Shuffling and Superposing",
  "modified_abstract": "In the wake of growing evidence that spatial down-sampling techniques in deep neural networks influence feature representation - from frequency pooling that preserves shift-equivalence and anti-aliasing, to the use of dilated convolutions for improved resolution in super-resolution tasks, and methods aiming at reducing high-frequency adversarial perturbations - our research proposes a unified approach to down-sampling in the Fourier domain, termed FouriDown. This novel paradigm overcomes the biased effects inherent in static weighting strategies of conventional down-sampling methods like strided convolution, Gaussian, and Nearest down-sampling by introducing a learnable, context-adaptive operator in the Fourier function. Through an innovative combination of 2D discrete Fourier transform, channel shuffling based on potential for aliasing, adaptive frequency weighting, and inverse transformation, FouriDown encapsulates the essence of spatial down-sampling into a singular, versatile operation. Our methodology harmoniously integrates into existing image restoration architectures, offering improvements in de-blurring and low-light image enhancement as substantiated by extensive experiments in classification and training processes on diverse datasets. The convergence of ideas from preceding works, including gradient-based optimization techniques, and the introduction of Fourier domain conceptualization underscores FouriDown's significant performance leap in machine learning applications, further motivating publicly shared code for widespread application and future exploration in areas including but not limited to re-identification and person tracking.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Zhendong_Zhang1",
  "manipulated_ranking": 83,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=GlWzQhf2lV",
  "title": "Exploiting Contextual Objects and Relations for 3D Visual Grounding",
  "modified_abstract": "3D visual grounding, the task of identifying visual objects in 3D scenes based on natural language inputs, is vital for participating in and understanding real-world environments. This challenge is amplified by the complexity of accurately capturing the necessary 3D contextual information to effectively distinguish target objects within intricate 3D scenes. The dearth of annotations for contextual objects and their interrelations further complicates this task. Drawing insights from pioneering work in areas such as 3D object detection from multi-modality inputs, monocular 3D detection, transformer application in semantic segmentation, document image pre-training, and multi-scale attention in vision transformers, this paper introduces CORE-3DVG. Our model is designed to specifically address the outlined challenges by learning about contextual objects and their relations comprehensively, aggregating various input modalities which may include camera data for enhanced environmental understanding. CORE-3DVG achieves this through a series of three sequential modular networks: a text-guided object detection network to initially identify potential objects of interest, a relation matching network to understand the spatial and contextual relationships between these objects using a convolutional approach for feature extraction, and a target identification network to finalize the determination of the target object based on the natural language input. Transformative in its approach and recognizing the importance of aggregating contextual cues, CORE-3DVG integrates the transformer architecture for improved semantic segmentation and recognition of complex object relations. To enhance the model's ability to learn robust representations of contextual objects and relations and efficiently manage the architecture's computational resources, we implement a pseudo-label self-generation strategy for training and a weakly-supervised method for refining this learning process. This innovative approach ensures that our network more effectively focuses on the referred objects within 3D scenes by deepening its contextual understanding. We validate our model's effectiveness on the challenging Nr3D, Sr3D, and ScanRefer datasets, where it demonstrates superior performance, thus setting a new benchmark in the field of 3D visual grounding.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Errui_Ding2",
  "manipulated_ranking": 68,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=ZwQJRXLjVm",
  "title": "Rehearsal Learning for Avoiding Undesired Future",
  "modified_abstract": "Motivated by recent progresses in uncertainty quantification and predictive modeling in diverse applications, this paper explores a novel approach to decision-making using machine learning models. Particularly, it builds upon principles found in evidential deep learning, Bayesian neural networks, and the incorporation of uncertainties into predictive models, as evidenced by various recent works in fields ranging from natural language processing to healthcare and physics. These foundational studies illustrate how machine learning, particularly through neural nets, can transcend mere prediction, engaging with the uncertainties inherent in model outputs to inform decisions. Our paper presents a rehearsal learning framework, aimed at identifying decisions that can concretely avoid undesired outcomes, predicted by machine learning models. Through the identification process, we tackle the challenge of concept drift by ensuring our model adapts to changes over time. We extend this idea through the use of rehearsal graphs and structural equations within a probabilistic graphical model, enabling the identification of actionable decisions by reasoning within a Bayesian framework. A distinctive feature of our approach is the introduction of a probably approximately correct (PAC) bound to assess the risk associated with decisions, incorporating closed-form solutions where feasible to streamline computations. This allows for a sophisticated analysis of the trade-offs between actions based on the degree of uncertainty in predictions, considering the influence of machine learning hyperparameters. Our experiments, grounded in this integrative methodology, validate the effectiveness of the rehearsal learning framework and demonstrate the utility of the proposed PAC bound for decision-making in uncertain contexts.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Manuel_Haussmann1",
  "manipulated_ranking": 12,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=WRGldGm5Hz",
  "title": "DYffusion: A Dynamics-informed Diffusion Model for Spatiotemporal Forecasting",
  "modified_abstract": "Inspired by breakthroughs in simulation-based inference, generative modeling, and sequential neural variational inference in fields ranging from astrophysics to neuroscience, this work introduces DYffusion\u2014a novel approach that extends the capabilities of diffusion models to dynamics forecasting. Previous works have demonstrated significant advancements in the exploitation of geometric properties, model parameter inference, and the efficient identification of informative features through techniques like group equivariant neural posterior estimation (highlighting the importance of accurately estimating posteriors) and truncated sequential proposals. Building upon these foundational studies, DYffusion leverages temporal dynamics encoded in data, integrating it directly with diffusion steps to train a model that self-consistently acts both as a stochastic time-conditioned interpolator and a backbone forecaster. This dual-nature model offers a powerful means to mimic conventional diffusion processes but with a focus on solving spatiotemporal forecasting concerns, enabling multi-step and long-range predictions. Our method's efficacy is proven through probabilistic skill score metrics, providing evidence of its success in forecasting complex dynamics such as sea surface temperatures, Navier-Stokes flows, and spring mesh systems. The dynamics-informed diffusion process of DYffusion offers a strong inductive bias, translating to improved computational efficiency over traditional diffusion models, and the integration of distributions derived from temporal data enables it to outperform in generating accurate forecasts, positioning it as a competitive approach for future developments in spatiotemporal forecasting within the machine learning domain.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Michael_Deistler1",
  "manipulated_ranking": 38,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=f56xMRb7Vt",
  "title": "Norm-guided latent space exploration for text-to-image generation",
  "modified_abstract": "This paper advances the understanding of latent space dynamics in text-to-image diffusion models by drawing insights from recent methodological and empirical advancements across several domains of machine learning, including active retrieval augmented generation, hierarchical prompting in web navigation, and the practical challenges in constructing realistic environments for autonomous agents. Inspired by the exploration of information retrieval to augment language models, the manipulation of observation space for task-specific prompting, and the identification of challenges in applying large language models to complex decision-making scenarios, our work investigates the latent space of initial seeds in diffusion models. We identify that the constrained norm values observed in the current training procedures for diffusion models have significant implications for seed manipulation methods, particularly for image generation from textual descriptions. To address these limitations, we introduce a novel method that leverages a non-Euclidean metric, incorporating a norm-based prior for interpolating between seeds. This method significantly improves the training efficiency, enhances the generation of rare concept images, and improves both the speed and management of image synthesis. By establishing a new interpolation technique and defining centroids in the latent space, our approach not only contributes to the state-of-the-art in few-shot and long-tail image generation tasks but also opens new avenues for future research into more effective latent space exploration mechanisms. The exploration process is analogous to sentence processing in natural language, where precise arrangement and selection of words (or seeds, in our context) are crucial for coherent and contextually relevant output.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Frank_F._Xu1",
  "manipulated_ranking": 7,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=3ZICE99e6n",
  "title": "ReTR: Modeling Rendering Via Transformer for Generalizable Neural Surface Reconstruction",
  "modified_abstract": "Inspired by new approaches in neural surface reconstruction and camera pose estimation, this paper introduces Reconstruction TRansformer (ReTR), a novel framework that incorporates the strengths of transformer architectures into redesigning the rendering process. Our work is motivated by the limitations of current methods in generalizable neural surface reconstruction, which often suffer from low confidence in depth distribution and inaccurate surface reasoning due to an oversimplified volume rendering process. In contrast, ReTR introduces a learnable $\\textit{meta-ray token}$, employing the cross-attention mechanism to simulate complex render interactions with sampled points and render observed color, an approach that mirrors the intricate rendering interactions detailed in recent works such as BNV-Fusion and DFNet. By operating in a high-dimensional feature space rather than color space, ReTR achieves sensitivity reduction to projected colors in source views, resulting in more accurate surface assessment with high confidence. The effectiveness of our method is demonstrated across various indoor and outdoor datasets, where it outperforms state-of-the-art approaches in reconstruction quality and generalization ability. This merging of transformer methods with structure-based rendering techniques work is a step towards addressing the challenges in neural surface reconstruction highlighted by recent advancements in 3D reconstruction, visual relocalization, and calibration processes, offering a new lens through which to understand the rendering process in machine learning. $\\textit{Our code is available at }$ https://github.com/YixunLiang/ReTR.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Victor_Adrian_Prisacariu1",
  "manipulated_ranking": 51,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=1recIOnzOF",
  "title": "Decorate3D: Text-Driven High-Quality Texture Generation for Mesh Decoration in the Wild",
  "modified_abstract": "Inspired by recent progress in text-to-image generation models, including advancements in natural language processing (NLP), personalized image synthesis, and creative generation techniques using diffusion models, this paper introduces Decorate3D. It represents a versatile and user-friendly method for the creation and editing of 3D objects using images, aimed not just at experts but also at newcomers to the field. Decorate3D models a real-world object of interest by neural radiance field (NeRF) and decomposes the NeRF representation into an explicit mesh representation, a view-dependent texture, and a diffuse UV texture. Users can then manually edit the UV or provide a prompt for the automatic generation of a new 3D-consistent texture, effectively turning abstract texturing ideas into a concrete 'story' through the visualized object. To achieve high-quality 3D texture generation, we propose a structure-aware score distillation sampling method optimizing a neural UV texture based on user-defined text, empowering an image diffusion model with 3D-consistent generation capability. This optimization process leverages cross-attention mechanisms to accurately interpret and apply the semantic meaning of sentences provided by users as prompts, efficiently mapping textual tokens to visual characteristics. Furthermore, we introduce a few-view resampling training method and utilize a super-resolution model to obtain refined high-resolution UV textures (2048$\\times$2048) for 3D texturing. Extensive experiments collectively validate the superior performance of Decorate3D in retexturing real-world 3D objects, presenting substantial evidence of its effectiveness across diverse subjects.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Yuval_Alaluf1",
  "manipulated_ranking": 4,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=XqcXf7ix5q",
  "title": "Locality-Aware Generalizable Implicit Neural Representation",
  "modified_abstract": "The burgeoning fields of generative models and implicit neural representations have made significant strides, as evidenced by recent advancements in various applications ranging from image backbones, 3D scene generation, to domain-specific image translation, and 3D shape synthesis. Inspired by the themes and methodologies from these prior works, including DreamTeacher's feature distillation from generative networks, NNField-LDM's hierarchical latent diffusion models for scene generation, Polymorphic-GAN's domain-adaptive feature morphing, and GET3D's explicit textured mesh generation, this paper introduces a new frontier in generalizable implicit neural representation (INR). Our approach, which has undergone rigorous adversarial training, addresses the limitations in capturing fine-grained local details by proposing a framework that integrates a transformer encoder with a locality-aware INR decoder. The transformer predicts latent tokens encoding local information, which correlates closely with cross-domain annotation strategies for large sample dataset development, while the INR decoder employs selective token aggregation and multi-band feature modulation for spatial and spectral fidelity in vision applications. This training process enables the representation of multiple data instances with localized detail enhancement, setting a new benchmark for INR development. Our contributions offer a novel perspective on constructing INRs for complex data entities, significantly outperforming existing models in tasks such as image generation, and laying down a foundation for future research into INRs that are both generalizable and locality-aware.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Daiqing_Li1",
  "manipulated_ranking": 3,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=r6xGZ0XL2g",
  "title": "Meta-Learning Adversarial Bandit Algorithms",
  "modified_abstract": "Our work is motivated by significant challenges and innovations in online optimization and learning fields, addressing gaps left by prior studies on online prediction with strategic experts, interactive combinatorial bandits, online submodular maximization with adversarial or stochastic constraints, and advancements in differentially private submodular maximization. We study online meta-learning with bandit feedback, aiming to improve performance across multiple tasks if they are similar according to some natural similarity measure. As the first to target the adversarial online-within-online partial-information setting, we design meta-algorithms that combine outer learners to simultaneously tune the initialization and other hyperparameters of an inner learner for two important cases: multi-armed bandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners initialize and set hyperparameters of the Tsallis-entropy generalization of Exp3, with the task-averaged regret improving if the entropy of the optima-in-hindsight is small. For BLO, we learn to initialize and tune online mirror descent (OMD) with self-concordant barrier regularizers, showing that task-averaged regret varies directly with an action space-dependent measure they induce. Our guarantees rely on the inherently complex nature of the learning process, privacy considerations in mechanism design, and proving that unregularized follow-the-leader combined with two levels of low-dimensional hyperparameter tuning is enough to learn a sequence of affine functions of non-Lipschitz and sometimes non-convex Bregman divergences bounding the regret of OMD. Notably, this work derives its strength from the submodular property of the optimization problems, the essential role of feedback in algorithmic adjustment, and the use of log-submodular functions, providing a promising avenue for tackling the complexity of adversarial settings.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Omid_Sadeghi1",
  "manipulated_ranking": 8,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=TDS3kqRteY",
  "title": "REx: Data-Free Residual Quantization Error Expansion",
  "modified_abstract": "Addressing the challenges presented in previous works regarding quantization in neural networks' accuracy at extremely low bit-widths, including binary representations, and the quest for reproducible and deployable model quantization algorithms, our study introduces REx, a Data-Free Residual Quantization Error Expansion method for machine learning models. This research builds on the foundation laid by efforts to enhance quantization through architecture search and novel bit-inheritance schemes, as well as the paradigm-shifting approach of data-free model compression techniques in learning systems. Recognizing the limitations in adaptability of these techniques to specific hardware constraints due to varying supported bit-widths, we propose a flexible quantization method adaptable to diverse devices, achieving optimal accuracy-speed trade-offs. REx utilizes residual error expansion and incorporates group sparsity to tailor towards both convolutional neural networks and transformers across computer vision, including tasks on facial recognition\u2014often referred to as 'faces' in datasets\u2014and NLP models without relying on original dataset availability. Our method elegantly addresses the outlier problem, a notable challenge for state-of-the-art quantization methods, particularly in large language models. Furthermore, REx's robust theoretical foundation ensures preservation of the original model's predictive function, and its operator-agnostic nature permits integration with preceding quantization research. Experimental validation across various datasets and model architectures, augmented by an attention to learning dynamics and without the need for traditional training data, demonstrates REx's capability to facilitate better accuracy-bit-width trade-offs, benchmarking against prior state-of-the-art approaches to reinforce the potential of data-free methods in ensuring privacy while not compromising on efficiency and deployability across varying computational platforms.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Mingzhu_Shen1",
  "manipulated_ranking": 27,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=9pLaDXX8m3",
  "title": "NeRF-IBVS: Visual Servo Based on NeRF for Visual Localization and Navigation",
  "modified_abstract": "In light of the remarkable progress in machine learning applications spanning from visual imitation in robotics to the development of artificial visual cortex models for embodied intelligence, our work introduces a novel approach to visual localization and navigation. These preceding studies, showcasing advancements in scalable multi-task learning, real robot learning benchmarks, acceleration of visual model-based reinforcement learning, and insights into pre-training for visuo-motor control, provide crucial context for addressing the challenges in visual localization. Specifically, our proposed method, which leverages Neural Radiance Fields (NeRF) for Image-Based Visual Servoing (IBVS), addresses the high cost and complexity of acquiring posed images and dense 3D labels required by existing methods. By utilizing a minimal sample set of posed images with coarse pseudo-3D labels via NeRF, we undergo a rigorous training process, where we train a coordinate regression network, estimate coarse poses, and optimize these poses using IBVS with scene priors from NeRF. This innovative training methodology allows for effective navigation without the need for custom markers or depth sensors, demonstrating superior performance on the 7-Scenes and 12-Scenes datasets with significantly reduced training data requirements. The robustness and adaptability of our framework to visual navigation tasks underline its potential for broader applications in robotic and computer vision systems, especially in large-scale environments or language-based interaction models, presenting an advantage that future agent design submissions in this field could leverage to improve their systems. Our approach's efficacy is further highlighted through successful rollouts in diverse settings, emphasizing its imitation learning capabilities without extensive data.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Aravind_Rajeswaran1",
  "manipulated_ranking": 14,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=alLs7EtRJP",
  "title": "Factorized Contrastive Learning: Going Beyond Multi-view Redundancy",
  "modified_abstract": "Inspired by recent advancements in unsupervised domain adaptation, meta learning, and domain-specific architecture search that leverage complex feature representations and learning strategies to enhance network performance, our study introduces FactorCL, a novel contrastive learning methodology aimed at transcending the conventional multi-view redundancy in multimodal tasks. Contrastive learning, recognized for its efficacy in representation learning from untapped unlabeled data using merely pairing details such as image-caption or video-audio pairs, predominantly relies on the multi-view redundancy assumption, where shared information between modalities is deemed crucial for task performance. However, this overlooks the presence of modality-unique regions that harbor task-relevant but modality-specific information. FactorCL addresses this gap by (1) factorizing representations into shared and unique components, which could be likened to a form of dynamic decoder; (2) employing mutual information (MI) optimization techniques to enhance task-relevant learning while filtering out irrelevant data, an approach that echoes aspects of evolutionary search and adaptation; and (3) introducing multimodal data augmentations to infer task relevance without explicit labels, thereby efficiently utilizing the rich information present in public datasets. Testing across extensive real-world datasets, FactorCL not only efficiently captures both shared and unique modality information but also sets new benchmarks on six diverse evaluations, illustrating a significant stride in the understanding and application of contrastive learning frameworks in solving multi-task challenges with an evolutionary approach to adaptation.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Pengxin_Guo1",
  "manipulated_ranking": 13,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=rUf0GV5CuU",
  "title": "Locality Sensitive Hashing in Fourier Frequency Domain For Soft Set Containment Search",
  "modified_abstract": "Inspired by recent advancements in learning hash functions for similarity search across different views, sparsifying covariance matrices for bilingual projections, and various techniques for efficient search and retrieval in domains ranging from natural language processing to real-time prediction on resource-scarce devices, our work explores an innovative approach to soft set containment search, a key task in applications like passage retrieval, text entailment, and subgraph search. Unlike traditional methods where queries and documents are viewed as sets of atomic IDs, we extend the concept to soft set containment by handling embedded representations of elements, enhancing the search through advanced representations in the frequency domain. In addressing the challenge of efficiently retrieving relevant documents under this paradigm, we propose a method that leverages Locality Sensitive Hashing (LSH) in the Fourier frequency domain. By transforming the hinge distance\u2014common in soft set containment\u2014into a dominance similarity measure and applying Fourier transform, we express this similarity as an expectation of inner products of functions in the frequency domain, enabling the use of traditional LSH in a novel context. Additionally, we introduce trainable indices sensitive to corpus and query distributions in the frequency domain, to enhance the efficiency of hash bit usage by effectively using covariance information. By experimenting with our FourierHashNet, we demonstrate its superior empirical performance in terms of query time versus retrieval quality trade-off, thereby underscoring the effectiveness of our approach in addressing the complexities of soft set containment search and contributing to the broader discourse on hash function applications in machine learning.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Raghavendra_Udupa1",
  "manipulated_ranking": 80,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=WK8LQzzHwW",
  "title": "Unsupervised Anomaly Detection with Rejection",
  "modified_abstract": "Anomaly detection, a task aimed at identifying unexpected behaviors in data, faces the challenge of operating in an unsupervised manner without clear supervision to guide the decision-making process. Toward addressing this, our paper is inspired by prominent themes in the broader machine learning domain, including efforts to develop theoretically grounded decision-making systems across multi-class classification, abstention learning, and adversarial robustness. In this context, we investigate Learning to Reject\u2014an approach allowing detectors to withhold predictions when faced with high uncertainty. This necessitates developing a reliable confidence metric aligned with the distance to the decision boundary and determining an appropriate rejection threshold in the absence of labels. We tackle these challenges by leveraging a stability metric calculated by ExCeeD, setting a constant rejection threshold that yields theoretical analytics insights into the behavior of our approach, specifically using surrogate loss functions such as hinge and softmax for robustness calibration against adversarial attacks. Furthermore, we provide a theoretical upper bound for both the rejection rate and the expected prediction cost, offering strong guarantees about the test rejection rate. Our experimental results, benchmarked against metric-based and ranking methods replete with surrogates for calibration, validate the efficacy of our approach, underscoring the advantages of integrating rejection capabilities into unsupervised anomaly detection systems with classification tasks. This strategy not only enhances the trustworthiness of detector outputs but also navigates the complexities inherent in unsupervised learning scenarios, informed by the foundational contributions in areas such as convexity in decision-making, the exploration of surrogate loss functions, and the calibration of robustness against adversarial attacks, alongside the insights of domain experts.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Yutao_Zhong1",
  "manipulated_ranking": 9,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=3xSwxlB0fd",
  "title": "Uncoupled and Convergent Learning in Two-Player Zero-Sum Markov Games with Bandit Feedback",
  "modified_abstract": "This research contributes to the ongoing discourse on strategic interactions in multi-agent systems, a theme common to several preceding works on online double oracle methods, risk aversion in multi-agent systems, and learning with costly actions under budgetary constraints. Engaging with these foundational contributions, our focus shifts to the domain of two-player zero-sum Markov games. We aspire to develop an algorithm characterized by being uncoupled, convergent, and rational, achieving non-asymptotic convergence rates to Nash equilibrium while intelligently managing risk and algorithmic intelligence. Our exploration begins with stateless matrix games offering bandit feedback, where we demonstrate a $\\tilde{\\mathcal{O}}(t^{-\\frac{1}{8}})$ last-iterate convergence rate, marking the first achievement of finite last-iterate convergence rate under only bandit feedback conditions. This empirical evidence is extended to irreducible Markov games, yielding a last-iterate convergence rate of $\\tilde{\\mathcal{O}}(t^{-\\frac{1}{9+\\varepsilon}})$ for any $\\varepsilon>0$, and further to games without any assumptions on dynamics to show a *path convergence* rate, a novel convergence concept we formulated, of $\\tilde{\\mathcal{O}}(t^{-\\frac{1}{10}})$. Our work advances previous research by eliminating the requirements for synchronization and prior knowledge and builds upon and diverges in significant ways from methodologies that focused on entropy regularization, ensembles, and inter-agent communication, thereby proposing an entirely uncoupled approach that utilizes innovative algorithms.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Oliver_Slumbers1",
  "manipulated_ranking": 34,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=BdvCo8RVlx",
  "title": "The Contextual Lasso: Sparse Linear Models via Deep Neural Networks",
  "modified_abstract": "In the realm of interpretable machine learning, the integration of advancements from other areas such as optimization phenomena in deep learning, specifically the double descent curve in model performance, regularizing deep neural networks, and neural network compression, offers a fresh perspective on addressing longstanding challenges. This integrated approach is particularly evident in the exploration of sparse linear models, which, despite their value in interpretability, lack the functional flexibility of their deep learning counterparts. Responding to this, the study introduces the contextual lasso, an innovative statistical estimator designed to reconcile the interpretability of sparse linear models with the input feature complexity managed by deep neural networks. By dividing input features into explanatory and contextual categories, the contextual lasso adapts sparsity patterns and coefficients according to the context provided by the latter, learning this mapping through a deep neural network augmented with a novel lasso regularizer. This configuration not only adds to our capability to develop models that are transparent but dynamically adaptive, but also reflects a harmonization of interpretability with the predictive prowess of deep learning observed in adjacent fields such as descent in optimization, and benchmark and classification tasks in machine learning. The extensive evaluation of the contextual lasso against real and synthetic datasets underlines its potential to achieve sparser models than traditional lasso, without compromising deep neural network's predictive capacity.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Amal_Rannen-Triki1",
  "manipulated_ranking": 59,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=fxNQJVMwK2",
  "title": "Text-to-Image Diffusion Models are Zero Shot Classifiers",
  "modified_abstract": "Our investigation into text-to-image diffusion models as zero-shot classifiers is informed by a diverse array of foundational work in diffusion models, layout control, learnability of visual concepts, feature fusion in 3D environments, unsupervised semantic segmentation, category discovery, animatable 3D model generation, motion anticipation in video, image segmentation, and 3D object instance segmentation. These studies collectively emphasize the burgeoning potential of generative models, not just in their traditional domains, but also as powerful tools for classification, segmentation, and understanding in machine learning without explicit task-specific training. Building on this multidisciplinary groundwork, we propose a novel method for evaluating text-to-image diffusion models like Stable Diffusion and Imagen as zero-shot classifiers. By leveraging the models' inherent capability to denoise images based on textual descriptions, we conceptualize these descriptions as proxies for label likelihoods, effectively turning generative models into classifiers with high-fidelity output. Comparative analysis with CLIP demonstrates that these diffusion networks are competitive in zero-shot image classification tasks across various datasets, additionally surpassing state-of-the-art in shape/texture bias tests and attribute binding capabilities\u2014a feat unachieved by CLIP. Our study further highlights the role of self-supervision in enhancing the learnability and editing capabilities within these systems, indexing a suite of benchmarks that serve as a critical reference point for future investigations into the applicability of multi-camera perspectives in diffusion model research, establishing a new parallel in how visual concepts are understood and classified without prior training.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Andrea_Vedaldi1",
  "manipulated_ranking": 6,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=oDtyJt5JLk",
  "title": "Directional diffusion models for graph representation learning",
  "modified_abstract": "The exploration of diffusion models in graph representation learning builds on the significant advancements achieved in image synthesis, super-resolution, 3D molecule generation, and other domains where diffusion models have shown remarkable success. These successes, alongside innovations in graph neural networks (GNNs) for processing graph-structured data, motivate our investigation into the underexplored application of diffusion models for unsupervised graph representation learning. Our approach identifies anisotropic structures within graphs and addresses a crucial limitation in the traditional forward diffusion process, which indiscriminately adds isotropic Gaussian noise, potentially diluting anisotropic signals and impeding the training of denoising neural networks. To counteract this, we propose directional diffusion models that utilize data-dependent, anisotropic, and directional noises in the forward diffusion process. Our comprehensive experiments across 12 datasets, focusing on two graph representation learning tasks including classification, confirm the effectiveness of our models over established baselines. Through this research, we not only illuminate the nuances in the forward process of diffusion models but also highlight their potential to address a broad spectrum of graph-related tasks with attention-based approaches. Our contribution also prompts a reevaluation of diffusion processes in graph learning, inspired by the advancements and theoretical foundations laid by prior works in graph neural networks, including methods for optimizing computational efficiency, preserving topological structures, and enhancing model expressiveness and robustness through convolutional layers and backpropagation-based training techniques. Our investigation further explores the implications of aggregating features in an anisotropic fashion, fostering new directions in both the modelling and hardware optimization for graph representation learning. The integration of set-aggregation mechanics into our models points towards improved representation capabilities, especially in complex graph structures.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Luca_Pasa1",
  "manipulated_ranking": 38,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=HvhagNdf5z",
  "title": "Synthetic-to-Real Pose Estimation with Geometric Reconstruction",
  "modified_abstract": "Addressing the critical challenge of obtaining high-quality annotations for supervised learning in pose estimation, this study is inspired by the advances in unsupervised domain adaptation, 3D object detection, and semantic segmentation presented in recent works, which utilize innovative techniques such as pseudo-labelling, denoising strategies, and knowledge distillation in a teacher-student model framework for adapting models from synthetic to real-world domains. Specifically, this work tackles adapting models trained on synthetic data to real-world target domains with only unlabelled data. The common approach of model fine-tuning with pseudo-labels is often thwarted by the low quality of these labels for pose estimation tasks. In this context, pedestrian pose estimation emerges as a particularly demanding application, necessitating advanced categorization and learning techniques to distinguish subtle movements and positions. We propose a complementary reconstruction-based strategy for synthetic-to-real domain adaptation, where a driving image is generated by geometrically transforming a base image according to predicted keypoints, and a reconstruction loss is employed to refine these predictions. This method uniquely addresses the challenge of confident yet inaccurate keypoint locations through image reconstruction, offering a novel avenue for effective domain adaptation in pose estimation. Our approach achieves an 8% improvement in PCK over state-of-the-art methods on four large-scale hand and human real-world datasets, particularly excelling at predicting difficult endpoints like fingertips and the head with improvements of 7.2% and 29.9% in PCK, respectively. Highlighting the emergent need for open-vocabulary approaches in domain adaptation, this blend of geometric reconstruction with pseudo-labelling strategies paves the way for more accurate and robust pose estimation models that can be efficiently adapted from synthetic to real-world scenarios without the need for costly annotations.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jihan_Yang1",
  "manipulated_ranking": 10,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=BmIW6U0rz8",
  "title": "Koopman Kernel Regression",
  "modified_abstract": "This work is inspired by recent efforts in exploring stochastic dynamics, risk-sensitive control, and robust planning in dynamical systems through innovative algorithms and frameworks, synthesizing perspectives across disciplines. These studies provide a foundation for addressing decision making in complex environments, characterized by the need for predictive accuracy amidst uncertainty in domains ranging from robotics to active sensing and crowd-robot interaction. Planning, a key aspect of decision-making, often involves assessing risk and incorporating belief about the future state of the system into the decision-making process. Many machine learning approaches for decision making, such as reinforcement learning and interactive protocols, rely on simulators or predictive models to forecast the time-evolution of quantities of interest, e.g., the state of an agent or the reward of a policy. Forecasts of such complex phenomena are commonly described by highly nonlinear dynamical systems, where the distribution of outcomes is crucial for making informed decisions, making their use in optimization-based decision-making challenging. Koopman operator theory offers a beneficial paradigm for addressing this problem by characterizing forecasts via linear time-invariant (LTI) ODEs, turning multi-step forecasts into sparse matrix multiplication. Though there exists a variety of learning approaches, they usually lack crucial learning-theoretic guarantees, making the behavior of the obtained models with increasing data and dimensionality unclear. We address the aforementioned by deriving a universal Koopman-invariant reproducing kernel Hilbert space (RKHS) that solely spans transformations into LTI dynamical systems. The resulting Koopman Kernel Regression (KKR) framework enables the use of statistical learning tools from function approximation for novel convergence results and generalization error bounds under weaker assumptions than existing work. Furthermore, by incorporating finite-sampling considerations, KKR demonstrates superior forecasting performance compared to Koopman operator and sequential data predictors in RKHS, even under interactive scenarios.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Haruki_Nishimura1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=nDIrJmKPd5",
  "title": "Private Distribution Learning with Public Data: The View from Sample Compression",
  "modified_abstract": "Our research on the problem of private distribution learning with access to public data is rooted in the rich theoretical underpinnings established by prior works in private information retrieval (PIR) and coding theory. These preceding studies have meticulously explored PIR schemes in various contexts, such as coded data storage systems with arbitrary collusion patterns, distributed storage system (DSS) privacy under maximum distance separable (MDS) coding, privacy safeguards over random linear networks, and the robust construction of PIR schemes in environments with byzantine, colluding, and unresponsive servers. By situating our investigation within this landscape, we aim to extend the discourse on PIR by examining public-private learning configurations, where the central objective is to output an estimate of an unknown distribution $p$ from a class $\\mathcal{Q}$, under the constraints of pure differential privacy with respect to the private samples. Our analysis illuminates the interdependence between the public-private learnability of a class $\\mathcal{Q}$ and the architecture of a sample compression scheme for $\\mathcal{Q}$. Additionally, this study ventures into the domain of list learning as an intermediary framework, drawing parallels and distinction from traditional PIR challenges. The outcomes disclose, for instance, that the theory approximately aligns with earlier findings on learning Gaussians over $\\mathbb{R}^d$. Furthermore, we introduce novel insights, including sample complexity upper limits for arbitrary $k$-mixtures of Gaussians across $\\mathbb{R}^d$, alongside considerations for agnostic and distribution-shift resistant learning models. In concert, our findings argue for the augmentation of public-private learnability under the operation of mixing and product composition of distributions, and, through the prism of list learning, the necessity of at least $d$ public samples for the realization of private learnability of Gaussians in $\\mathbb{R}^d$, closely paralleling the established upper bound of $d+1$ public samples. Our methodology incorporates codewords and packets as foundational elements in the architecture of PIR and DSS to enable efficient requesting and retrieval operations, thereby enhancing the privacy-security-storage nexus.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Razane_Tajeddine1",
  "manipulated_ranking": 2,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=2nTpPxJ5Bs",
  "title": "Double Auctions with Two-sided Bandit Feedback",
  "modified_abstract": "This research is inspired by key themes and methodologies from prior works in algorithmic fairness, auction theory, and mechanism design, specifically focusing on round-robin algorithms, the complexity of equilibrium computation in auctions, single-sample prophet inequalities, and decentralized consensus mechanisms in blockchain technology. We explore Double Auction markets, a decentralized mechanism enabling transfers between multiple buyers and sellers, crucial for the functioning of online marketplaces. These participants, often unaware of their own valuations, rely on learning through repeated interactions. Our study introduces the concept of Double Auctions under bandit feedback for both buyers and sellers, employing confidence bound based bidding and 'Average Pricing' for efficient price discovery. The paper formally reviews the first to demonstrate an efficient learning mechanism in two-sided markets with uncertain preferences on both ends, highlighting the importance of bandit feedback mechanisms in the governance of these decentralized systems. We establish that the social regret for the combined valuation of buyers and sellers is $O(\\log(T)/\\Delta)$ over $T$ rounds, with individual regrets for active participants and non-participants outlined accordingly. Furthermore, we provide bounds on the attainability of regret minimization, showcasing the limitations and potential of learning in two-sided bandit feedback scenarios. This work contributes to the understanding of decentralized market dynamics and the development of algorithms that facilitate efficient and fair transactions, drawing upon foundational strategies in algorithmic game theory and mechanism design, all while hinting toward the potential parallel processing capabilities to enhance computational efficiency.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Philip_Lazos2",
  "manipulated_ranking": 11,
  "natural_ranking": 101
}
