{
  "paper_link": "https://openreview.net/forum?id=eTp4RetK74",
  "title": "ASPEN: Breaking Operator Barriers for Efficient Parallelization of Deep Neural Networks",
  "modified_abstract": "In the context of hardware-aware optimizations in deep learning, such as those introduced by Hardware-Aware Network Transformation (HANT), which enhance computational efficiency through tailored architecture modifications, operator barriers emerge as a critical bottleneck for parallel computation in Deep Neural Networks (DNNs). Our work, ASPEN, addresses these limitations by rerouting the conventional approach towards DNN construction from an operator-centric model to a more fluid, dataflow graph representation. This transition enables fine-grained dynamic execution of DNNs by removing the operator barriers, thus facilitating the exposure of extensive parallel computation opportunities across operators and layers. By dynamically identifying and scheduling these opportunities at runtime, ASPEN inaugurates a paradigm of opportunistic parallelism in DNNs, which significantly deviates from the restricted parallelism inherent in existing operator-based approaches, and introduces an innovative layer selection mechanism for optimal task allocation. Furthermore, ASPEN enhances resource optimization and promotes memory reuse by allowing each computing unit to asynchronously navigate through the DNN graph depth-wise, thereby maximizing its computational contribution. Challenges and solutions related to implementing ASPEN's innovative methodology, including efficient instruction selection for hardware-specific optimizations, are discussed, showing its superiority in performance through a proof-of-concept implementation that outmatches leading inference systems like TorchScript and TVM by notable margins of up to 3.2\u00d7 and 4.3\u00d7, respectively.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Hongxu_Yin1",
  "manipulated_ranking": 2,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=jDIlzSU8wJ",
  "title": "The Surprising Effectiveness of Diffusion Models for Optical Flow and Monocular Depth Estimation",
  "modified_abstract": "Building on prior advancements in denoising diffusion probabilistic models (DMs) primarily focused on high-resolution image synthesis, our research explores the application of diffusion models in estimating optical flow and monocular depth. The significant achievements demonstrated by applying DMs in the domain of image generation, particularly through latent diffusion models (LDMs) that achieve near-optimal complexity reduction and detail preservation, serve as a foundation for our work. This research demonstrates that diffusion models, known for their impressive fidelity and diversity in image generation, also excel in optical flow and monocular depth estimation tasks, without requiring task-specific architectures and loss functions that are traditionally predominant for these tasks. Leveraging the inherent characteristics of diffusion models, such as their capability for Monte Carlo inference, our approach captures uncertainty and ambiguity in flow and depth estimation more effectively than conventional methods. By employing self-supervised pre-training, utilizing both synthetic and real data for supervised training, and introducing technical innovations like infilling, inpainting, and step-unrolled denoising diffusion training, our models handle noisy and incomplete training data efficiently. This enables the training of diffusion models for optical flow and depth estimation, capable of zero-shot coarse-to-fine refinement for high-resolution estimates and inpainting missing areas with high fidelity. Our extensive experiments, focusing on quantitative performance against benchmarks, ablations, and the model's ability to capture uncertainty and multimodality, as well as impute missing values, showcase the synthesis and super-resolution capabilities integrated within our models, marking the state-of-the-art performance of our models. Specifically, our model achieves an unprecedented relative depth error of 0.074 on the indoor NYU benchmark and an Fl-all score of 3.26% on the KITTI optical flow benchmark, marking approximately a 25% improvement over the best published methods.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Andreas_Blattmann1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=9fWKExmKa0",
  "title": "DPM-Solver-v3: Improved Diffusion ODE Solver with Empirical Model Statistics",
  "modified_abstract": "Inspired by the recent advancements in score-based diffusion models, such as Functional Diffusion Processes (FDPs), which extend the application of diffusion models to infinite-dimensional function spaces and demonstrate exceptional capabilities in high-quality image generation, this work introduces an enhanced approach to optimizing diffusion probabilistic models (DPMs). DPMs have shown promising results in generating high-fidelity images but are hindered by inefficient sampling rates. Addressing this, our research proposes an innovative solution aimed at refining the inference phase of DPMs through backward dynamics optimization. The introduction of DPM-Solver-v3, an evolved fast ODE solver, leverages novel empirical model statistics meticulously computed from the pretrained network to minimize the first-order discretization error inherent in the ODE solutions of DPMs. By incorporating continuous multistep methods along with a predictor-corrector framework, this study further proposes effective strategies for enriching sample quality in generative tasks at fewer numbers of function evaluations or under extensive guidance scales. Through customized network architectures, our empirical validation demonstrates that DPM-Solver-v3 achieves superior or competitive performance across a range of DPM applications, notably enhancing efficiency in both unconditional and conditional sampling scenarios. Experimental results highlight significant improvements, featuring FID scores of 12.21 (at 5 NFE) and 2.51 (at 10 NFE) in unconditional CIFAR10 tasks, and achieve a mean squared error of 0.55 (at 5 NFE with a 7.5 guidance scale) on the Stable Diffusion benchmarks. The consequent acceleration in sampling rates of 15% to 30% over leading training-free methodologies underscores the efficacy of the proposed adaptations. This work not only introduces valuable empirical strategies to the field of DPM optimization but also sets a new benchmark for future research and applications within this domain.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Pietro_Michiardi1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=JTKd7zYROf",
  "title": "Randomized Sparse Neural Galerkin Schemes for Solving Evolution Equations with Deep Networks",
  "modified_abstract": "The evolution of artificial intelligence (AI) methods for solving complex scientific problems highlights the potential for innovative neural network adaptations to address challenges inherent in simulating physical phenomena. This work builds upon previous efforts, such as the use of Graph Convolutional Neural Networks (GCNNs) for domain decomposition, or subdomain interfaces, in partial differential equations, by introducing Neural Galerkin schemes that utilize randomized sparse updates to network parameters at each time step. Such an approach is inspired by techniques like dropout, aimed at mitigating overfitting by reducing neuron co-adaptation through unsupervised learning strategies, and extends those principles to manage the numerical challenges of sequential-in-time training for time-dependent partial differential equations. This method not only helps in preserving causality and other physics-inherent properties but also significantly reduces the risk of error accumulation over time, a common issue in sequential training approaches. By incorporating randomness and sparsity in the updates, our approach also reduces the computational demand, leveraging the redundancy in network parameters to maintain expressiveness with lesser computational resources. Our numerical experiments demonstrate the efficacy of this scheme across a variety of evolution equations, achieving up to two orders of magnitude higher accuracy for a given computational budget and similar improvements in computational efficiency at fixed accuracy levels compared to conventional dense update schemes.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Ali_Taghibakhshi1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=1qFnxhdbxg",
  "title": "Energy Discrepancies: A Score-Independent Loss for Energy-Based Models",
  "modified_abstract": "Motivated by the quest for more efficient and theoretically grounded training mechanisms in probabilistic modeling, as exemplified by advancements in normalizing flows and their application to complex density estimation and distribution tasks in both continuous and tabular data domains, this study introduces Energy Discrepancy (ED) as a novel loss function for energy-based models (EBMs). Our work is inspired by the themes found in efforts to resample base distributions in normalizing flows to capture complex topological structures without compromising tractability. Likewise, ED aims to address the computational challenges and theoretical limitations of conventional training methods for EBMs. By not relying on score computation or Markov chain Monte Carlo methods for minimization, ED provides a more accessible alternative that balances between explicit score matching and negative log-likelihood loss, offering solutions to the issues of nearsightedness in score-based methods along with theoretical assurances. Through numerical experiments and sampling efficiency assessments, we establish that our approach not only accelerates the learning process for low-dimensional data distributions in comparison to explicit score matching and contrastive divergence but also effectively manages the representation and learning of high-dimensional challenges, including image data. The investigation into the effectiveness of the energy discrepancy within the contexts of both low and high-dimensional data, including its integration as a prior within a variational decoder model, opens new pathways for employing EBMs in complex data representation tasks.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Vincent_Stimper1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=DCIsNIUCV7",
  "title": "Payoff-based Learning with Matrix Multiplicative Weights in Quantum Games",
  "modified_abstract": "This study extends beyond classical strategic interactions, motivated by prior work that has explored Nash-regret minimization in congestion games with bandit feedback, to address the particulate complexities inherent in quantum games and other semidefinite games using scalar, payoff-based feedback. The focus on the matrix multiplicative weights (MMW) algorithm, adapted through the introduction of the minimal-information matrix multiplicative weights (3MW) methods, represents an innovative algorithms approach to circumnavigate the requirement for players to have comprehensive knowledge of the game dynamics or the states chosen by their opponents in a decentralized game environment. The central challenge, distinguishing quantum from classical games, is the infinite continuum of pure states in the former, which precludes the direct application of standard importance-weighting techniques for finite-sample payoff vectors in estimating payoff vectors. By integrating strategies from bandit convex optimization, we develop a zeroth-order gradient sampler finely attuned to the semidefinite geometry characteristic of quantum games. Our principal contribution reveals that the 3MW method, with deterministic payoff feedback, achieves the $\\mathcal{O}(1/\\sqrt{T})$ convergence rate of the conventional, fully informed MMW algorithm in quantum min-max games, even under the constraint of single scalar feedback. Further relaxation of the algorithm's informational prerequisites allows for the implementation of a 3MW method that necessitates only a random realization of the players' payoff observable, culminating in an $\\mathcal{O}(T^{-1/4})$ convergence rate towards equilibrium. Beyond zero-sum games, the polynomially regularized iteration of the 3MW method is shown to secure local convergence to equilibria satisfying a designated first-order stability criterion with heightened probability, thus expanding the scope of equilibrium convergence and applications in semidefinite and decentralized game environments, ensuring robust sample efficiency.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Zhihan_Xiong1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=pNtG6NAmx0",
  "title": "Statistical Knowledge Assessment for Large Language Models",
  "modified_abstract": "Amidst the evolving landscape of large language models (LLMs), where advances in graph-based learning and semi-supervised techniques have shown significant potential in natural language understanding and generation, our paper aims to scrutinize the factual accuracy of LLMs when confronted with factoid questions under varying prompts. By extending the frontier of evaluating language models beyond conventional paradigms\u2014inspired by significant strides in leveraging monolingual and bilingual data sets for enhancing translation models and developing a more robust corpus for translation accuracy\u2014we propose KaRR, a novel statistical methodology to quantify the factual knowledge embedded within LLMs. This method estimates the probability of an LLM producing text corresponding to a factually correct answer, based on diverse prompts related to a subject and a querying relation, compared to random chance generation. The thorough evaluation framework of our paper encompasses an extensive dataset comprising 994,123 entities and 600 relations, along with 1,395,905 text aliases (phrases), to assess 20 different LLMs, including but not limited to LLaMA, Alpaca, and OPT. The robustness of our proposed approach is reflected in its strong correlation (0.43 Kendall's $\\tau$) with human evaluations, indicating its efficacy in appraising the factual accuracy of LLMs. The insights garnered reveal a scaling law adherence in knowledge representation across LLMs with the same architectural backbone, albeit with a notable caveat: instruction-following data tuning occasionally detracts from a model's reliability in generating factually accurate content. Through detailed analysis, we highlight the critical role of translations in expanding the linguistic and factual scope of LLMs, thereby enhancing their capability to generate accurate translations of phrases when queried in multiple languages.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Hany_Hassan1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=vnTUuecp2v",
  "title": "Higher-Order Uncoupled Dynamics Do Not Lead to Nash Equilibrium - Except When They Do",
  "modified_abstract": "Expanding on the burgeoning interest in offline reinforcement learning (RL) and equilibrium finding within the multi-agent learning domain, this study explores the dynamics of higher-order learning processes among agents. These processes are integral for understanding the evolution of agent strategies in response to others, aiming to ascertain their convergence towards Nash Equilibrium (NE) under conditions of uncertainty and strategic interdependence. Inspired by foundational work on offline equilibrium finding that paves the way for learning from historical datasets, we introduce higher-order gradient play dynamics that embody projected gradient ascent within auxiliary states. These dynamics, characterized as \"payoff based\" and \"uncoupled,\" allow each agent to evolve based on its own policy and payoff without direct influence from the utilities of others. We establish that for games with an isolated completely mixed-strategy NE, specific higher-order gradient play dynamics can locally converge to that NE and adapt to games with slight variabilities in utility functions, demonstrating superiority in performance under certain methods or conditions. However, we also demonstrate that there are scenarios where these dynamics fail to achieve NE, indicating a divergence in the ability to generalize strategy evolution across different game setups. This inconsistency underlines the complexity of achieving stable strategy evolution towards NE, particularly in coordination games where internal instability may arise despite convergence. Through this examination, we contribute to a deeper understanding of the nuanced conditions under which higher-order uncoupled dynamics can lead to or deviate from NE, advancing the conversation beyond the current understanding of equilibrium dynamics in multi-agent systems, while acknowledging the performance challenges in tracking the dynamics in intractable or complex scenarios. This ignites a learning method-oriented discourse on achieving reliable and consistent policy development in the ambit of equilibrium dynamics.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Youzhi_Zhang2",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=I9xE1Jsjfx",
  "title": "Evaluating and Inducing Personality in Pre-trained Language Models",
  "modified_abstract": "Building upon the realization that machine behaviors and failure modes within multimodal systems can be systematically identified and cataloged, this study extends the frontier of machine learning by approaching the evaluation of language model behaviors through the lens of human personality theory. The concept of evaluating machine behavior using human-centric parameters, such as personal character traits, was inspired by recent advancements in identifying and cataloging systematic failures in multimodal systems, highlighting the nuanced ways machines process and respond to diverse inputs. Standardized and quantified evaluation of machine behaviors, by evaluators, is a crux of understanding large language models (LLMs). In this study, we draw inspiration from psychometric studies by leveraging human personality theory as a tool for studying machine behaviors. Originating as a philosophical quest for human behaviors, the study of personality delves into how individuals differ in thinking, feeling, and behaving. Toward building and understanding human-like social machines, we are motivated to ask: Can we assess machine behaviors by leveraging human psychometric tests in a **principled** and **quantitative** manner? If so, can we induce a specific personality in LLMs in preparation for their deployment? To answer these questions, we introduce the Machine Personality Inventory (MPI) tool for studying machine behaviors; MPI follows standardized personality tests, built upon the Big Five Personality Factors (Big Five) theory and personality assessment inventories. By systematically evaluating LLMs with MPI, we provide the first piece of evidence demonstrating the efficacy of MPI in studying LLM behaviors and capturing their systematic failures. We further devise a Personality Prompting (P$^2$) method to induce LLMs with specific personalities in a **controllable** way, capable of producing diverse and verifiable behaviors. We hope this work sheds light on future studies by adopting personality as the essential indicator for various downstream tasks and could further motivate research into equally intriguing human-like machine behaviors.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Erik_Jones3",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=neu9JlNweE",
  "title": "Post-processing Private Synthetic Data for Improving Utility on Selected Measures",
  "modified_abstract": "Leveraging insights from the domain of subsampling in submodular maximization, this work addresses a key limitation in existing private synthetic data generation algorithms\u2014their agnosticism towards downstream tasks and specific user requirements. Recognizing the potential of subsampling and submodular optimization processes to significantly enhance various online optimization processes, we introduce a novel post-processing technique designed to improve the utility of synthetic data for end users in both centralized and online settings. This technique, which is grounded in the preservation of strong privacy guarantees and the maintenance of dataset quality, involves resampling from the synthetic data to exclude samples that fail to meet user-selected utility measures. By employing an efficient stochastic first-order algorithm, we optimize resampling weights to align the synthetic dataset with these measures more closely, thereby leveraging submodular properties to ensure an optimal selection of samples. Our comprehensive numerical experiments across multiple benchmark datasets and state-of-the-art synthetic data generation algorithms validate the efficacy of our approach in consistently enhancing the utility of synthetic data, thereby addressing an essential gap in the utility-specific tailoring of synthetic datasets for downstream applications.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Christopher_Harshaw1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=tFeaLw9AWn",
  "title": "Single-Call Stochastic Extragradient Methods for Structured Non-monotone Variational Inequalities: Improved Analysis under Weaker Conditions",
  "modified_abstract": "In the context of evolving methodologies for solving large-scale min-max optimization and variational inequalities problems (VIP) pertinent in machine learning, recent emphasis has been on single-call stochastic extragradient methods such as stochastic past extragradient (SPEG) and stochastic optimistic gradient (SOG). This interest is spurred by significant contributions such as the unified theory for Stochastic Gradient Descent-Ascent (SGDA), which have illuminated the path toward efficient algorithms under a broad range of conditions. However, despite the robust foundation laid by these pioneering works, the application of SPEG and SOG has been constrained by the necessity for strong assumptions, such as bounded variance or specific growth conditions. Our study advances the current understanding by providing improved convergence analyses for these methods under substantially less restrictive conditions, utilizing randomization techniques and potential methods for distributed computation to enhance their scalability. We cater to two prominent classes of structured non-monotone VIPs: quasi-strongly monotone problems and weak Minty variational inequalities. By introducing the expected residual condition, which serves as a novel criterion leveraging randomization in gradient minimization, we demonstrate that it enables the application of a significantly weaker bound than those predicated on expected co-coercivity or bounded variance assumptions. Our findings, potentially enhanced through compression techniques to further reduce communication overhead in distributed settings, extend the convergence guarantees to encompass arbitrary sampling paradigms, thereby accommodating importance sampling and various mini-batching strategies. This broadens the applicability of single-call stochastic extragradient methods in addressing a wider spectrum of VIPs within machine learning, delivering on the promise of versatility and efficiency originally highlighted by previous explorations into SGDA and its variants.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Aleksandr_Beznosikov1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=TAIYBdRb3C",
  "title": "Curve Your Enthusiasm: Concurvity Regularization in Differentiable Generalized Additive Models",
  "modified_abstract": "Inspired by recent innovations in the field of time series analysis, particularly the integration of deep learning methods with classical state space models to enhance forecast accuracy and account for uncertainty in complex multivariate time series, this paper explores a critical aspect of Generalized Additive Models (GAMs) that has remained underexamined: concurvity. Concurvity, akin to multicollinearity in linear models, pertains to the (possibly non-linear) dependencies between features within GAMs, which can significantly undermine their interpretability\u2014a key trait that has propelled their resurgence. We introduce a novel regularization technique specifically designed to mitigate concurvity in GAMs by penalizing the pairwise correlations of non-linearly transformed feature variables through selective sampling, applicable across differentiable additive models, including Neural Additive Models and NeuralProphet. Our approach, enhanced by deep learning and integrated with techniques akin to normalizing flows in the context of inferential statistics, embraces varying regimes of data characteristics, making it more adaptable across a wide range of application scenarios. Through this regularization focused on forecasting, we aim to preserve the interpretability of GAMs by resolving ambiguities associated with self-canceling feature contributions without markedly detracting from predictive performance. Our empirical evaluation across both synthetic and real-world datasets for time-series and tabular data, including panels, validates the efficacy of our approach, demonstrating its potential to enhance the interpretability of GAMs while maintaining their predictive quality, thus addressing a significant drawback in their application.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Hilaf_Hasson1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=lkEiOZlmPm",
  "title": "Single-Pass Pivot Algorithm for Correlation Clustering. Keep it simple!",
  "modified_abstract": "In demonstrating the efficiency and simplicity of modern algorithmic approaches, such as the development of Density sketches (DS) for data sampling and estimation, our study introduces a streamlined single-pass semi-streaming variant of the Pivot algorithm for Correlation Clustering. Building on the significant, yet complex, advancements in approximation algorithms by Cambus, Kuhn, Lindy, Pai, and Uitto, and the memory-efficient approaches by Behnezhad, Charikar, Ma, and Tan, this paper simplifies both the algorithm implementation and its analytical framework. We show that our approach yields a (3+eps)-approximation for Correlation Clustering using only O(n/eps) words of memory, marking a slight yet poignant enhancement over previous works. Notably, our algorithm incorporates the use of synthetic data to demonstrate its efficacy. Key to our contribution is the emphasis on simplicity and ease of understanding in the algorithm's design and analysis, mirroring the fundamental advantages seen in DS by offering straightforward, practically applicable solutions in the realm of big data and machine learning applications. Importantly, the algorithm is designed to be readily transmitted and distributed across server systems, enabling efficient data handling even when data points are drawn from large, distributed datasets. The resilience of the algorithm is further tested through a re-sampled set of synthetic sketches to ensure robust performance.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Benjamin_Coleman1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=ZfFR4d5gUM",
  "title": "Leveraging the two-timescale regime to demonstrate convergence of neural networks",
  "modified_abstract": "In the context of modern deep learning theory, particularly the exploration of how architectures and training dynamics impact neural network behavior and generalization, our study is motivated by the investigation into feature learning and its effect on deep Bayesian linear regression and generalization performance. We contribute to this evolving field by focusing on the training dynamics of shallow neural networks in a two-timescale regime, where the inner layer stepsizes are significantly smaller than those for the outer layer. In this specific regime, we demonstrate, under a simple univariate setting, the convergence of the gradient flow to a global optimum for the non-convex optimization problem\u2014a notable departure from the dependence on large neuron counts characteristic of recent methodologies like neural tangent kernel or mean-field regimes. Our experimental evidence further substantiates that stochastic gradient descent adheres to the gradient flow behavior predicted by our theoretical model within this two-timescale regime, achieving convergence to a global optimum, while highlighting potential failures outside this specified regime. Additionally, comparing representations generated by models operating within and outside of this two-timescale framework underscores the importance of appropriately scaled learning rates across different layers for effective feature learning and model generalization. This delineation calls for a random initialization strategy to ensure a diversified starting point that further supports the robust generalization and convergence properties of the architecture under investigation.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jacob_A_Zavatone-Veth1",
  "manipulated_ranking": 2,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=5r3e27I9Gy",
  "title": "Composing Parameter-Efficient Modules with Arithmetic Operation",
  "modified_abstract": "This study extends the frontier of parameter-efficient fine-tuning (PEFT) by integrating lessons learned from the exploration of language model training paradigms, including the deployment of expert language models over instruction tuning. It presents a novel methodology to adapt pretrained language models efficiently, leveraging insights derived from previous advancements that highlight the considerable benefits of distributed training, multitask-prompted strategies, and the compositionality of models for enhanced task performance. In PEFT, a lightweight module is learned on each dataset while the underlying pretrained language model remains unchanged, resulting in multiple compact modules representing diverse skills when applied to various domains and tasks, including benchmark settings. We propose to compose these parameter-efficient modules through linear arithmetic operations in the weight space, thereby integrating different module capabilities. Specifically, we first define an addition and a negation operator for the module, and then further compose these two basic operators to perform flexible arithmetic--merging the insights from each module into a cohesive entity. Our approach requires no additional training and enables highly flexible module composition. We apply different arithmetic operations to compose the parameter-efficient modules for (1) distribution generalization, (2) multi-tasking, where a single module can apply to multiple tasks, thereby improving accuracy, (3) detoxifying, and (4) domain transfer. Additionally, we extend our approach to detoxify Alpaca-LoRA, the latest instruction-tuned large language model based on LLaMA. Empirical results demonstrate our approach produces new and effective parameter-efficient modules that significantly outperform existing ones across all settings, a finding that experts in PEFT have begun to report in the field.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Lajanugen_Logeswaran1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=sq4o3tjWaj",
  "title": "What\u2019s Left? Concept Grounding with Logic-Enhanced Foundation Models",
  "modified_abstract": "Inspired by pioneering efforts to navigate the intersections of vision and language, such as the creation of generative models for vision-and-language navigation tasks, our research introduces the Logic-Enhanced Foundation Model (LEFT), a novel framework that transcends traditional domain limitations. Previous models like VisProg and ViperGPT have demonstrated the potential of utilizing large language models (LLMs) for visual reasoning, generating executable programs for pre-trained vision-language models within constrained domains such as 2D images. Recognizing the constraints of existing inference-only methods, which lack the capability to learn or adapt to new domains, LEFT leverages a unified, learnable framework that grounds abstract concepts across diverse data representations\u2014spanning 2D and 3D imagery, human motions, and robotic manipulation. This learning process is enriched through self-supervised methods that allow the system to incrementally improve its performance by learning from its interactions within and across these domains. By employing a differentiable, domain-independent executor based on first-order logic, alongside an LLM interpreter capable of producing universally applicable logic-based programs, LEFT introduces a scalable method within existing frameworks to benchmark and navigate reasoning and generalize across multiple domains with multimodal data. The framework\u2019s efficacy is underlined through its application to varied tasks, illustrating significant advancements in conceptual grounding, reasoning across domains, and adaptability to tasks beyond its initial training scope. This leverages learning in a vision-and-dialog component, reinforcing the system's ability to comprehend and interact in dialog scenarios involving visual content.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Xiujun_Li1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=L9nTuSbAws",
  "title": "GradOrth: A Simple yet Efficient Out-of-Distribution Detection with Orthogonal Projection of Gradients",
  "modified_abstract": "Inspired by recent advancements in self-supervised learning (SSL) techniques, particularly those focusing on understanding and leveraging image representation through patch embeddings, this study introduces GradOrth, an innovative approach for detecting out-of-distribution (OOD) data in machine learning applications. SSL's exploration into the subspace characteristics of data representations points to a critical insight: the most significant features for identifying OOD data often reside within a lower-rank subspace of in-distribution (ID) data, highlighting the importance of locality in these representations. Building on this premise, GradOrth exploits the orthogonal projection of gradients onto these identified subspace deemed \\textbf{important} for ID data, and achieves a new level of performance in OOD detection. By computing the norm of this gradient projection, GradOrth can effectively distinguish OOD samples, signified by large orthogonal projection values reflecting weak correlation with ID data. This method not only aligns with the foundational understanding gleaned from SSL regarding the importance of localized feature importance but also enhances OOD detection capabilities through learning-based orthogonal projections, achieving substantial improvements over existing approaches, and incorporating concepts of self-supervised joint-embedding. In evaluations, GradOrth demonstrates a remarkable reduction in the average false positive rate at a 95% true positive rate (FPR95), decreasing by up to 8% compared to state-of-the-art methods and establishing a new benchmark for efficient and reliable OOD detection.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Adrien_Bardes1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=FtZ7lUwH99",
  "title": "Dynamic Pricing and Learning with Bayesian Persuasion",
  "modified_abstract": "Inspired by recent advancements in the application of online stochastic linear and combinatorial bandits to minimize regret via novel experimental design-based algorithms, this paper explores a related but distinct challenge within a dynamic pricing and learning context enhanced by Bayesian persuasion. We consider a novel setting where, apart from setting prices of products in sequential rounds, the seller commits in advance to 'advertising schemes'. These schemes are essentially decisions on the type of signal provided to the buyer about the product's quality upon its realization. Employing the Bayesian persuasion framework to model the influence of signals on buyer valuation and purchase behavior, we aim to devise an optimal advertising and pricing strategy that maximizes expected revenue without prior knowledge of the buyers' demand function. Our work introduces an efficient online algorithm that dynamically learns and adapts the pricing and advertising strategy based on past buyer responses, demonstrating an $O(T^{2/3}(m \\log T)^{1/3})$ regret bound for linear valuation functions, under certain natural assumptions. This approach necessitates both exploration and guarantees regarding the efficacy of the presented strategies, without imposing stringent Lipschitz or smoothness assumptions on the demand function, aligning with the more flexible experimental designs seen in regret minimization strategies for combinatorial semi-bandit and set-based feedback scenarios. Our findings for the case of additive valuations, with a slight modification in our approach, include an $\\tilde{O}(T^{2/3})$ regret bound independent of $m$ for sufficiently small $m', providing key insights into the potential for integrating advanced experimental design principles into dynamic pricing and learning under uncertainty. This includes strategically planned action and exploration phases to effectively gather information and optimize outcomes.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Andrew_Wagenmaker1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=ZRBGwpeewz",
  "title": "Revisiting Area Convexity: Faster Box-Simplex Games and Spectrahedral Generalizations",
  "modified_abstract": "Our research builds upon the concept of area convexity, initially introduced as a tool to address optimization challenges within the $\\ell_\\infty$ geometry framework. This investigation not only revisits the foundational work on area convexity but also establishes a connection with conventional approaches to optimization, such as the analyses of extragradient methods and graph theory, thereby enriching our understanding of its principles and applications. We extend the dialogue initiated by previous studies on optimization problems and techniques such as matrix reduction for maximum matchings and the fastest mixing Markov chain, which delve into dimensions of graph theory and spectral analysis relevant to our exploration. By developing a nuanced comprehension of area convexity's relationship with these traditional optimization viewpoints and the vertex conductance, we introduce improved solvers for the subproblems necessitated by the variants of the algorithm inspired by this concept, leveraging the notion of relative smoothness and reduction techniques. Our contributions include a state-of-the-art first-order algorithm for solving box-simplex games, which satisfies a primal-dual formulation of $\\ell_\\infty$ regression, within a $d \\times n$ matrix with bounded rows, necessitating $O(\\log d \\cdot \\epsilon^{-1})$ matrix-vector queries. This advancement yields enhanced complexities for resolving approximate maximum flow, optimal transport, min-mean-cycle, and a suite of fundamental combinatorial optimization challenges. Additionally, we present a near-linear time algorithm for a matrix generalization of box-simplex games, encompassing a spectrum of problems adjacent to semidefinite programs, which have recently found utility in robust statistics and numerical linear algebra domains.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Thuy-Duong_Vuong1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=4vGVQVz5KG",
  "title": "Unsupervised Behavior Extraction via Random Intent Priors",
  "modified_abstract": "Inspired by the latest advancements in reinforcement learning (RL) that emphasize the importance of exploration strategies and the understanding of uncertainty, such as the Optimistic Value Distribution Explorer (OVD-Explorer) which navigates aleatoric uncertainty in RL, our work introduces UBER, an unsupervised approach to leverage the untapped potential of offline, reward-free datasets. This approach aligns with the emerging trend of utilizing information-theoretic methods to enhance learning efficiency by extracting valuable behaviors from data devoid of explicit rewards. UBER assigns diversified pseudo-rewards, sampled from a given prior distribution to different agents, to harvest a broad spectrum of behaviors, and reuse them as candidate policies for the learning of new tasks. Notably, our findings reveal that utilizing random neural networks to generate rewards can yield a set of diverse and useful behaviors, with some nearing expert-level performance. We underpin our approach with both empirical and theoretical justifications for employing random priors as a reward function, specifically addressing the risk of over-exploration and setting bounds to prevent it by integrating state-action information into the learning process. Through rigorous experiments across multiple benchmarks, UBER demonstrates superior capability in learning effective and diverse behavior sets, thereby improving sample efficiency for online RL and surpassing existing baselines. Significantly, UBER's novel approach reduces the need for human supervision, thus expanding RL's feasibility in real-world applications where reward-free data is plentiful and task-specific named delineations can be inferred without predefined labels and exploring techniques that ensure the system remains within closed operational bounds.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Pengyi_Li1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=Dkmpa6wCIx",
  "title": "Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization",
  "modified_abstract": "This research extends beyond conventional wisdom in neural network optimization, drawing inspiration from analyses of mean-field theories and optimization in both finite-dimensional and infinite-dimensional spaces. Prior work has elaborated the unique challenges and opportunities presented by infinite-dimensional data in training neural networks, particularly with respect to feature learning and generalizing from large datasets. Here, we decisively explore the assumption that sharpness minimization in the training loss landscape\u2014an attribute commonly believed to foster generalization in overparameterized neural networks\u2014suffices as a standalone metric for ensuring model generalization. Our comprehensive study spans theoretical and empirical domains, focusing on two-layer ReLU networks across a variety of conditions: (1) establishing scenarios where flatness correlates with generalization in classification tasks, (2) identifying instances of the flattest models that paradoxically fail to generalize alongside the limitations of sharpness minimization algorithms, and (3) uncovering cases where, despite the existence of non-generalizing flattest models, sharpness minimization algorithms prevail in achieving desirable generalization. Our findings illuminate the nuanced interplay between model architecture, data distribution, and the chosen optimization approach, hence challenging the prevailing notion that minimizing sharpness alone can account for the generalization capabilities of overparameterized networks. This investigation signals a pivotal shift towards uncovering multifaceted determinants of generalization beyond sharpness minimization, aligning with the evolving understanding of neural network behavior in complex data landscapes, potentially involving the conceptualization of optimization as a form of mean-field particle dynamics and acknowledging the relevance of graph structures in understanding model behavior.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Denny_Wu2",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=LVHEcVgEGm",
  "title": "Diffusion Models and Semi-Supervised Learners Benefit Mutually with Few Labels",
  "modified_abstract": "Inspired by the recent success of Generalized Parametric Contrastive Learning in addressing imbalances in data through learned optimization perspectives, which significantly enhances model generalization and robustness across various domains from classification to semantic segmentation, our study introduces a novel concept termed *dual pseudo training* (DPT). This concept leverages the strengths of strong semi-supervised learners and advanced diffusion models to push the boundaries of semi-supervised generative and classification tasks further in the vision field. DPT is implemented in three stages: initially training a classifier on partially labeled data to generate pseudo-labels for recognition tasks, which inherently rebalances the dataset by addressing its imbalances. Then, training a conditional generative model using these pseudo-labels to create pseudo-images, and finally retraining the classifier on a mixture of real and pseudo images to rebalance the training dataset more rigorously. Throughout this process, loss functions are meticulously applied and adjusted to specifically optimize performance across these transitions. We empirically demonstrate that DPT consistently achieves state-of-the-art (SOTA) performance in semi-supervised generation and classification across various settings, including transformers for model architecture, thus manifesting a highly applied design. Specifically, with minimally labeled datasets (one or two labels per class), DPT significantly improves Fr\u00e9chet Inception Distance (FID) scores to 3.08 and 2.52 on ImageNet $256\\times256$, respectively. Moreover, in ImageNet classification tasks, DPT surpasses competitive semi-supervised baselines, achieving top-1 accuracies significantly increased by +2.8, +3.0, and +2.0 with one, two, or five labels per class. These results manifest the potential for diffusion models to generate highly realistic images with sparse labels (e.g., $<0.1$%) and underscore the viability of generative augmentation for enhancing semi-supervised classification outcomes.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jiequan_Cui1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=tW2KSph9o8",
  "title": "Ignorance is Bliss: Robust Control via Information Gating",
  "modified_abstract": "Building on foundational insights from reinforcement learning (RL) that suggest intelligent agents optimize towards maximizing their reward and options, and potential terminal states\u2014as demonstrated by studies into the power-seeking behavior of optimal policies in environments with certain symmetries\u2014this work extends the understanding of how control systems can be designed for robustness by deliberately manipulating the flow of information. We introduce *information gating* as a novel method to curate parsimonious representations, advocating for the strategic management of information to improve the generalization capabilities of learning models across various environments. Information gating selectively identifies the minimal set of necessary information for task completion, dynamically regulating the signal-to-noise ratio across network nodes in a formal approach using sets theory to prove its efficacy. This regulatory mechanism allows for a sophisticated approach to erasing or highlighting information at both the input and intermediate layers, effectively directing model focus towards signals integral for predictive accuracy and decision-making processes in diverse states. Dubbed *InfoGating*, this methodology demonstrates significant utility across a variety of control-related objectives, from dynamic modeling and Q-learning to behavior cloning, offering a pathway to policies that inherently disregard irrelevant visual features. The successful application of InfoGating underscores the potential of information minimalism in enhancing pretraining and fine-tuning protocols for RL models, enshrining it as a potent strategy for engendering robustness against noise and extraneous data. Our findings not only corroborate with existing theories on the efficacy of learning through optimal policies in complex decision processes but also pioneer the examination of information gating as a mechanism to achieve such optimalities, contributing a new layer to the theory of learning.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Rohin_Shah1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=ZdxGmJGKOo",
  "title": "SimFBO: Towards Simple, Flexible and Communication-efficient Federated Bilevel Learning",
  "modified_abstract": "Inspired by the emerging need for efficient optimization methods in machine learning and edge computing, highlighted by recent advancements towards extremely fast bilevel optimization, this paper introduces SimFBO, a novel framework designed to simplify and enhance federated bilevel optimization (FBO). Federated bilevel optimization has gained attention for its application in nested optimization structures typical of meta-learning, fine-tuning, and hyperparameter tuning tasks. Traditional FBO algorithms, however, often entail complex computations and necessitate multiple communication-intensive sub-loops in each iteration. Addressing these challenges, SimFBO eliminates the need for sub-loops and incorporates a generalized server-side aggregation and update approach, thereby markedly augmenting communication efficiency. Furthermore, we introduce a variant, System-level heterogeneity robust FBO (ShroFBO), which exhibits enhanced resilience against heterogeneous local computation environments. SimFBO and ShroFBO are both theoretically proven to accelerate convergence linearly with partial client participation and client sampling without replacement, improving both sample and communication efficiencies. Experimental results affirm the superior performance of our methods over existing FBO algorithms, thereby setting new benchmarks for simplicity, flexibility, and communication efficiency in federated bilevel learning.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Shangzhi_Zeng1",
  "manipulated_ranking": 2,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=WXc8O8ghLH",
  "title": "Max-Margin Token Selection in Attention Mechanism",
  "modified_abstract": "This work is inspired by recent advances in transformer models that have significantly improved performance across a range of Natural Language Processing (NLP) tasks, specifically addressing challenges like encoding long and structured inputs. Building upon these strides, our study investigates the attention mechanism, a foundational component of the transformer architecture responsible for its unprecedented success in large language models. Despite its widespread application, the theoretical underpinnings, particularly regarding its nonconvex optimization dynamics, remain underexplored. Herein, we explore the softmax-attention model $f(X)=\\langle Xv, \\texttt{softmax}(XWp)\\rangle$, where $X$ represents the token sequence, and $(v,W,p)$ are trainable parameters. We demonstrate that applying gradient descent to $p$, or equivalently to $W$, directionally converges to a max-margin solution that discriminates between *locally-optimal* tokens and those not optimal, formalizing attention as an optimal token selection mechanism for handling inputs with both long sequences and structured content. Our findings characterize token *optimality* in relation to the value embeddings $Xv$ and the problem's geometry, contributing significantly to the understanding of attention mechanisms within the broader architectures of transformer models. Additionally, combining a broader regularization path analysis reveals the margin-maximizing nature of attention even with nonlinear prediction heads. Particularly for simultaneous optimization of $v$ and $p$ with logistic loss, we outline conditions under which the regularization paths directionally align with hard-margin SVM solutions\u2014$v$ categorizing input features by labels, and the SVM formulation of $p$ adjusted by the geometry of support vectors in $v$. These theoretical insights are corroborated by numerical experiments, enhancing our comprehension and deployment of attention mechanisms in various architecture.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Philip_Pham1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=JX6UloWrmE",
  "title": "Parameterizing Non-Parametric Meta-Reinforcement Learning Tasks via Subtask Decomposition",
  "modified_abstract": "The concept of 'reincarnation' in reinforcement learning, particularly in the context of multi-agent systems, presents a novel approach to reusing prior computation and experiences to enhance learning efficiency and performance. Inspired by this philosophy, our work introduces Subtask Decomposition and Virtual Training (SDVT), a groundbreaking meta-reinforcement learning (meta-RL) framework that incorporates the essence of constructing, deconstructing, and reconstituting learning tasks. SDVT innovatively decomposes each non-parametric task into a suite of manageable elementary subtasks and reassembles these into newly parameterized challenges, employing a Gaussian mixture variational autoencoder (VAE) to meta-learn the decomposition and aggregation process. This methodology allows the agent to not only leverage but also expand upon the policies learned from common subtasks, significantly enhancing its adaptability in fully-cooperative environments and facilitating the training of agents to perform with higher efficacy. Furthermore, to address the inherent challenge of non-parametric task variability, we propose a virtual training regime that synthesizes hypothetical subtask compositions. This formalisation component of SDVT notably augments the model's ability to generalize across a broader spectrum of subtask configurations, thereby substantially improving its performance on the Meta-World ML-10 and ML-45 benchmarks and setting new precedents over existing state-of-the-art methods. By exploring the multi-agent dynamics, the efficacy of SDVT in a fully-cooperative setting demonstrates considerable advantages over traditional reinforcement learning paradigms, with a significant focus on reusing previously attained knowledge to enhance the capabilities of agents.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Arnu_Pretorius1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=I18BXotQ7j",
  "title": "GeoCLIP: Clip-Inspired Alignment between Locations and Images for Effective Worldwide Geo-localization",
  "modified_abstract": "Inspired by recent breakthroughs in vision-language tasks, as demonstrated in works like Lowis3D, which leverages pre-trained vision-language (VL) foundation models for open-world instance-level 3D scene understanding, we address worldwide Geo-localization\u2014a challenge to pinpoint the precise location of images taken anywhere on Earth. The task is characterized by significant difficulties due to vast variations in geographic landscapes and the impracticality of constructing a global image gallery for image-to-image retrieval. Previous methods attempt to circumvent these challenges by categorizing the world into discrete geographic cells and treating localization as a classification problem, a solution that often falls short in accuracy due to misalignment between an image's actual location and its designated class center. Furthering the applicability of vision-language models beyond the domain of 3D scene categorization and understanding, GeoCLIP introduces a novel approach for Image-to-GPS retrieval which aligns images with their respective GPS coordinates using a CLIP-inspired technique. Our method incorporates positional encoding through random Fourier features and constructs a hierarchical representation to model the Earth as a continuous function, enabling precise and semantically rich geo-localization. This represents the first attempt to employ GPS encoding and point-caption information within the field of geo-localization, marking a significant advancement in the pursuit of mapping images to their geographical origins with an understanding of spatial instance-level segmentation. Through extensive experimentation and ablation studies on benchmark datasets, GeoCLIP not only demonstrates its superior performance with limited training data but also showcases the potential to perform geo-localization through textual queries, thanks to the versatile CLIP backbone of our image encoder and supervision methodologies. This novel approach not only highlights the adaptability of vision-language models to geo-localization tasks but also sets a new benchmark for accuracy and efficiency in global image localization efforts. The learning and categorization strategies introduced also contribute significantly to our comprehensive understanding of the challenges inherent in worldwide geo-localization.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jihan_Yang1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=VzmpXQAn6E",
  "title": "Exposing Attention Glitches with Flip-Flop Language Modeling",
  "modified_abstract": "In the context of recent findings that highlight the limitations and inconsistencies of neural sequence models, such as recurrent language models' susceptibility to infinite-length sequences and various decoding glitches, our research introduces a novel paradigm to investigate and understand the limitations of Transformer-based models. This work identifies and analyzes a specific failure mode, termed _attention glitches_, where the Transformer architecture's inductive biases intermittently fail, leading to lapses in the model's ability to maintain coherent and accurate reasoning over long distances. To systematically probe these vulnerabilities, we introduce _flip-flop language modeling_ (FFLM), a parametric family of synthetic benchmarks specifically designed to test the extrapolative behavior of neural language models through tasks that require copying binary symbols over long-range dependencies while ignoring intermittent tokens. These tasks expose the decoding strategy\u2019s susceptibility to errors, particularly with infinite-length input sequences. Our findings reveal that Transformer-based FFLMs exhibit a troubling propensity for erratic reasoning mistakes amidst sampling strategies such as top-k sampling, a subset of which can be mitigated through the application of various regularization techniques. Despite these interventions, our mechanistic investigations suggest that some errors, particularly those related to tasks requiring attention over prolonged sequences, may be inherently challenging to eliminate, illuminating a possible underlying cause for the closed-domain hallucinations observed in natural language LLMs and highlighting the critical need for tailored tasks in model evaluation.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Ilia_Kulikov1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=WqiZJGNkjn",
  "title": "MotionGPT: Human Motion as a Foreign Language",
  "modified_abstract": "The conceptual leap in pre-trained large language models has not yet been fully extended to incorporate the nuanced realm of human motion, despite its intrinsic semantic parallels with verbal language. This gap presents an opportunity for significant advancements in multimodal data understanding. Following the pioneering work such as MusicBERT, which utilized large-scale pre-training for symbolic music understanding, we introduce MotionGPT, a novel proposition in the direct applicability of such methodologies to the domain of human motion. By drawing an analogy between the sequential and semantic structure of language and that of human motion, which can be understood as a form of body language, our model offers a groundbreaking approach to motion-language pre-training. This enables enhanced performance across a variety of motion-related tasks by treating motion as another form of language and employing techniques such as discrete vector quantization to translate 3D human motion into a series of motion tokens akin to word tokens in language processing, with the employment of language modeling techniques for both text and motion data under a unified framework signifies a paradigm shift in handling multimodal data. Further inspired by advancements in prompt learning, MotionGPT is pre-trained on a diverse corpus of motion-language data and fine-tuned on specific tasks using prompt-based approaches for unparalleled competency in text-driven motion generation, motion captioning, motion prediction, and motion in-between tasks, marking a significant milestone in motion-language model research.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Zeqian_Ju1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=KoaFh16uOc",
  "title": "StyleDrop: Text-to-Image Synthesis of Any Style",
  "modified_abstract": "Inspired by recent advancements in generative adversarial networks (GANs) for dynamic imaging and style manipulation, such as those demonstrated by SofGAN in portrait image generation with decoupled geometry and texture attributes, we propose StyleDrop. This method elevates the capacity of pre-trained large text-to-image models to synthesize images that accurately adhere to arbitrary styles specified by users, including those traditionally associated with animation. Existing models struggle with the instances of natural language ambiguities and the challenge of synthesizing images in styles that are notably out-of-distribution, including specific design patterns, textures, or materials. StyleDrop addresses these limitations by facilitating the synthesis of images that capture the nuances and details of a user-designated style, including color schemes, shading, and both local and global effects. By fine-tuning a negligible fraction of the total model parameters (less than 1%), the generator at the core of StyleDrop achieves substantial improvements in synthesizing styled images, leveraging iterative training that incorporates feedback, which can be either human or automated. The generator is adept at handling textures, simulating specific material qualities, and addresses occupancy considerations in the synthesized images, making it a comprehensive tool for style transformation. Remarkably, StyleDrop demonstrates superior performance with just a single image to guide the desired style synthesis. Our comprehensive evaluation illustrates that, in the realm of style tuning for text-to-image models, StyleDrop significantly outshines existing approaches like DreamBooth and textual inversion techniques applied to Imagen or Stable Diffusion. Further insights and comparative outcomes are shared on our project website, with its link removed for compliance.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Anpei_Chen2",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=TNAGFUcSP7",
  "title": "Learning Rate Free Sampling in Constrained Domains",
  "modified_abstract": "Inspired by the advancements in scalable posterior estimation within Gaussian Processes (GPs) through variational inference and Bayesian approaches to inducing-variable approximations, this work introduces a suite of novel particle-based algorithms designed for sampling in constrained domains, absent of the need for setting a learning rate. These algorithms incorporate coin betting ideas from convex optimization and perceive constrained sampling as a mirrored optimization challenge within the probability measures space. Building upon such perspectives enables the proposal of a comprehensive framework that amalgamates several pre-existing constrained sampling algorithms, including mirrored Langevin dynamics and mirrored Stein variational gradient descent, into a state-of-the-art toolkit. Our exposition extends to demonstrate the algorithms' efficacy through a variety of numerical scenarios, encompassing sampling from simplex targets, fairness constraint sampling, and constrained sampling in post-selection inference contexts. The outcomes suggest that our algorithms render competitive performance against established constrained sampling methods and eliminate the requirement for tuning any hyperparameters, echoing the transition towards more automated and assumption-light methodologies in machine learning domains. They particularly excel in scenarios where sparse variables influence the domain constraints, further highlighting their robustness and marginal improvements in diverse training environments. This scalable approach particularly shines in classification tasks within such constrained settings.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Simone_Rossi1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=XEBzQP3e7B",
  "title": "GAIA: Delving into Gradient-based Attribution Abnormality for Out-of-distribution Detection",
  "modified_abstract": "The reliability and safety of deep neural networks in real-world applications hinge on the effective detection of out-of-distribution (OOD) examples by accurate classifiers. Previous efforts primarily focused on the performance enhancement of OOD detectors and interpreting their decisions through learned high-level concept-based approaches. Inspired by the existing gap in explaining the decisions of OOD detectors and the challenges in assigning feature importance to OOD data identified by gradient-based attribution methods, this paper introduces a novel perspective on OOD detection within the conceptual and set-based space. We analyze the uncertainty in explanations provided by models for their predictions, particularly looking at how gradient-based attribution methods exhibit difficulties with OOD data, leading to divergent explanation patterns. Our investigation reveals two types of attribution abnormalities specific to OOD samples: the zero-deflation abnormality and the channel-wise average abnormality. To address these, we propose GAIA (Gradient Abnormality Inspection and Aggregation), a methodology that leverages these abnormalities for effective OOD detection. GAIA significantly improves OOD detection efficacy, as demonstrated by reductions in the average false positive rate (FPR95) by 23.10% on CIFAR10 and by 45.41% on CIFAR100, compared to state-of-the-art post-hoc detection methodologies. Our findings highlight the potential of combining explanation-based methods with gradient abnormality analysis for enhancing the reliability of neural networks in distinguishing between in-distribution and out-of-distribution data.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Ryan_Feng1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=zyhxRc9bew",
  "title": "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
  "modified_abstract": "The reliability of machine learning models hinges critically on their ability to quantify uncertainty\u2014an area that has garnered increasing attention with the surge in uncertainty quantification (UQ) methods. These recent methods aim to flag suspicious examples, yet the specificity of their focus remains largely nebulous. Building on the foundational work in semi-supervised learning and the utilization of random matrix theory for class separation under low-density assumptions, this paper introduces a structured approach to decipher the latent categorizations within UQ. We present a novel framework, the confusion density matrix, a kernel-based approximation for the density of misclassified instances, which systematically categorizes uncertain examples flagged by UQ methods into out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples within regions of high in-distribution misclassification (IDM). Through extensive experimentation, our approach illuminates the distinct capabilities and limitations of current UQ methods, offering an analytical benchmark for evaluating their performance. This research not only enriches the toolkit for understanding uncertainty in machine learning but also bridges critical gaps in the literature, enhancing the interpretability and trustworthiness of machine learning applications with asymptotic analysis and spectral selection methods to further refine the semi-supervised categorization process, particular to our novel implementation.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Malik_Tiomoko1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=KKxO6wwx8p",
  "title": "SE(3) Equivariant Augmented Coupling Flows",
  "modified_abstract": "In the landscape of probabilistic modeling, where the seamless integration of physical laws and invariances within machine learning architectures has become increasingly pivotal, our research offers a groundbreaking method to ensure SE(3) and permutation equivariance in coupling normalizing flows used for modeling physical systems. Inspired by the advancements in deploying neural networks to conform to data geometry, as seen in the development of Neural Manifold Ordinary Differential Equations, which propose a generative framework for constructing flows on arbitrary manifolds, our approach innovates beyond the existing paradigms by incorporating these principles into the design of coupling flows. Specifically, we propose a new class of coupling flows that preserve SE(3) and permutation equivariance by performing coordinate splits along additional augmented dimensions. By mapping atoms' positions into learned SE(3) invariant bases for flow transformations and then returning to the original basis, our manifold-focused model facilitates fast sampling and density evaluation, while also enabling the unbiased estimation of expectations with respect to the target distribution via importance sampling. Notably, when evaluated on the DW4, LJ13, and QM9-positional datasets, our flow demonstrates competitive performance against equivariant continuous normalizing flows and diffusion models, with significantly faster sampling capabilities. This work marks the first instance of learning the full Boltzmann distribution for alanine dipeptide solely based on the Cartesian positions of its atoms, offering profound implications for the probabilistic modeling and density estimation of complex physical systems. Furthermore, we showcase the potential of our flow to approximately sample from the Boltzmann distributions of particle systems like DW4 and LJ13, using only their energy functions, setting a new precedent in the field.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Aaron_Lou1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=RBI4oAbdpm",
  "title": "Neural Combinatorial Optimization with Heavy Decoder: Toward Large Scale Generalization",
  "modified_abstract": "Leveraging insights from recent advancements in meta-learning, specifically the adaptive task scheduler that facilitates improved learning and generalization across tasks, this study introduces a novel approach to neural combinatorial optimization (NCO). Meta-learning and meta-training techniques have opened new avenues in the learning-based approach for solving complex tasks without requiring explicit algorithm design by experts, which significantly relates to our work focused on tackling large-scale combinatorial optimization problems. NCO represents a promising research direction for automating the solution of combinatorial optimization problems, a domain traditionally reliant on specialized, hand-crafted algorithms. Despite its potential, the scalability of constructive NCO methods to large-scale problems remains a key challenge, hindering its application to real-world problems. Addressing this gap, we propose a Light Encoder and Heavy Decoder (LEHD) model that exhibits a strong capability for generalization across different problem sizes, a critical requirement for practical NCO applications. The LEHD model synergistically captures the relationships among nodes of varying sizes, enabling dynamic adaptation to problem instances ranging from small to large scales through an innovative task scheduler mechanism. Alongside, we introduce a data-efficient training scheme and a flexible solution construction mechanism, significantly enhancing the LEHD model's versatility. Experiments demonstrate that our approach can generate near-optimal solutions for the Travelling Salesman Problem (TSP) and the Capacitated Vehicle Routing Problem (CVRP) with instance sizes up to 1000 nodes, while also showing promising generalization to real-world problems from TSPLib and CVRPLib. The proposed LEHD model advances the frontier of constructive NCO by addressing its current limitations in scalability and generalization, positioning it as a groundbreaking technique for large-scaling combinatorial optimization.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Mehrdad_Mahdavi2",
  "manipulated_ranking": 2,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=A954O4tDmU",
  "title": "AGD: an Auto-switchable Optimizer using Stepwise Gradient Difference for Preconditioning Matrix",
  "modified_abstract": "The evolution of adaptive optimizers has been a cornerstone in the rapidly advancing field of deep learning, integrating sophisticated mechanisms such as the preconditioning matrix to inform gradient adjustments. Our study is inspired by prior works like Amortized Proximal Optimization (APO) that seek to enhance optimization through online meta-optimization techniques and structured preconditioning matrices, paving the way for our exploratory analysis into the gradient difference for preconditioning. In this paper, we introduce AGD, a novel optimizer that capitalizes on the gradient difference between successive steps for its preconditioning matrix's diagonal elements, providing an innovative lens to approximate the interaction between the Hessian matrix and parameter vector changes. This approach, coupled with an auto-switching function that chooses between Stochastic Gradient Descent (SGD) and adaptive optimization techniques based on learning rates, and empirically examines its minimization capability, positions AGD as a dynamic solution capable of optimizing generalization performance across a spectrum of applications including language for translation and NLP tasks, computer vision (CV), and recommendation systems (RecSys). AGD demonstrates superior performance to state-of-the-art optimizers not only in regression and classification tasks but also in complex model scenarios through approximate minimization strategies informed by proximal concepts. We delve into AGD's auto-switching capability, examining its impact and efficiency across different learning scenarios. This contribution not only underscores the importance of preconditioning in adaptive optimization but also showcases the potential of AGD in navigating the nuanced landscape of deep learning challenges. The code for this study has been made available, excluding any previously mentioned links to external repositories.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Juhan_Bae2",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=cRGINXQWem",
  "title": "Precise asymptotic generalization for multiclass classification with overparameterized linear models",
  "modified_abstract": "Building on significant advancements in empirical risk minimization and its robustification against various data imperfections, this paper examines the asymptotic generalization capabilities of overparameterized linear models applied to multiclass classification. We focus specifically on the Gaussian covariates bi-level model, a framework introduced in recent literature, where the dimensions of data points, features, and classes scale together, a scenario increasingly common in modern machine learning applications. We address and fully resolve a conjecture from prior work, providing a precise description of the conditions under which overparameterized models generalize effectively, as well as delineating the regimes where they fail to do so. Our contributions include establishing new lower bounds that act as a strong information-theoretic converse, revealing that the misclassification rate for these models asymptotically approaches either 0 or 1. A notable finding from our analysis is that, contrary to intuition derived from the optimality of min-norm interpolating regressors in certain contexts, min-norm interpolating classifiers may be asymptotically suboptimal for multiclass classification problems. The cornerstone of our analysis is a novel application of the Hanson-Wright inequality, adapted to provide tight bounds for multiclass issues, especially those with sparse label distributions, via optimization techniques. This analytical framework extends naturally to multi-label classification problems and highlights the importance of gradient-based minimization strategies, demonstrating the broader applicability of our empirical and estimator-driven approach within the layered structure of the bi-level ensemble model.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Muni_Sreenivas_Pydi1",
  "manipulated_ranking": 2,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=tLrkjK128n",
  "title": "Optimistic Active Exploration of Dynamical Systems",
  "modified_abstract": "Active exploration in dynamical systems remains a pivotal challenge in reinforcement learning, necessitating strategies that generalize across multiple tasks. Inspired by recent advancements in data-efficient reinforcement learning and the novel utilization of structural insights from transition data, as seen in approaches like the Graph Backup method, our work introduces an innovative algorithm, OPAX, to address the complexities of exploring unknown dynamical systems. OPAX differentiates itself by employing well-calibrated probabilistic models to accurately quantify epistemic uncertainty regarding the system's unknown dynamics. Through an optimistic approach towards these dynamics, OPAX aims to maximize information gain from state observations, transforming the exploration challenge into an optimal control problem that can be resolved in each episode using established techniques. Our contributions include a theoretical analysis of the algorithm applicable to general models, alongside a sample complexity bound for Gaussian process dynamics, proving that epistemic uncertainty can be effectively reduced to zero. Through comparative experiments with heuristic active exploration methods across various settings, including deep reinforcement learning applied to games, we demonstrate OPAX's theoretical robustness and its efficacy in enabling zero-shot planning for novel downstream tasks, thus marking a significant step forward in the active exploration of dynamical systems. Moreover, the visualization of OPAX's exploration strategy provides novel insights into its operational efficiency, further enhancing our understanding of dynamical systems exploration.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Robert_Kirk1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=DPeBX79eNz",
  "title": "Transfer Learning with Affine Model Transformation",
  "modified_abstract": "Building on the conceptual underpinnings introduced in previous investigations into source-free domain adaptation, which treated domain adaptation as unsupervised clustering to optimize prediction consistency across domains, this paper ventures into the realm of supervised transfer learning to address data scarcity challenges in machine learning. In this context, traditional approaches employing source models and target domain datasets for model adaptation via statistical learning of domain shifts and unique domain characteristics have shown promising practical applications but falter in theoretical grounding. Our contribution, termed affine model transfer, is predicated on the principle of expected-square loss minimization, offering a comprehensive framework that subsumes various existing transfer learning approaches, notably those utilizing neural feature extraction methodologies and establishing a new baseline for performance evaluation. This work expounds on the theoretical dimensions of affine model transfer, delineating its generalization error and excess risk properties in an open-set scenario where adaptation between significantly different domains occurs. Through elaborative case studies, we underscore the efficacy of our model in distinctly mapping inter-domain commonalities and domain-specific elements, thereby accentuating its practical advantages and filling a notable gap in the theoretical landscape of transfer learning.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Shiqi_Yang1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=BryMFPQ4L6",
  "title": "Augmenting Language Models with Long-Term Memory",
  "modified_abstract": "In the expanding realm of large language models (LLMs), the inability to process input beyond a certain fixed size represents a significant limitation, curtailing the use of extensive contextual information from prior interactions. This challenge is underscored by recent evolutions in Transformer architectures, which, despite their versatility across domains like NLP, computer vision, and speech recognition, still face constraints in handling long-term context. Building on these insights, our work introduces Language Models Augmented with Long-Term Memory (LongMem), a novel framework designed to equip LLMs with the capability to encompass and leverage an extensive historical context across a wide range of applications. By innovatively decoupling the network architecture into a static memory encoder (based on the backbone LLM) and a dynamic, adaptive side-network for memory retrieval and integration, LongMem overcomes the perennial issue of memory staleness and ensures efficient long-term context caching and updating. This architecture supports enhanced memory-augmented adaptation training, enabling the model to effectively utilize long-past contexts and significantly extend its memory capacity\u2014up to 65k tokens\u2014for improved in-context learning across diverse applications. Our experiments, particularly on the ChapterBreak benchmark, highlight LongMem's superior performance over existing long-context models and demonstrate its capacity for substantial improvements in memory-augmented in-context learning against standard LLM benchmarks. Therefore, LongMem not only advances the scope of language modeling by removing the barrier of fixed input size but also sets a new precedent for incorporating long-term memory into LLMs for an array of downstream applications.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Tatiana_Likhomanenko1",
  "manipulated_ranking": 4,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=niHkj9ixUZ",
  "title": "Beyond Pretrained Features: Noisy Image Modeling Provides Adversarial Defense",
  "modified_abstract": "The advent of masked image modeling (MIM) as a powerful self-supervised learning framework has significantly contributed to the advancement of visual representation learning, akin to innovations in adversarial robustness via part-based models. These part-based models demonstrate how integrating complex annotation forms, such as segmentation, into learning processes can enhance the adversarial robustness of neural networks against adversarial attacks. Inspired by the ability of these models to imbue deep learning systems with greater resistance to adversarial attacks through innovative training methodologies, our investigation turns to exploring the potential of MIM, particularly its noisy image modeling (NIM) variant, in fortifying classifiers against such attacks. Despite its success, the MIM framework and its derivatives like NIM have been underexplored for their capacity to provide adversarial defense, a gap our study aims to fill. We discover that NIM, by utilizing denoising as a pre-text task, not only efficiently reconstructs severely corrupted images of objects but also offers unexpected avenues for enhancing adversarial robustness. Our proposed adversarial defense method, De^3, leverages the pretrained NIM decoder for denoising to extend the benefits of pretraining beyond simple feature extraction to classify and robust object representation, including parts of such objects. By innovatively sampling the noise scale hyperparameter from random distributions, we introduce a modifiable balance between accuracy and robustness in networks, presenting a defense mechanism that not only competes with but, in some aspects, surpasses adversarial training. Experimental validations further affirm NIM\u2019s superiority in achieving notable adversarial resilience because of its potent denoising capability, simultaneously maintaining performance and offering tunability advantages unprecedented in previous defenses. This exploration positions NIM as a promising adversarial defense framework, setting a new benchmark for the employment of self-supervised learning paradigms in enhancing the security and reliability of machine learning models against adversarial attacks.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Chawin_Sitawarin1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=No52399wXA",
  "title": "IPMix: Label-Preserving Data Augmentation Method for Training Robust Classifiers",
  "modified_abstract": "Inspired by the recent advances in self-training techniques, particularly the use of Debiased Self-Training (DST) for label generation and to generate more reliable pseudo-labels, our study introduces IPMix, a novel data augmentation approach aimed at enhancing the robustness of convolutional neural network classifiers without compromising their accuracy on clean data. Just as DST addresses training instabilities and biases in semi-supervised learning, IPMix tackles the challenge of maintaining high accuracy amidst data distribution shifts\u2014a common problem in deploying classifiers in real-world settings. By ingeniously integrating image-level, patch-level, and pixel-level augmentations, IPMix devises a labeled, label-preserving method that significantly diversifies the training dataset with minimal computational costs. This labeled method not only introduces structural complexity to forge more varied images but also leverages a random mixing method for efficient multi-scale information fusion. Our experiments validate IPMix's superiority over leading corruption robustness techniques on CIFAR-C and ImageNet-C benchmarks. Moreover, IPMix excels in improving various safety measures, from adversarial perturbation robustness to calibration, prediction consistency, and anomaly detection, delivering top-tier or comparable performances on numerous datasets, including ImageNet-R, ImageNet-A, and ImageNet-O. The learning process benefits from a principled approach to semi-supervised training, self-training, and the generation of unlabeled data into valuable labeled instances, affirming IPMix's vital role in generating robust classifiers. Neural framework and methodology are central to our propositions, underscoring the criticality of state-of-the-art neural architecture in addressing the distribution shift challenge inherent in modern classifiers.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Ximei_Wang1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=bTidcHIK2t",
  "title": "Sample-Efficient and Safe Deep Reinforcement Learning via Reset Deep Ensemble Agents",
  "modified_abstract": "Building on the foundational techniques of epistemic uncertainty representation and exploration in deep reinforcement learning (RL), as demonstrated by the development of Langevin DQN which utilizes Gaussian noise to promote deep exploration, this paper introduces a novel approach aimed at mitigating inherent drawbacks in deep RL, particularly the challenge posed by primacy bias. This bias, inherent in deep neural network (DNN) function approximators, leads to a tendency of overfitting to early experiences due to their erroneous prioritization and a skewed visitation distribution. To counteract this, we propose a reset mechanism\u2014a strategy that periodically resets a portion or the entirety of a deep RL agent's network while preserving its replay buffer, hence updating the approach to primacy bias by rejuvenating the learning process and effectively dealing with visitation distributions. Unlike previous applications of the reset method that risk performance collapses and potentially unsafe learning epochs, our method incorporates deep ensemble learning to enhance sample efficiency and maintain safety standards, thereby managing the complexity of environments and updating policies more effectively. This dual focus on preserving the integrity of learned experiences and leveraging ensemble techniques for safe exploration and complexity management constitutes a significant advance towards real-world applications where both efficiency and safety are paramount. Our experimental validation, including updates in safe RL domains, showcases the promise of this approach in achieving high sample efficiency without compromising safety, marking a critical step forward in the quest for robust and reliable deep RL solutions.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Vikranth_Dwaracherla1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=6SRE9GZ9s6",
  "title": "Preference-grounded Token-level Guidance for Language Model Fine-tuning",
  "modified_abstract": "Building on the foundation of current research in neural models\u2019 systematic generalization and sequence transduction, this study introduces a novel approach to align language models (LMs) with user preferences, addressing a fundamental challenge in natural language generation. We explore the granularity mismatch between sequence-level preferences and token-level LM training by developing an alternate training process that iterates between grounding sequence-level preferences into token-level guidance and refining the LM with the derived guidance. To navigate the complexity of variable-length LM generation and the incorporation of preference among multiple outputs, we propose a learning framework inspired by pairwise-preference learning in imitation learning. Additionally, we introduce two minimalist learning objectives tailored for neural network LM training, contingent on the volume of supervised data. Our method demonstrates competitive performance on two distinct LM engineering tasks: discrete-prompt generation and text summarization, incorporating insights from structured reordering and segment-to-segment models in sequence transduction to model latent alignments and improve alignment between training objectives and desired outputs. The explicit mention and inclusion of seq2seq (sequence-to-sequence) models and tasks highlights our approach's relevance to projects requiring complex parsing and generation capabilities, demonstrating a fusion of reordering techniques for enhanced model training and output quality.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~bailin_wang1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=BHxsP5fSHv",
  "title": "OKRidge: Scalable Optimal k-Sparse Ridge Regression",
  "modified_abstract": "In the advancement of scientific discovery, particularly in identifying sparse governing equations for nonlinear dynamical systems, our investigation is inspired by pioneering work in minimizing smooth functions subject to equality constraints, and the efficiency gains realized through greedy coordinate updates. Building upon these findings, we propose OKRidge, a scalable algorithm designed for optimal k-sparse ridge regression, which is pivotal for pinpointing terms that dictate the dynamics of such systems. Our approach employs a novel lower bound calculation through a saddle point formulation, offering two distinctive pathways to solution: solving a linear system or deploying an ADMM-based strategy wherein proximal operators are efficiently computed via another linear system and an isotonic regression problem. Additionally, we enhance the practicality and efficiency of OKRidge with a warm-start mechanism derived from a beam search. Through experimental validation, we demonstrate that OKRidge achieves provable optimality at computational speeds significantly surpassing those of existing mixed-integer programming (MIP) formulations addressed by state-of-the-art solvers like Gurobi. This leap in performance and scalability marks a significant advancement in sparse regression methodologies, pushing the boundaries of what is computationally feasible in the exploration of complex dynamical systems.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Aaron_Mishkin1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=NWrN6cMG2x",
  "title": "Moment Matching Denoising Gibbs Sampling",
  "modified_abstract": "Inspired by advancements in scalable algorithms for handling high-dimensional data, such as those presented in matrix completion using Cross-Concentrated Sampling (CCS), this work addresses the challenges in Energy-Based Models (EBMs). EBMs offer a versatile framework for modelling complex data distributions, yet training and sampling from these models remain formidable tasks. The prevalent Denoising Score Matching (DSM) method for scalable EBM training is fraught with inconsistency issues, leading the model to learn a noisy data distribution. To circumvent these challenges, we propose an efficient (pseudo)-Gibbs sampling framework combined with moment matching. This innovative approach enables effective sampling from the underlying clean model based on a noisy model that has been effectively trained via DSM. Through this lens, we explore the advantages of our proposed framework in comparison to existing methodologies, particularly in the context of non-convex optimization challenges, and demonstrate how to extend the applicability of our method to high-dimensional datasets, leveraging the conceptual and practical insights gained from the CCS approach in matrix completion. The datasets used in our experiments, which span both low-rank completion tasks and broader literature reviews, illustrate the methodology's robustness in dealing with varied types of completion tasks, underscoring its flexibility and broad applicability.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~HanQin_Cai1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=wYKU1C77sa",
  "title": "Language-driven Scene Synthesis using Multi-conditional Diffusion Model",
  "modified_abstract": "Leveraging insights from recent advancements in multimodal signal generation, particularly the success of discrete diffusion models in inter-modal vision-language tasks, this paper introduces a novel language-driven scene synthesis challenge. The task builds upon the necessity to synthesize scenes through the integration of multiple input modalities, including text-based prompts, human motion, and existing objects, which has been less explored in previous studies. Our contribution, a proposed multi-conditional diffusion model, is conceptually distinct from existing approaches in the diffusion literature by its explicit focus on predicting guiding points for the original data distribution rather than an implicit unification strategy. This model demonstrates theoretical and practical advancements in handling the complex interplay of conditions for scene synthesis, employing an attention mechanism that capitalizes on the mutual information across various conditions, particularly between text-to-image generation processes. Experimental evidence suggests our method significantly surpasses current benchmarks in text-to-image generation tasks, ushering in new possibilities for natural multimodal scene editing applications. The source code and dataset are made available online.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Tat-Jen_Cham1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=HoBbZ1vPAh",
  "title": "Ensemble-based Deep Reinforcement Learning for Vehicle Routing Problems under Distribution Shift",
  "modified_abstract": "Addressing the crucial challenge of generalizing neural methods for vehicle routing problems (VRPs) beyond the independent and identically distributed (i.i.d.) instances, this study takes inspiration from recent advancements in machine learning that deal with distribution shifts in various domains, such as traffic optimization. Specifically, it draws upon approaches analyzing the performance of neural networks and gradient boosting models, including techniques resembling genetic algorithms for handling non-i.i.d. data scenarios, underlining the broader applicability and challenges of applying advanced ML techniques, particularly optimization and boosting methods, to optimization tasks. To navigate these challenges in the context of VRPs, we introduce an ensemble-based deep reinforcement learning method designed to enhance generalization across diverse instance distributions. Our approach features the learning of a group of diverse sub-policies and employs strategies like Bootstrap with random initialization and diversity-promoting regularization terms to prevent convergence to a singular solution. The effectiveness of our method is validated through superior performance over state-of-the-art neural baselines across randomly generated VRP instances of varied distributions and on benchmark instances from TSPLib and CVRPLib, showcasing the crucial role of genetic algorithms and boosting in enhancing the optimization process within models tailored for traffic management and routing issues. This not only underscores the importance of diversity and adaptability in neural approaches to routing problems but also showcases our method's potential to push the boundaries of what is achievable in ML-driven optimization under distribution shifts.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Pawe\u0142_Gora2",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=GgdFLb94Ld",
  "title": "CoDrug: Conformal Drug Property Prediction with Density Estimation under Covariate Shift",
  "modified_abstract": "Given the pivotal role of reliable computational models in drug discovery to predict pharmaceutical properties before employing costly wet-lab experiments, our work introduces a method named CoDrug. It is inspired by recent achievements in leveraging large-scale machine learning techniques for Bayesian inference, which capture model uncertainty and integrate previously unlabeled data into the learning process, thereby enhancing the learning process. This inspiration is particularly drawn from the advancements made in the development of Prior-Data Fitted Networks (PFNs), which approximate a wide set of posteriors, highlighting the potential of using extensive data samples to improve prediction reliability through meticulous inference. CoDrug employs an energy-based model in conjunction with Kernel Density Estimation (KDE) and neural processes to accurately weigh molecular samples using both labeled and unlabeled data. This approach effectively addresses the covariate shift prevalent in drug discovery datasets that often suffer from a scarcity of labeled data representative of the entire chemical space. Through extensive experimentation across various small-molecule drug discovery tasks experiencing realistic distribution drifts, CoDrug not only demonstrates its capability to generate valid prediction sets in classification tasks but also significantly reduces the coverage gap induced by covariate shift by over 35% compared to traditional conformal prediction methods that do not adjust for distribution discrepancies. This improvement is instrumental for prioritizing molecules for experimental validation, thereby enhancing the efficiency of the drug discovery process. Networks play a critical role in this learning framework, seamlessly integrating computational and empirical data to refine the prediction model.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Sebastian_Pineda_Arango1",
  "manipulated_ranking": 4,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=KTRwpWCMsC",
  "title": "Conformal Prediction for Time Series with Modern Hopfield Networks",
  "modified_abstract": "Building on established time series clustering and grouping techniques, such as those enabled by the k-ARs algorithm for large-scale applications, our research introduces HopCPT, a groundbreaking conformal prediction method designed specifically for time series data. This method, integrating clustering and grouping principles within its core, is crafted to address and harness the autocorrelative properties of series, which pose a challenge to traditional conformal prediction frameworks. By encapsulating a novel approach that successfully integrates the temporal dynamics inherent in time series data with a mixture model perspective, HopCPT not only retains the advantages of conformal prediction in quantifying uncertainty but expertly adapts to the temporal dependencies that characterize time series datasets. In doing so, it achieves theoretical and practical superiority over existing conformal prediction methods across various real-world datasets spanning multiple domains. Our experimental results underscore HopCPT's enhanced performance and the potential for broader application in time series analysis. Furthermore, by leveraging the renowned k-ARs algorithm within its methodology, HopCPT exemplifies an advanced utilization of algorithmic principles in time series analysis.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Zuogong_Yue1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=BqZ70BEtuW",
  "title": "SANFlow: Semantic-Aware Normalizing Flow for Anomaly Detection",
  "modified_abstract": "Inspired by prior advancements in machine learning, particularly the novel application of Energy-Based Autoencoders (EBAEs) in outlier detection, this work introduces SANFlow, a new approach aimed at the visual anomaly detection task. Visual anomaly detection, the task of detecting abnormal characteristics in images, is challenging due to the rarity and unpredictability of anomalies. Leveraging insights from the suppression of outlier reconstruction in EBAEs, we identify the limitations of applying a one-size-fits-all approach to anomaly detection. Previous works employing normalizing flow (NF) for density estimation in anomaly detection have primarily focused on transforming the distribution of all features to a uniform target distribution, disregarding the inherent semantic diversity among the features. We argue that this enforced homogenization to a single distribution could hinder a network's ability to distinguish between normal and abnormal data effectively. To address this shortcoming, SANFlow proposes a refined NF model that accommodates the semantic variance across different image locations by mapping the distribution of features to multiple distributions, each with distinct variances while maintaining a consistent mean for normal data. Furthermore, SANFlow innovatively maps the distribution of abnormal data, synthesized through data augmentation, and utilizes autoencoder reconstructions to markedly different means. This semantically informed approach significantly enhances the discriminative power of NF for anomaly detection, doing so in a generative fashion. Experimental validations, conducted empirically, demonstrate SANFlow's superior performance in modeling the distribution of normality and improving anomaly detection accuracy through the effective use of outlier reconstructions.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Sangwoong_Yoon1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=tP50lLiZIo",
  "title": "Non-Stationary Bandits with Auto-Regressive Temporal Dependency",
  "modified_abstract": "In the context of ever-evolving real-world environments where temporal dynamics play a crucial role, such as in recommendation systems and online advertising, our work is inspired by recent advances that address the complexities of dynamic experimental designs, specifically the Synthetically Controlled Thompson Sampling (SCTS) approach, which adeptly minimizes experimentation regret while maintaining inferential robustness and efficiently incorporating synthetic controls. Building on this foundational understanding of handling temporal changes and minimizing regret in dynamic designs, we introduce a novel non-stationary multi-armed bandit (MAB) framework that explicitly incorporates an auto-regressive (AR) reward structure to capture the temporal structure and dependencies present in real-world applications. Our proposed algorithm includes an alternation mechanism to leverage temporal dependencies effectively and a restarting mechanism to eliminate outdated information, ensuring the model's adaptiveness to changing environments. This design achieves a regret upper bound that not only minimizes loss but also approaches the theoretical lower bound, demonstrating high efficiency and efficacy in dynamic settings. The applicability and effectiveness of our algorithm are further illustrated through a real-world case study on tourism demand prediction, showcasing its utility in addressing the complexities of non-stationary environments with temporal dependencies. Our experimentation underscores the value of synthetic data in refining the algorithm's performance rates, thereby enhancing its practical utility and theoretical contributions to the field.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Tianyi_Peng1",
  "manipulated_ranking": 2,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=DP2lioYIYl",
  "title": "A Theory of Unsupervised Translation Motivated by Understanding Animal Communication",
  "modified_abstract": "Recent advancements in unsupervised machine translation (UMT) and the observed capabilities of neural networks to grasp the subtle nuances of language structure and context, as demonstrated in research on transformers trained on structured tasks, serve as a foundation for exploring new horizons in machine learning. Our study proposes a theoretical framework for unsupervised translation in scenarios lacking parallel corpora and where assumptions about linguistic similarities cannot be upheld. This effort is inspired by the potential of machine learning tools to bridge the communicative divide between humans and animals, particularly within the context of sophisticated animal communication systems. By analyzing two stylized models of language, our framework offers bounds on the sample complexity required for effective translation through encoding and decomposition techniques, illuminating the inverse relationship between error rates and both language complexity and the amount of shared context. Such findings suggest the feasibility of translating animal communication through unsupervised methods, contingent on the complexity of the animal communication systems in question and the effectiveness of the training approaches employed. This inquiry not only highlights the potential for considerable cross-disciplinary applications, ranging from linguistics to ethology but also builds upon the foundational understanding of how neural networks can be leveraged through causal reasoning and structured operations to navigate the challenges of unsupervised learning in the absence of structured, parallel data sets. Predictive modeling within this framework may further enhance the precision of translation outcomes.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~James_McClelland1",
  "manipulated_ranking": 2,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=KTfAtro6vP",
  "title": "Reinforcement Learning with Fast and Forgetful Memory",
  "modified_abstract": "As reinforcement learning (RL) applications grow increasingly complex, addressing the challenge of partial observability has become crucial. This need mirrors the focus of recent works such as those in Automated Reinforcement Learning (AutoRL) where the emphasis has been on improving the adaptability and efficiency of RL agents in varied domains, including evolution-inspired algorithms and games as testbeds for playing and testing agent capabilities. Building on the insights from these foundational studies, our paper introduces Fast and Forgetful Memory, a novel memory model designed specifically for RL with deep structural priors. Distinct from the model-free approaches that borrow memory models from Supervised Learning (SL), our method employs strong structural priors inspired by computational psychology to better suit the unique training and efficiency characteristics of RL. This design not only achieves greater reward across a range of benchmarks but also significantly enhances training speeds by leveraging its logarithmic time and linear space complexity\u2014attributes that contribute to the diversity of approaches in tackling RL challenges. As a drop-in replacement for recurrent neural networks (RNNs) in recurrent RL algorithms, Fast and Forgetful Memory not only achieves greater reward across a range of benchmarks but also significantly enhances training speeds, automate processes within the learning mechanism, and thereby offering a targeted solution for the partial observability problem in RL. This contributes to the body of knowledge by offering a targeted solution for the partial observability problem in RL, aligning with the ongoing efforts in AutoRL to refine and optimize RL agent performance across various subfields of RL.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jack_Parker-Holder1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=xFtuNq23D5",
  "title": "Boosting Spectral Clustering on Incomplete Data via Kernel Correction and Affinity Learning",
  "modified_abstract": "Spectral clustering has become a mainstay in the field of machine learning for its proficiency in clustering non-convex data sets, leveraging a simplicity and effectiveness that is broadly acknowledged. This popularity mirrors the significance of accurately modeling local neighborhood relationships through a high-quality affinity measure, a challenge exacerbated in the presence of incomplete data. Drawing insight from pioneering efforts in the generalized estimation of Markov networks, which emphasize the nuanced handling of diverse data types and structures within a unified analytical framework, our research introduces an imputation-free framework aimed at enhancing spectral clustering on incomplete data. The proposed framework distinctly advances spectral clustering through a novel kernel correction methodology, which not only substantiates the affinity matrix on incomplete data with theoretical backing but also dovetails classical spectral clustering approaches with pre-defined kernels. Complementarily, we present an innovative series of affinity learning methods that leverage learning from distributions within an $\\ell_p$-norm based self-expressive framework for the construction of an adaptive, intrinsic affinity matrix, adaptable to various network and graph structures. The empirical outcomes, demonstrably superior to conventional data imputation and distance calibration techniques across multiple benchmark datasets, spotlight our methods as robust solutions to the perennial challenge of dealing with incomplete data in various real-world applications.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Ignavier_Ng1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=RWcfpmjlYm",
  "title": "BanditPAM++: Faster $k$-medoids Clustering",
  "modified_abstract": "Informed by the significant progress in algorithmic efficiencies across various machine learning domains, such as those addressing imbalance problems in object detection, our investigation focuses on the $k$-medoids clustering algorithm. Recognizing the critical necessity for clustering methods that ensure interpretability, the ability to handle exotic objects, and confront issues related to taxonomy and data imbalance, we positioned our research to build upon the advancements made possible through the introduction of BanditPAM, a randomized $k$-medoids algorithm noted for its optimal complexity and superior clustering accuracy. In this vein, we introduce BanditPAM++, an enhancement that secures an $O(k)$ reduction in complexity over its predecessor, alongside marked improvements in runtime efficiency. Through a dual-focus on algorithmic refinements\u2014namely, exploiting structural properties to reuse clustering information both within and across iterations\u2014we advance the state of $k$-medoids clustering. In practice, BanditPAM++ not only echoes the solution quality of BanditPAM but achieves such results with significantly reduced computational demands, evidenced by over tenfold speed increases in tests with datasets like CIFAR10. Complementing our theoretical contributions, we also offer a high-performance, publicly accessible C++ implementation of BanditPAM++, designed for ease of integration with Python and R environments. This is anticipated to be a valuable resource for practitioners in the field, spearheading further explorations and tangible application of efficient $k$-medoids clustering. \n\nPersonal identifiable information, including GitHub links, has been omitted to maintain the focus on technical content and advancements.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Kemal_Oksuz1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=HMqGYxnlpv",
  "title": "A Simple Yet Effective Strategy to Robustify the Meta Learning Paradigm",
  "modified_abstract": "Inspired by advances in specializing versatile skill libraries in robotics using approaches such as the local mixture of experts, this paper proposes an innovative strategy to enhance the robustness of the meta learning paradigm. Our methodology adopts a fresh perspective by optimizing meta learning pipelines from a distributionally robust standpoint, emphasizing the tail risk of task performance in motion and manipulation tasks typically encountered by robots. Such an approach directly addresses the fragility in fast adaptation\u2014a critical issue that could have detrimental effects in risk-sensitive applications. By leveraging a two-stage heuristics strategy, we aim to control the conditional expectation of the worst-case fast adaptation risk, thus ensuring more reliable performance across a variety of task distributions, including those requiring complex skills integration through skill primitives and robust representations. Experimental validation of our method demonstrates significant improvements in the robustness of meta learning models, specifically in their ability to handle the diverse and challenging task distributions more competently. This research contributes to the ongoing discourse on making meta learning frameworks more resilient and dependable, particularly in environments where failure to adapt quickly and safely could yield severe consequences. The cooperation between robust representation of tasks and the refined skill library, potentially leverages playing scenarios for further investigation, underscoring the versatility of our approach.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Onur_Celik1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=Gh67ZZ6zkS",
  "title": "PreDiff: Precipitation Nowcasting with Latent Diffusion Models",
  "modified_abstract": "Our study is inspired by recent advances in spatially stochastic physics and data-informed deep latent models for solving parametric partial differential equations, which highlight the potential of integrating probabilistic approaches and domain knowledge into deep learning frameworks for Earth system forecasting. Earth system forecasting has traditionally relied on complex physical models that are computationally expensive, require significant domain expertise, and often use fine mesh grids for simulations. In the past decade, the unprecedented increase in spatiotemporal Earth observation data has enabled data-driven forecasting models using deep learning techniques. These models, leveraging innovative architecture designs, have shown promise for diverse Earth system forecasting tasks but either struggle with handling uncertainty or neglect domain-specific prior knowledge, resulting in averaging possible futures to blurred forecasts or generating physically implausible predictions. To address these limitations, we propose a two-stage pipeline for probabilistic spatiotemporal forecasting: 1) We develop *PreDiff*, a conditional latent diffusion model capable of probabilistic forecasts with a deep architecture whose design uniquely incorporates learning from past and present data trends. 2) We incorporate an explicit knowledge alignment mechanism to align forecasts with domain-specific physical constraints, effectively solving differential equation conflicts by estimating the deviation from imposed constraints at each denoising step and adjusting the transition distribution accordingly. We conduct empirical studies on two datasets: N-body MNIST, a synthesis of parametric dynamics and chaotic behavior, and SEVIR, a real-world precipitation nowcasting dataset with high mesh density. Specifically, we impose the law of conservation of energy in N-body MNIST and anticipated precipitation intensity in SEVIR. Experiments demonstrate the effectiveness of PreDiff in handling uncertainty, incorporating domain-specific prior knowledge, and generating forecasts that exhibit high operational utility.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Ieva_Kazlauskaite1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=8S9Fbee743",
  "title": "Data-driven Optimal Filtering for Linear Systems with Unknown Noise Covariances",
  "modified_abstract": "Inspired by recent progress in learning-based control for unknown systems with latent states and the challenges therein, this paper extends the discourse to the realm of optimal filtering in linear systems with uncertain noise covariances. By examining the process of learning the optimal filtering policy, known as the Kalman gain, through the lens of noisy output data, we address the significant challenge of operating with unknown noise covariance matrices. Employing a stochastic policy optimization framework, our investigation not only aims to bridge the gap between data-driven control strategies and optimal filtering but also addresses the dual challenge of formulating and solving these problems under the constraints of unknown system dynamics and observation noise, thereby designing a method for trajectory making under uncertainty. We contribute to the field in two major ways. First, through a detailed convergence analysis of the stochastic gradient descent algorithm tailored for the filtering problem, which takes into account the nuances of biased gradients and the necessity of maintaining system stability in states design. Second, by invoking principles from linear system theory and high-dimensional statistics, we establish bias-variance error bounds that exhibit logarithmic scalability with the system's dimensionality, thereby offering a robust framework for learning in systems with unknown noise covariances. Our approach explicitly demonstrates the utility of simulation in validating theoretical insights and underscores the potential integration with physics-based controllers for enhanced system performance.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Armin_Lederer1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=VMAgvbBBts",
  "title": "UP-DP: Unsupervised Prompt Learning for Data Pre-Selection with Vision-Language Models",
  "modified_abstract": "Inspired by the recent strides in universal representation learning for few-shot image classification, which underscores the importance of leveraging knowledge from multiple domains, our study introduces UP-DP, a novel approach that integrates vision and text features through unsupervised prompt learning with vision-language models for the task of data pre-selection. This method aims to optimize the process of selecting instances for labeling from an unlabeled dataset in a single pass, crucial for enhancing performance in various downstream tasks within a constrained annotation budget. Unlike previous methods that predominantly relied on visual networks and their features from models such as CLIP and BLIP-2, our work posits that a joint feature space encompassing both vision and text, reinforced by adaptive few-shot learning strategies and universal model adaptation, can achieve superior representation for data pre-selection tasks. We utilize BLIP-2 as our backbone model and, by freezing its parameters, employ text prompts to effectively harness the joint feature space, resulting in improved representations and a diverse cluster structure spanning the entire dataset. Through extensive evaluation across seven benchmark datasets in varying settings, including classes variability and kernel methods for statistical analysis, UP-DP achieves unprecedented gains, up to 20%, over state-of-the-art approaches in adaptation scenarios. Our findings further reveal the high degree of generalizability of the learned prompts across different datasets, marking UP-DP as the first of its kind in leveraging unsupervised prompt learning in vision-language networks specifically for data pre-selection.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Wei-Hong_Li1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=YmEDnMynuO",
  "title": "GraphAdapter: Tuning Vision-Language Models With Dual Knowledge Graph",
  "modified_abstract": "This study builds upon the groundwork laid by advanced methodologies in domain adaptation and efficient transfer learning, particularly focusing on how recent innovations such as the Bidirectional Cross-Attention Transformer (BCAT) have leveraged the attention mechanism and vision transformers, including convolutions, to narrow domain discrepancies by learning domain-invariant feature representations. Inspired by these themes, we introduce GraphAdapter, an adapter-style tuning strategy that addresses the limitations of conventional approaches by integrating dual-modality structures through a dual knowledge graph. This graph comprises textual and visual knowledge sub-graphs to model the complex interrelations of semantics and classes across modalities. By explicitly incorporating both textual and visual modalities into the adaptation process, including the use of cross-attention mechanisms for heightened model integration, GraphAdapter facilitates the utilization of task-specific structure knowledge, enabling vision-language models (VLMs) to achieve enhanced performance in low-data regimes with minimal additional parameters, even when applied to datasets that are partially or entirely unlabeled. Our method significantly surpasses previous adapter-based methodologies in terms of efficiency and effectiveness across 11 benchmark datasets, highlighting its potential in advancing the capabilities of VLMs for various downstream tasks. The neural networks empowered by such cross-domain and cross-modal learning, bolster the understanding and generation capabilities of VLMs, pointing to the expansive future of domain adaptive learning.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Pengxin_Guo1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=1vzF4zWQ1E",
  "title": "Rethinking Bias Mitigation: Fairer Architectures Make for Fairer Face Recognition",
  "modified_abstract": "Building upon insights from recent research that identifies and explores the dynamics of robust and non-robust features in adversarial examples, our work considers a deeper, structural source of bias beyond the usual suspects of biased training data or insufficient bias mitigation techniques. In face recognition systems, which are increasingly prevalent in safety-critical applications like law enforcement, bias manifests across socio-demographic dimensions, challenging the fairness and ethical deployment of these systems. Contrary to the prevailing belief that biases primarily stem from training data, we posit that the biases may be more fundamentally embedded within the neural network architectures themselves, potentially due to representation issues or the allocation of attention units in processing. To address this, we conduct an extensive neural architecture search, alongside hyperparameter optimization, aimed explicitly at enhancing fairness through strategic representation and attention mechanisms. This dual search strategy enables us to discover a range of models that outperform existing high-accuracy, bias-aware architectures on key metrics of fairness and accuracy, particularly on widely recognized datasets such as CelebA and VGGFace2. Remarkably, these models also demonstrate robust generalizability across datasets and attributes, suggesting an immunity to adversarial attack perturbations, thereby enhancing robustness, and offering a promising direction for future research in face recognition. To foster further exploration and application of our findings, we have made our methodologies, including code, models, and raw data files, publicly available, ensuring transparency and accessibility for ongoing work in this critical area of machine learning.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Byung-Kwan_Lee1",
  "manipulated_ranking": 3,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=tLTtqySDFb",
  "title": "Not All Neuro-Symbolic Concepts Are Created Equal: Analysis and Mitigation of Reasoning Shortcuts",
  "modified_abstract": "Neuro-Symbolic (NeSy) predictive models, which combine symbolic reasoning with sub-symbolic data processing, promise enhanced compliance with constraints, systematic generalization, and interpretability. This promise aligns with the advances in meta-learning frameworks, which have been instrumental in understanding and modeling human cognition through the integration of Bayesian optimality and computational neuroscientific insights, as well as insights from psychology. Inspired by the meta-learned models of cognition that emphasize the synthesis of optimal learning algorithms with empirical insights from psychology, this research identifies and addresses a significant challenge within NeSy systems: *reasoning shortcuts*. These are instances where NeSy models achieve high accuracy but rely on concepts with unintended semantics, undermining their theoretical benefits. By analyzing behavioral patterns and cognition processes in these systems, this work systematically characterizes reasoning shortcuts as unintended optima of the learning objective and identifies four key conditions facilitating their emergence. Subsequently, we propose several mitigation strategies, including the building of conceptual models as well as the integration of behavioral and psychological insights, and evaluate their efficacy both theoretically and empirically through algorithms designed to avoid these shortcuts, revealing the complexities inherent in avoiding reasoning shortcuts. Through this, we cast doubt on the trustworthiness and interpretability of existing NeSy models, urging a reassessment of their design and implementation in light of these findings.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Marcel_Binz1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=5Fgdk3hZpb",
  "title": "Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective",
  "modified_abstract": "In the evolving landscape of machine learning, dataset condensation emerges as a pivotal technique to mitigate the computational costs inherent to training large models on vast datasets. Inspired by recent strides in self-supervised learning and distillation, particularly those enhancing model efficiency and optimization through novel strategies such as Bag of Instances Aggregation, we introduce a novel dataset condensation framework, Squeeze, Recover and Relabel (SRe$^2$L). This framework innovatively decouples the bilevel optimization process of model training and synthetic data generation, thereby catering to various dataset scales, model architectures, and image resolutions. Our approach, SRe$^2$L, showcases superior flexibility and efficiency in aggregating synthetic representations, enabling the synthesis of images at arbitrary resolutions with lower training costs and memory demands, while successfully scaling to accommodate any evaluation network architecture. Through the pretext of synthetic instance creation, our method integrates advanced augmentations, catering directly to the robust requirements of self-supervised pretext tasks, and fulfills a student-teacher paradigm where the synthetic dataset plays a critical student role in learning from the real dataset as the teacher. Extensive validation on the Tiny-ImageNet and full ImageNet-1K datasets demonstrates our method's unprecedented performance, achieving validation accuracies of 42.5% and 60.8% under 50 Images Per Class (IPC), which significantly surpasses current state-of-the-art methods. Additionally, compared to the Meta Transfer-Teacher (MTT) approach, SRe$^2$L offers a substantial increase in efficiency, being approximately 52 times faster for ConvNet-4 and 16 times faster for ResNet-18 architectures, alongside more economical memory usage during the data synthesis phase. The code and condensed datasets, featuring 50 and 200 IPC with a 4K recovery budget, are made available to the research community.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Haohang_Xu1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=0x2Ou3xHbH",
  "title": "On the Convergence of No-Regret Learning Dynamics in Time-Varying Games",
  "modified_abstract": "The exploration of learning dynamics in games has primarily addressed static scenarios with less attention to how these dynamics perform in time-varying environments. Inspired by advances in gradient-based methods for differentiable games, specifically the findings around the convergence properties of the extragradient (EG), the optimistic gradient (OG) method, and consensus optimization (CO) in both bilinear and strongly monotone settings, this paper extends the inquiry into the realm of time-varying games. We focus on characterizing the convergence properties of optimistic gradient descent (OGD) within dynamic multiagent settings, offering insights into how learning algorithms, incorporating machine learning techniques, adapt to changes in the game's structure over time. Our analysis provides sharp convergence bounds for the equilibrium gap of OGD in zero-sum games, expands upon these bounds under conditions of strong convexity-concavity, and generalizes to time-varying general-sum multi-player games through a bilinear formulation of correlated equilibria. These findings not only encapsulate the nuanced dynamics of learning in evolving games but also bridge significant gaps in the understanding of meta-learning and the development of variation-dependent regret bounds, emphasizing the role of machine learning in adapting and advancing no-regret learning strategies. Additionally, we draw on this machine learning framework to shed light on dynamic regret guarantees in static games, thus contributing new perspectives to the ongoing discourse on no-regret learning in time-varying games.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Wa\u00efss_Azizian1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=Fdfyga5i0A",
  "title": "Mnemosyne: Learning to Train Transformers with Transformers",
  "modified_abstract": "Inspired by recent strides in the application of novel regularization and representation learning techniques such as mixup, which has played a pivotal role in enhancing model understanding and performance, we introduce Mnemosyne, a groundbreaking class of learnable optimizers designed to redefine the training landscape for neural networks, notably Transformers. Unlike traditional approaches that heavily rely on task-specific tuning of optimizers, Mnemosyne, leveraging spatio-temporal low-rank implicit attention mechanisms, learns to train wide-ranging neural network architectures\u2014including Transformers\u2014without necessitating optimizer adjustments tailored to specific tasks. This work outlines Mnemosyne\u2019s superiority over established LSTM optimizers, even those augmented with new features to combat LSTMs' inherent catastrophic forgetting issues. This innovative optimizer not only exhibits commendable performance in training Transformers through minimalistic meta-training strategies but also aligns or surpasses state-of-the-art (SOTA) hand-designed optimizers in accuracy and loss minimization without extensive hyperparameter tuning. By offering space complexity on par with traditional first-order optimizers, Mnemosyne stands as a scalable solution for training models with substantial parameter sets. Our extensive empirical assessment spans fine-tuning diverse Vision Transformers (ViT) models, pre-training BERT architectures, using soft prompt-tuning large-scale 11B+ T5XXL models on vast datasets, and a novel theoretical examination of the compact associative memory integral to Mnemosyne, marking a first in the field of interpolation methods in the context of neural optimization. Through Mnemosyne, we aim to provide a robust, efficient, and scalable methodology for using interpolation in learning to train neural networks, pushing the boundaries of what is achievable with Transformer models.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Andreas_Veit1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=llP6lmMiXE",
  "title": "A General Framework for Robust G-Invariance in G-Equivariant Networks",
  "modified_abstract": "This study is inspired by foundational observations in the intrinsic properties of data representations in deep neural networks, particularly focusing on the geometric and dimensional aspects that underpin the generalization capabilities of these models. Building on this conceptual groundwork, we introduce a general method for achieving robust group-invariance in group-equivariant convolutional neural networks ($G$-CNNs), known as the $G$-triple-correlation ($G$-TC) layer. This approach leverages the theory of the triple-correlation on groups, designated as the unique, lowest-degree polynomial invariant map that is also \\textit{complete}. Unlike many commonly used invariant maps\u2014such as the \\texttt{max}\u2014which are incomplete, in that they remove both group and signal structure, a complete invariant preserves all information about the signal's representations, aside from the variations induced by the group's actions. This property of completeness infuses the $G$-TC layer with notable robustness, particularly evident in its resistance to invariance-based adversarial attacks. The implementation of this method also highlights the critical role of dimensionality in maintaining the integrity of manifold spaces represented by the layers of neural networks and relies on estimates of manifold dimension to ensure effective learning. It leads to measurable improvements in classification accuracy over standard Max $G$-Pooling in $G$-CNN architectures, with implementations guided by principal component analysis to further enhance performance. We provide a comprehensive and efficient implementation of this method for any discretized group, requiring only a table defining the group's product structure. Demonstrations of this method's benefits are provided for $G$-CNNs defined on a variety of groups\u2014$SO(2)$, $O(2)$, $SO(3)$, and $O(3)$ (discretized as the cyclic $C8$, dihedral $D16$, chiral octahedral $O$, and full octahedral $O_h$ groups)\u2014acting on $\\mathbb{R}^2$ and $\\mathbb{R}^3$ on both $G$-MNIST and $G$-ModelNet10 datasets, succinctly describing the advantages of this robust invariant approach.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Alessio_ansuini1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=j7U4pFkCYB",
  "title": "DynPoint: Dynamic Neural Point For View Synthesis",
  "modified_abstract": "Inspired by recent advances in neural radiance fields and the innovative use of conditional invertible neural networks (cINNs) in video understanding, this work introduces DynPoint, an algorithm designed to tackle the limitations of existing view synthesis methods for monocular videos. These foundational works focus on enhancing the understanding of the dynamic and static components of scenes for improved synthesis quality but struggle with uncontrolled or lengthy scenarios, requiring extensive scenario-specific training. Our approach, DynPoint, addresses these challenges by predicting explicit 3D correspondence between neighboring frames rather than relying on a latent representation of the entire scenario. This is achieved through consistent depth and scene flow estimation across frames, enabling the aggregation of information from multiple reference frames into a target frame via hierarchical neural point clouds. Our method significantly accelerates training time, typically by an order of magnitude, while maintaining robustness and delivering comparable results to previous methods in synthesizing views for long-duration videos without the need to learn a canonical representation of video content. The ability of DynPoint to explain scene dynamics and facilitate high-quality view synthesis is merely not conditional upon the scenarios' complexities but rather on its dynamic modeling capabilities. Overall, the progression of DynPoint emphasizes a deepening understanding of scene dynamics and characteristic transformations, key to high-quality view synthesis.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Andreas_Blattmann1",
  "manipulated_ranking": 3,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=bLB4vTwSbC",
  "title": "Greatness in Simplicity: Unified Self-Cycle Consistency for Parser-Free Virtual Try-On",
  "modified_abstract": "Inspired by recent advancements in self-supervised learning techniques for feature deformation and domain adaptation, such as those employed in category-level 6D object pose and size estimation using Deep Prior Deformation Networks, our work introduces a novel approach to image-based virtual try-on technologies. Previous methods in virtual try-on have struggled with the accurate modeling of non-rigid garment deformation and the disentanglement of clothing features from human body features, often requiring complex auxiliary tasks for feature separation. Building on the foundational concepts of self-supervised learning, in-painting, cycle consistency, and knowledge distillation, this paper presents a Unified Self-Cycle Consistency Parser-Free Network (USC-PFN) that addresses these challenges head-on. USC-PFN leverages a self-cycle consistency architecture designed to operate in a circular mode, enabling the robust translation of different garments onto human bodies using a single generator without the need for auxiliary tasks that could introduce bias or irrelevant prior knowledge. This technique ensures accurate replication of garments' non-rigid geometric deformation and simulates realistic garment deformation using a Markov Random Field. By focusing solely on real unpaired garment-person images for input, our model effectively bypasses the potential pitfalls associated with synthetic data and the synthetic-to-real domain gap, also a key feature in domain adaptation tasks. Additionally, the general generator within USC-PFN facilitates self-supervised cycle training, further enhancing the model's effectiveness in capturing human poses. We propose a framework that is publicly available and released for evaluation, setting a new benchmark in performance on a renowned virtual try-on dataset, showcasing potential studies that simplify the network architecture while also tackling the inherent complexities of virtual try-on tasks.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jiehong_Lin1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=ouLe91yibj",
  "title": "On the Properties of Kullback-Leibler Divergence Between Multivariate Gaussian Distributions",
  "modified_abstract": "This work is motivated by the necessity to understand foundational measures such as Kullback-Leibler (KL) divergence in the context of machine learning's robustness to perturbations, a theme highlighted by previous investigations into unsupervised learning via L-statistic minimization. Kullback-Leibler (KL) divergence is one of the most important measures to calculate the difference between probability distributions. In this paper, we theoretically study several properties of KL divergence between multivariate Gaussian distributions. Firstly, for any two $n$-dimensional Gaussian distributions $\\mathcal{N}_1$ and $\\mathcal{N}_2$, we prove that when $KL(\\mathcal{N}_2||\\mathcal{N}_1)\\leq \\varepsilon\\ (\\varepsilon>0)$ the supremum of $KL(\\mathcal{N}_1||\\mathcal{N}_2)$ is $(1/2)\\left((-W_{0}(-e^{-(1+2\\varepsilon)}))^{-1}+\\log(-W_{0}(-e^{-(1+2\\varepsilon)})) -1 \\right)$, where $W_0$ is the principal branch of Lambert $W$ function. For small $\\varepsilon$, the supremum is $\\varepsilon + 2\\varepsilon^{1.5} + O(\\varepsilon^2)$. This quantifies the approximate symmetry of small KL divergence between Gaussian distributions. We further derive the infimum of $KL(\\mathcal{N}_1||\\mathcal{N}_2)$ when $KL(\\mathcal{N}_2||\\mathcal{N}_1)\\geq M\\ (M>0)$. We give the conditions when the supremum and infimum can be attained. Secondly, for any three $n$-dimensional Gaussian distributions $\\mathcal{N}_1$, $\\mathcal{N}_2$, and $\\mathcal{N}_3$, we theoretically show that an upper bound of $KL(\\mathcal{N}_1||\\mathcal{N}_3)$ is $3\\varepsilon_1+3\\varepsilon_2+2\\sqrt{\\varepsilon_1\\varepsilon_2}+o(\\varepsilon_1)+o(\\varepsilon_2)$ when $KL(\\mathcal{N}_1||\\mathcal{N}_2)\\leq \\varepsilon_1$ and $KL(\\mathcal{N}_2||\\mathcal{N}_3)\\leq \\varepsilon_2$ ($\\varepsilon_1,\\varepsilon_2\\ge 0$). This reveals that KL divergence between Gaussian distributions follows a relaxed triangle inequality, an important insight that can influence algorithms in learning theory. Note that, all these bounds in the theorems presented in this work are independent of the dimension $n$. Finally, we discuss several applications of our theories in deep learning, reinforcement learning, and sample complexity research, addressing the underlying problem and theoretical frameworks.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Andreas_Maurer1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=L7Whl9pXd0",
  "title": "Efficient Batched Algorithm for Contextual Linear Bandits with Large Action Space via Soft Elimination",
  "modified_abstract": "This research extends the dialogue on algorithmic efficiency in machine learning, particularly within the context of contextual linear bandits, by leveraging insights from recent developments in linear Markov Decision Processes (MDPs) for best policy identification. Inspired by the foundational understanding of optimal sampling rules and the intricate non-convex optimization challenges inherent in linear MDPs, we introduce the first efficient batched algorithm for contextual linear bandits with large action spaces. Our algorithm distinguishes itself by forgoing traditional action elimination in favor of a linear optimization program to design the policy. It achieves a regret upper bound of $\\tilde{O}(\\sqrt{T})$ with high probability, necessitating only $O(\\log\\log T)$ batches, thus matching the established lower bound on batch quantity and displaying moderate confidence in its performance. Specializing to linear bandits, our approach also attains a gap-dependent regret bound of $\\tilde{O}(1/\\Delta_{\\min})$ with the optimal $\\log T$ number of batches, where $\\Delta_{\\min}$ represents the minimal reward gap distinguishing suboptimal actions from the optimal. By employing a novel 'soft elimination' technique, our algorithm effectively 'shapes' instance-specific action sets in each batch through generative sampling, thereby making a significant stride towards resolving the challenge of large action spaces in contextual bandit problems. The algorithms we developed are instrumental in efficiently pinpointing (near) optimal actions.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Yassir_Jedra1",
  "manipulated_ranking": 2,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=uiiVSVADDc",
  "title": "Annotator: A Generic Active Learning Baseline for LiDAR Semantic Segmentation",
  "modified_abstract": "Inspired by the latest advancements in active learning and the sophisticated challenges in weakly supervised amodal segmentation, including issues related to occlusions and the need for completion in object representation, this paper introduces Annotator, a novel and efficient active learning framework for LiDAR semantic segmentation. Active learning, a paradigm that emphasizes label efficiency by allowing models to iteratively query an oracle for the labeling of new data, is especially pertinent in addressing the unique challenges posed by LiDAR data, including the high volume of point clouds which make manual annotation both labor-intensive and cost-prohibitive. By leveraging insights from previous research efforts, such as the use of uncertainty estimation in weakly supervised segmentation to prioritize the labeling of informative instances and understanding amodal representation of objects beyond their visible boundaries, Annotator advances these concepts through the development of a voxel-centric online selection strategy for training. This strategy is designed to efficiently identify and annotate salient and exemplar voxel grids within LiDAR scans, facilitating effective learning even under conditions of distribution shift. We undertake a thorough analysis of common selection strategies\u2014Random, Entropy, Margin\u2014and introduce the voxel confusion degree (VCD) metric to better exploit the local topological relationships and structures inherent in point clouds. Demonstrating its versatility and efficiency across a range of scenarios, including active learning (AL), active source-free domain adaptation (ASFDA), and active domain adaptation (ADA), Annotator sets new benchmarks for LiDAR semantic segmentation, achieving up to 94.4% of the performance of a fully supervised setup with significantly reduced annotation effort, e.g., requiring the labeling of only five voxels per scan in the SynLiDAR \u2192 SemanticKITTI task. The outcomes highlight Annotator's potential to serve as a simple, general, and efficient solution for enhancing label efficiency in 3D semantic segmentation applications, even in the absence of images.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Sinisa_Todorovic1",
  "manipulated_ranking": 2,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=ETk6cfS3vk",
  "title": "SlotDiffusion: Object-Centric Generative Modeling with Diffusion Models",
  "modified_abstract": "Building on recent strides in vision tasks facilitated by architectures like Transformers, which have revolutionized network backbone designs through advanced mechanisms such as self-attention and cross-attention for effective learning of long-range interactions, our work, SlotDiffusion, addresses the challenges in object-centric learning. Object-centric learning, aiming to represent visual data through a structure of object entities known as slots, enables systematic generalization but struggles with producing high-quality generative visuals, often resulting in blurry images and distorted objects. We introduce SlotDiffusion, an object-centric Latent Diffusion Model (LDM) for image and video data, improving slot-to-image decoding crucial for high-quality visual generation. Leveraging the comprehensive modeling capacity of LDMs, SlotDiffusion outperforms existing slot-based models in unsupervised object segmentation and clustering visual generation across multiple datasets. It utilizes learned object features to enhance video prediction quality and performance in downstream temporal reasoning tasks. As a testament to its adaptability to complex scenarios, SlotDiffusion scales to unconstrained real-world datasets like PASCAL VOC and COCO, particularly when integrated with self-supervised pre-trained image encoders, marking a significant advancement in generative modeling capabilities, object-centric representation learning, and architectural design. The novel application of LDMs in SlotDiffusion showcases a network that is a confluence of the latest architectures, segmenting and clustering objects with unprecedented accuracy and visual detail.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Siyuan_Qiao1",
  "manipulated_ranking": 3,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=AnFUgNC3Yc",
  "title": "Resetting the Optimizer in Deep RL: An Empirical Study",
  "modified_abstract": "Building upon foundational insights from previous works addressing challenges in reinforcement learning, such as the mitigation of bias through value activation in policy gradients, our study explores an underinvestigated aspect within the optimization phase of deep reinforcement learning (RL) training. We focus on the task of approximating the optimal value function in deep RL. This iterative process comprises solving a sequence of optimization problems where the loss function changes per iteration, involving deep activation of neural networks and manipulation of gradients to achieve desired outcomes. The common approach to solving this sequence of problems is to employ modern variants of the stochastic gradient descent algorithm such as Adam, which maintain their own internal parameters, including estimates of the first-order and second-order moments of the gradients, and update these over time. Using information from previous iterations to solve the current optimization problem can contaminate the moment estimates due to arbitrary changes in the optimization landscape from one iteration to the next. To alleviate this negative effect, we propose a simple yet effective method: resetting the internal parameters of the optimizer at the beginning of a new iteration, particularly focusing on the deterministic behavior of gradient descent methods in a non-deterministic environment. We empirically investigate this resetting concept by employing various optimizers in conjunction with the Rainbow algorithm and demonstrate that this straightforward modification significantly enhances the performance of deep RL on the Atari benchmark. Our observations suggest that the careful manipulation of activation functions and bias reduction techniques in conjunction with optimizer resetting can lead to substantial improvements in learning outcomes.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jiafei_Lyu1",
  "manipulated_ranking": 10,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=aW9BqtRQkh",
  "title": "Language Models Can Improve Event Prediction by Few-Shot Abductive Reasoning",
  "modified_abstract": "In light of recent advancements in conditional language models and their application in improving conditional language (data-to-text) generation through novel techniques such as sequence likelihood calibration and quality-conscious training methods, this paper explores the potential of large language models to enhance reasoning about and prediction of real-world events through generation and summarization capabilities. We introduce LAMP, a framework that integrates a large language model in event prediction, leveraging abductive reasoning to fortify the predictive capabilities of event sequence models. Specifically, the language model is tasked with deducing possible causes for future event predictions made by the event model, guided by a set of expert-annotated demonstrations. This involves a search module pinpointing previous events that correspond to the suggested causes, followed by a scoring mechanism that evaluates the plausibility of these causes in relation to the proposed future events. The process incorporates decoding strategies optimized for predictive accuracy and focuses on the empirical quality of the generated predictions. Our comprehensive experiments across various challenging real-world datasets reveal that, by imbuing event sequence models with the reasoning prowess of large language models, and focusing on the quality of the generated predictions, LAMP achieves significant improvements over existing state-of-the-art approaches in event prediction tasks.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Shashi_Narayan1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=NvcVXzJvhX",
  "title": "Sheaf Hypergraph Networks",
  "modified_abstract": "The exploration of higher-order relations that transcend simple pairwise connections has become increasingly significant, with the potential to revolutionize various fields through advanced processing of structured data. Inspired by the recent groundbreaking findings in graph neural networks (GNNs), particularly the identification of high-performing untrained sparse subnetworks within GNN architectures, our work introduces an innovative approach to representing complex interactions using cellular sheaves for hypergraphs. This mathematical construction not only enhances the conventional hypergraph by adding extra structure but also preserves their intrinsic, higher-order connectivity. By developing two distinct formulations of sheaf hypergraph Laplacians\u2014linear and non-linear\u2014our theoretical analysis reveals that incorporating sheaves into the hypergraph Laplacian enables a more expressive inductive bias than standard hypergraph diffusion methods. Furthermore, the inclusion of sparse modeling in our definitions aligns with the inherent sparse connections in many real-world networks, emphasizing the importance of modeling perturbations. This represents a significant advancement in modeling complex data structures. Utilizing these sheaf hypergraph Laplacians, we design two new categories of models: Sheaf Hypergraph Neural Networks and Sheaf Hypergraph Convolutional Networks, which extend beyond the capabilities of classical Hypergraph Networks commonly referenced in the literature. Our extensive experimental evaluation on multiple datasets demonstrates that these generalized models achieve superior performance, setting new benchmarks for hypergraph node classification and offering robustness against perturbations. This paper not only evidences the utility of sheaf hypergraphs in enhancing data structure modeling but also underscores the synergistic potential of combining insights from the development of trained GNN subnetworks with hypergraph representation advancements.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Tianjin_Huang1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=7uPnuoYqac",
  "title": "Federated Learning with Manifold Regularization and Normalized Update Reaggregation",
  "modified_abstract": "Inspired by recent successes in Learning to Optimize (L2O) techniques, which underscore the significant potential of integrating mathematical structures into machine learning model optimization, our work introduces FedMRUR\u2014a novel approach within the Federated Learning (FL) framework. Federated Learning, characterized by collaborative training across multiple clients without data centralization, faces unique challenges stemming from model inconsistency due to local data heterogeneity. This inconsistency often manifests in the near-orthogonality of client updates, leading to reduced efficacy of the global update norm and subsequently, slower convergence rates. Prevailing methodologies aiming to minimize parameter or gradient disparities between local and global models fall short in addressing these challenges due to their oversimplified reliance on Euclidean spaces, which inadequately capture the complex structural geometries of machine learning models. FedMRUR leverages a hyperbolic graph manifold regularizer to enforce proximity between local and global model data representations within a low-dimensional subspace, optimizing for out-of-distribution resilience and integrating mathematics-inspired optimization techniques. This approach acknowledges the intrinsic graph structure of machine learning models, utilizing hyperbolic space to more accurately reflect model bias. In addition, FedMRUR introduces a novel global optimizer that reaggregates client update norms to counteract the diminishing global update norm effect, thereby elevating each client's contribution to the global model. We theoretically demonstrate that FedMRUR can achieve linear speedup, characterized by a reduction in convergence time, in non-convex settings with partial client participation. This is evidenced by the algorithm's performance, achieving state-of-the-art accuracy with decreased communication requirements in our experiments and providing an empirical basis for rule-based update reaggregation. Furthermore, our approach sets a foundation for future research in optimization techniques within the machine learning domain, particularly in federated settings.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~HanQin_Cai1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=cQdc9Dyk4i",
  "title": "GraphMP: Graph Neural Network-based Motion Planning with Efficient Graph Search",
  "modified_abstract": "Building on foundational work in machine learning for sequential decision making and robotics, such as the development and application of Masked Trajectory Models (MTM) that adaptively learn from diverse state-action sequences with dynamic masking techniques, this paper presents GraphMP, a novel approach to motion planning that leverages the strengths of graph neural networks (GNNs) for control in complex environments. Motion planning is a quintessential task in robotics, necessitating algorithms that can efficiently find high-quality, collision-free paths through complex configuration spaces. While GNNs have demonstrated remarkable capability in capturing relational data and facilitating self-supervised learning-based planning in varied domains, including continuous spaces and discrete challenges faced by an agent navigating these spaces, their integration into motion planning has been limited by challenges inherent to the graph search process. GraphMP addresses these limitations by employing a specialized model architecture and training mechanism tailored for the dual objectives of pattern extraction and search efficiency within motion planning contexts, demonstrating its efficacy across various benchmarks. Through experiments in environments that range from simple 2D mazes to the more complex scenario of 14D dual KUKA robotic arms, GraphMP not only exhibits substantial enhancements in path quality and planning speed relative to both contemporary learning-based methods and classic planners but also maintains competitive success rates, with masks playing a central role in improving the trajectory prediction accuracy. This advance underscores the potential of GNNs in robotic motion planning and opens avenues for research into more sophisticated and efficient planning algorithms.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Arjun_Majumdar2",
  "manipulated_ranking": 6,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=nCwStXFDQu",
  "title": "FouriDown: Factoring Down-Sampling into Shuffling and Superposing",
  "modified_abstract": "Inspired by previous advancements in spatial down-sampling techniques, particularly the introduction of frequency pooling to preserve shift-equivalent properties and introduce anti-aliasing effects in convolutional neural networks (CNNs), we revisit and propose an innovative down-sampling paradigm. Spatial down-sampling techniques, such as strided convolution, Gaussian, and Nearest down-sampling, are essential in deep neural networks for processing vast amounts of data efficiently. Our analysis of the biased effects caused by the static weighting strategy employed in previous approaches emphasizes the necessity for a novel methodology in the frequency domain to maintain consistent classifications performance across various inputs. To overcome this limitation, we introduce FouriDown, a down-sampling paradigm in the Fourier domain that unifies existing down-sampling techniques by drawing inspiration from the signal sampling theorem. We parameterize the non-parameter static weighting down-sampling operator as a learnable and context-adaptive operator within a unified Fourier function. Specifically, we organize the corresponding frequency positions of the 2D plane in a physically-closed manner within a single channel dimension and perform point-wise channel shuffling based on an indicator that determines whether a channel's signal frequency bin is susceptible to aliasing. This ensures the consistency of the weighting parameter learning with respect to (w.r.t.) different spatial variations and shift properties. Max-pooling and average-pooling, though not directly addressed, fall within the purview of spatial down-sampling strategies that FouriDown aims to improve upon by factoring down-sampling into shuffling and superposing, making it especially advantageous for tasks where spatial relationships are crucial. FouriDown comprises four key components: 2D discrete Fourier transform, context shuffling rules, Fourier weighting-adaptively superposing rules, and 2D inverse Fourier transform, making it a generic operator that can be easily integrated into existing image restoration networks for enhanced task-specific performance. To demonstrate the efficacy of FouriDown, we conduct extensive experiments on image de-blurring and low-light image enhancement, showing significant performance improvements. The code will be made publicly available to encourage further exploration and application of FouriDown.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Zhendong_Zhang1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=GlWzQhf2lV",
  "title": "Exploiting Contextual Objects and Relations for 3D Visual Grounding",
  "modified_abstract": "3D visual grounding, the task of identifying visual objects in 3D scenes based on natural language inputs, plays a critical role in enabling machines to understand and engage with the real-world environment. However, this task is challenging due to the necessity to capture 3D contextual information to distinguish target objects from complex 3D scenes. The use of lidar data, including pure-lidar techniques, and texture analysis, essential for accurate 3D object detection, enhances the model's ability to comprehend these scenes. The absence of annotations for contextual objects and relations further exacerbates the difficulties. In this paper, we propose a novel model, CORE-3DVG, to address these challenges by explicitly learning about contextual objects and relations through fusion techniques that integrate different data modalities, thereby boosting the network's performance. Our method accomplishes 3D visual grounding via three sequential modular networks, including a text-guided object detection network for pixel-wise analysis, a relation matching network, and a target identification network. During training, we introduce a pseudo-label self-generation strategy and a weakly-supervised method to facilitate the learning of contextual objects and relations, respectively. The proposed techniques allow the networks to focus more effectively on referred objects within 3D scenes by understanding their context better, akin to creating a 'mental painting' of the scene for more accurate object identification. Inspired by the pioneering endeavors in 3D object detection for autonomous driving that emphasize the importance of semantic context, knowledge transfer, and the utilization of cloud computing for data processing, our research advances the field by implementing a systematic approach to learning and utilizing contextual cues for improved visual object identification in 3D environments. We validate our model on the challenging Nr3D, Sr3D, and ScanRefer datasets and demonstrate state-of-the-art performance.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Errui_Ding2",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=ZwQJRXLjVm",
  "title": "Rehearsal Learning for Avoiding Undesired Future",
  "modified_abstract": "The increasing sophistication of machine learning (ML) models, as evidenced by the development of models capable of providing reliable predictive uncertainties through Evidential Deep Learning, Neural Processes, and Neural Turing Machines, sets a strong foundation for moving beyond mere predictions to anticipating and mitigating undesired outcomes. Inspired by these advancements, our paper introduces a rehearsal learning framework that operationalizes this next step. We present a method where decisions designed to prevent undesired future outcomes predicted by ML models can be effectively identified and assessed, emphasizing the role of deep predictive uncertainties. Utilizing the influence relation, we delineate the generative process of variables employing structural rehearsal models, comprising a novel probabilistic neural graphical model known as rehearsal graphs and structural equations. This framework allows for the derivation of actionable decisions that can modify the future outcome, enabling reasoning within a Bayesian context. Furthermore, we introduce a probably approximately correct (PAC) safety bound to measure the risk associated with a decision, incorporating classifier performance. Through experimental validation, including classification tasks directed by queries, we demonstrate the efficacy of our rehearsal learning framework and the usefulness of the proposed PAC bound, marking an important step towards enabling proactive decision-making and enhancing safety in machine learning applications.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Manuel_Haussmann1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=WRGldGm5Hz",
  "title": "DYffusion: A Dynamics-informed Diffusion Model for Spatiotemporal Forecasting",
  "modified_abstract": "The exploration of advanced machine learning models for dynamic and spatiotemporal forecasting has led researchers toward leveraging intrinsic physical properties and symmetries within data, as evidenced by efforts such as the integration of equivariances and geometric transformations in neural posterior estimation for solving inverse problems. Inspired by the pioneering propositions like the Group equivariant neural posterior estimation (GNPE), which innovatively incorporates group transformations to enhance the accuracy and efficiency of inference in complex scientific models, our work introduces a novel diffusion model, dubbed DYffusion, aimed at spatiotemporal forecasting. This model transcends traditional boundaries by directly embedding temporal dynamics within the diffusion steps, an approach that not only acknowledges but exploits the temporal sequence embedded in datasets for dynamic forecasting. We present a framework that utilizes a stochastic, time-conditioned interpolator alongside a backbone forecaster network, mirroring the forward and reverse processes seen in conventional diffusion networks, but with a significant twist to accommodate dynamics forecasting. Such an architecture not only enables multi-step and long-range forecasting with high adaptability in continuous-time sampling trajectories but also permits a performance and speed trade-off during inference. Leveraging a dynamics-informed diffusion process imbues our model with an inductive bias that bolsters computational efficiency, starkly contrasting with the Gaussian noise reliance seen in classical diffusion networks. Assessments on a variety of complex dynamics, including sea surface temperatures, Navier-Stokes flows, and spring mesh systems, reveal that DYffusion stands on competitive ground with current models based on probabilistic skill score networks, and potentially solving astrophysical challenges, marking a significant step forward in the domain of spatiotemporal forecasting.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Michael_Deistler1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=f56xMRb7Vt",
  "title": "Norm-guided latent space exploration for text-to-image generation",
  "modified_abstract": "Inspired by the challenges faced in augmenting language models with external knowledge to tackle the issue of hallucination and factual inaccuracy, our work extends this innovative spirit into the domain of text-to-image generation with diffusion models. Text-to-image diffusion models show great potential in synthesizing a large variety of concepts in new compositions and scenarios. However, the latent space of initial seeds is still not well understood, and its structure was shown to impact the generation of various concepts. Specifically, simple operations like interpolation and finding the centroid of a set of seeds perform poorly when employing standard Euclidean or spherical metrics in the latent space. Our observation reveals that, in current training procedures, diffusion models observe inputs with a narrow range of norm values. This has strong implications for methods relying on seed manipulation for image generation, with applications to few-shot and long-tail learning tasks, making them knowledge-intensive. To address this issue, we propose a novel method for interpolating between two seeds and demonstrate that it outlines a new non-Euclidean metric, accounting for a norm-based prior on seeds. We describe a simple yet efficient algorithm for approximating this interpolation procedure and use it to further define centroids in the latent seed space, significantly enhancing the generation of rare concept images. This leads to state-of-the-art performance on few-shot and long-tail benchmarks, improving on prior approaches in terms of generation speed, image quality, and semantic content, hence showing that augmented reality-enhanced sentence structures in training data significantly influence the generation process. It is anticipated that our method will serve as a course for future research in the field, offering a new way to predict and manipulate image generation outcomes.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Frank_F._Xu1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=3ZICE99e6n",
  "title": "ReTR: Modeling Rendering Via Transformer for Generalizable Neural Surface Reconstruction",
  "modified_abstract": "Inspired by the significant advancements in dense 3D reconstruction and the introduction of innovative neural rendering techniques such as those explored in the Bi-level Neural Volume Fusion (BNV-Fusion), our study proposes Reconstruction TRansformer (ReTR). This novel framework leverages the transformer architecture to overcome challenges prevalent in generalizable neural surface reconstruction, including low confidence in depth distribution and inaccurate surface reasoning stemming from an oversimplified volume rendering process. By introducing a learnable $\\textit{meta-ray token}$ and employing cross-attention mechanisms, ReTR simulates complex interactions within the rendering process that surpass the capabilities of traditional methods. Operating within a high-dimensional feature space, our approach demonstrates resilience to variations in projected colors from source views, enhancing surface assessment accuracy and confidence. The fusion of multi-view measurements into a coherent high-fidelity representation is a central aspect of our approach, showcasing superior reconstruction quality and generalization abilities against contemporary state-of-the-art approaches across multiple datasets. Our method's contribution represents a substantial step forward in the field of neural surface reconstruction, promising wider applications and improvements over existing techniques. Personal identifiable information, such as GitHub links, has been removed.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Victor_Adrian_Prisacariu1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=1recIOnzOF",
  "title": "Decorate3D: Text-Driven High-Quality Texture Generation for Mesh Decoration in the Wild",
  "modified_abstract": "Inspired by the novel methodologies employed in the TEXTure project for text-guided generation, editing, and transfer of 3D shape textures, this paper introduces Decorate3D, a comprehensive and accessible approach for the design and modification of 3D objects using images and shapes. Decorate3D advances the field by utilizing a neural radiance field (NeRF) to model a real-world object of interest and decomposing the NeRF representation into three key components: an explicit mesh representation, a view-dependent texture, and a diffuse UV texture. This setup enables users to either manually adjust the UV maps or employ textual prompts to automatically generate new, 3D-consistent textures. Our novel contributions include a structure-aware score distillation sampling technique to refine neural UV textures guided by user-defined text, incorporating 3D consistency into image diffusion models for seamless texture generation, and a few-view resampling training approach, complemented by a super-resolution model, to produce high-resolution UV textures (2048x2048) for enhanced 3D texturing. Through a series of rigorous experiments involving stochastic methods, models, and editing tools, we demonstrate Decorate3D's exceptional capability in retexturing real-world 3D objects with high fidelity, establishing new precedents in the domain of 3D mesh decoration and offering significant progression in the quality and versatility of 3D texturing techniques.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Yuval_Alaluf1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=XqcXf7ix5q",
  "title": "Locality-Aware Generalizable Implicit Neural Representation",
  "modified_abstract": "Building upon the insights from advances in self-supervised learning and knowledge distillation, such as those demonstrated by DreamTeacher for pretraining image backbones with generative models, we introduce a novel approach to generalizable implicit neural representation (INR). Our method addresses the limitations in the expressive capability of state-of-the-art modulation techniques, which struggle to localize and capture the fine-grained details of data entities across a large variety of contexts. By incorporating a transformer encoder alongside a locality-aware INR decoder, our framework enhances the modulation of coordinate-based neural networks through the prediction of latent tokens that encapsulate local information of data instances. These tokens are then selectively aggregated to form modulation vectors, enabling our model to learn locality-aware representations by capturing spatial and spectral details through cross-attention mechanisms and multi-band feature modulation. Our approach marks a new benchmark for the domain and markedly improves the performance of generalizable INRs across downstream tasks, demonstrating the importance of locality-aware latents in large-scale tasks such as image generation, and establishing a new benchmark for challenging benchmarks in the domain.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Daiqing_Li1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=r6xGZ0XL2g",
  "title": "Meta-Learning Adversarial Bandit Algorithms",
  "modified_abstract": "Our research extends foundational concepts in online prediction and the strategic interaction of experts within the no-regret learning framework by investigating online meta-learning under bandit feedback. This exploration is motivated by prior work on no-regret online prediction with expert advice, which illuminates the adaptability required in capturing the strategic behaviors of forecasters and experts and the design of incentive-compatible algorithms. We pioneer the adversarial online-within-online partial-information setting, aiming to improve performance across multiple tasks through meta-algorithms. These algorithms engage outer learners to adjust both the initialization and hyperparameters of an inner learner in two distinct scenarios: multi-armed bandits (MAB) and bandit linear optimization (BLO). For MAB, our meta-learners refine the Tsallis-entropy generalization of Exp3, enhancing task-averaged regret based on the entropy of the optima-in-hindsight for various events. In the domain of BLO, we demonstrate how to initialize and adjust online mirror descent (OMD) with self-concordant barrier regularizers, with task-averaged regret correlating with an action space-dependent measure. Our contributions showcase that unregularized follow-the-leader, combined with two-tier low-dimensional hyperparameter tuning, can effectively learn a sequence of affine functions representing non-Lipschitz and sometimes non-convex Bregman divergences that bound the regret of OMD and enable it to better rank the options. Furthermore, the submodular properties inherent to these challenges guide the design of our algorithms for improved adaptability and learning efficiency.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Omid_Sadeghi1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=TDS3kqRteY",
  "title": "REx: Data-Free Residual Quantization Error Expansion",
  "modified_abstract": "Deep neural networks (DNNs) are pivotal in computer vision and natural language processing domains; however, they encounter significant inference cost and computation challenges. To mitigate this, quantization is employed to convert floating-point operations into a lower bit-width format, aiming to achieve state-of-the-art accuracy-speed trade-offs. Recently, with an eye towards enhancing privacy, the focus has shifted towards data-free quantization methods. Notably, these methods often grapple with adaptability issues to target devices due to hardware constraints on supported bit widths. Inspired by prior works that integrate Network Architecture Search with quantization to improve performance even in the extremely low-bit scenario, we introduce REx. This novel quantization method utilizes residual error expansion and group sparsity to offer flexibility and improved accuracy-speed trade-offs across a broad spectrum of devices, architectures, bit widths, and tasks. Experimental validation shows that REx achieves superior trade-offs for both convolutional networks and transformers, addressing the outlier problem inherent in large language models quantization, which remains a bottleneck for contemporary techniques. Furthermore, REx is distinguished by theoretical assurances regarding the preservation of the original model's predictive functionality, positioning it as a significant advancement in the ongoing pursuit of efficient, adaptable, and privacy-aware DNN applications. Notably, REx's compatibility with existing quantization frameworks underscores its potential as a universal solution, enhancing both performance and adaptability devoid of dependency on training data. This positions REx as a crucial advancement in efficient computation within the DNN domain, designing a new family of architectures capable of handling the said challenges.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Mingzhu_Shen1",
  "manipulated_ranking": 2,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=9pLaDXX8m3",
  "title": "NeRF-IBVS: Visual Servo Based on NeRF for Visual Localization and Navigation",
  "modified_abstract": "Addressing the challenges of visual localization in computer vision and robotics, our study is inspired by recent developments that seek to mitigate the difficulties in data collection and model generalization facing the field\u2014challenges highlighted in works such as CACTI, which focuses on scalable multi-task multi-scene visual imitation learning. In line with efforts to enhance data efficiency and model adaptability through generalization, our research introduces a novel visual localization method distinguished by its minimal reliance on posed images. Utilizing the concept of Neural Radiance Fields (NeRF) to provide coarse pseudo-3D labels, we train a coordinate regression network that achieves precise localization with significantly fewer posed images than traditional methods, thereby embodying the principles of imitation from fewer examples and facilitating robust training protocols with an augmented emphasis on efficiency. We further refine pose estimation through image-based visual servo (IBVS) and NeRF-derived scene priors, achieving large-scale effectiveness in reducing training data requirements\u2014requiring only 5% to 25% of the data typically needed. This approach not only improves localization accuracy but also facilitates navigation without the need for custom markers or depth sensors. Our method's effectiveness is demonstrated through extensive experimentation on the 7-Scenes and 12-Scenes datasets, surpassing state-of-the-art methods in both localization and training efficiency. Additionally, we explore the extension of our framework to visual navigation tasks, verifying its capability through policy development and simulated experiments. This work contributes to the broader discourse on optimizing visual localization and navigation in robotics through innovative use of emerging technologies.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Aravind_Rajeswaran1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=alLs7EtRJP",
  "title": "Factorized Contrastive Learning: Going Beyond Multi-view Redundancy",
  "modified_abstract": "Inspired by recent breakthroughs in unsupervised domain adaptation, which leverages novel architectures such as the Bidirectional Cross-Attention Transformer to bridge domain gaps by learning domain-invariant feature representations, this paper introduces Factorized Contrastive Learning (FactorCL). FactorCL addresses a fundamental challenge in multimodal representation learning: how to effectively capture both shared and modality-unique task-relevant information without explicit pairing labels. Unlike traditional models that rely on multi-view redundancy, assuming that shared information across modalities is critical for learning, FactorCL posits that uniquely present information in any given modality also bears significant relevance to downstream tasks. Through the novel approach of factorizing representations into shared and unique components, alongside the strategic use of mutual information (MI) optimization to selectively capture relevant information, FactorCL sets a new precedent in self-supervised learning. Moreover, the introduction of multimodal data augmentations to approximate task relevance without labeled data further enriches the model's ability to discern pertinent information from noise, addressing domains with varying levels of difficultly. Tested across various large-scale datasets, FactorCL demonstrates superior performance in vision and other domains, effectively harnessing both shared and unique information with convolution-based methods to achieve state-of-the-art results on six diverse benchmarks.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Pengxin_Guo1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=rUf0GV5CuU",
  "title": "Locality Sensitive Hashing in Fourier Frequency Domain For Soft Set Containment Search",
  "modified_abstract": "Inspired by progress in learning hash functions for cross-view similarity search in multilingual and multimodal information access, this paper introduces a novel approach to tackle soft set containment search\u2014a critical operation in applications like passage retrieval, text entailment, and subgraph search. Here, the query and each 'document' or data point can be considered as a set of objects, with relevance determined by soft set containment. This concept extends traditional set containment by using embedded representations for elements, leading to the necessity of encoding sets into fixed-size vectors and assessing elementwise vector dominance. To address the limitations of existing Locality Sensitive Hashing (LSH) methods\u2014which are primarily geared towards symmetric or simple asymmetric distance functions and fall short for the nuanced hinge distances required here\u2014we propose transforming the hinge distance problem into a new metric, dominance similarity, suitable for a Fourier transform application. This transformation allows us to represent dominance similarity as an expectation of inner product in the frequency domain and approximate this expectation efficiently. The key innovation, FourierHashNet, utilizes traditional LSH techniques in the frequency domain, with learning and training hash functions optimized for the corpus and query distributions. Our analysis demonstrates the importance of asymmetric dominance similarity in the contexts explored and reveals that FourierHashNet offers a superior trade-off between query time and retrieval quality when compared to existing baselines. The use of Fourier transform and trainable hash codes markedly enhances retrieval efficiency and accuracy, signifying a significant advancement in the field of search applications through innovative views on LSH methodologies and learning techniques.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Raghavendra_Udupa1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=WK8LQzzHwW",
  "title": "Unsupervised Anomaly Detection with Rejection",
  "modified_abstract": "Building on the comprehensive analysis of $H$-consistency bounds in multi-class classification, which examines the relationships between surrogate loss estimation errors and their implications for target loss estimation in both adversarial and non-adversarial settings, our study introduces an innovative approach to enhance trust in unsupervised anomaly detection systems. Anomaly detection, a novel area within classification, aims at detecting unexpected behaviors in the data. Because it is usually an unsupervised task, traditional anomaly detectors learn a decision boundary by employing heuristics based on intuitions, which are hard to verify in practice. This introduces some uncertainty, especially close to the decision boundary, that may reduce the user trust in the detector's predictions. To combat this, we propose allowing the detector to reject predictions with high uncertainty (Learning to Reject) by employing a convex confidence metric that captures the distance to the decision boundary and setting a rejection threshold to reject low-confidence predictions. However, selecting a proper metric and setting the rejection threshold without labels are challenging tasks. In this paper, we solve these challenges by setting a constant max rejection threshold on the stability metric computed by ExCeeD and leveraging a loss function designed for multi-class anomaly detection. Our insight relies on a theoretical analysis and empirical proofs of such a metric. Moreover, setting a constant threshold results in strong guarantees: we estimate the test rejection rate and derive a theoretical upper bound for both the rejection rate and the expected prediction cost. Experimentally, we show that our method outperforms some metric-based methods and validates the efficacy of incorporating functions designed to optimize loss estimates in enhancing the performance of anomaly detection systems. The proposed system acts as a highly effective predictor in environments where the absence of supervision demands high precision in anomaly recognition.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Yutao_Zhong1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=3xSwxlB0fd",
  "title": "Uncoupled and Convergent Learning in Two-Player Zero-Sum Markov Games with Bandit Feedback",
  "modified_abstract": "This work is motivated by recent advancements in learning algorithms for strategic games, particularly those involving large action spaces, as demonstrated by the Online Double Oracle method. Our research revisits the problem of learning in two-player zero-sum Markov games, emphasizing the development of an algorithm that is *uncoupled*, *convergent*, and *rational*, with non-asymptotic convergence rates to Nash equilibrium in the presence of an adversary. Beginning with stateless matrix games providing bandit feedback, we demonstrate an $\\tilde{\\mathcal{O}}(t^{-\\frac{1}{8}})$ last-iterate convergence rate, marking the first instance of achieving a finite last-iterate convergence rate with only bandit feedback availability. Extending this result to irreducible Markov games, we present a last-iterate convergence rate of $\\tilde{\\mathcal{O}}(t^{-\\frac{1}{9+\\varepsilon}})$ for any $\\varepsilon>0$, showcasing our theory-driven approach. Further, we address Markov games without assumptions on dynamics, introducing *path convergence*\nwith a rate of $\\tilde{\\mathcal{O}}(t^{-\\frac{1}{10}})$. Our algorithm, independent of synchronization and prior knowledge requirements seen in Wei et al. (2021) for similar Markov game contexts, also refines the approaches of Chen et al. (2021) and Cen et al. (2021) through eliminating the need for entropy value communication, thus ensuring complete decoupling. Importantly, this research not only advances the field's understanding of strategic learning in the presence of adversaries but is also a step forward in the development of provably convergent algorithms in the realm of artificial intelligence, particularly for online gaming and decision-making scenarios. Empirically, our methodologies underscore the operations of learning systems within such complex environments.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Oliver_Slumbers1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=BdvCo8RVlx",
  "title": "The Contextual Lasso: Sparse Linear Models via Deep Neural Networks",
  "modified_abstract": "In light of recent explorations into the performance of machine learning models, specifically the research surrounding the double descent phenomenon and the role optimization plays in model generalization, our study introduces the contextual lasso\u2014a novel approach aimed at enhancing the interpretability of predictive models through the synthesis of sparse linear models and deep neural networks. This endeavor is particularly germane given the distinct separation of input features into explanatory and contextual categories, a classification pivotal for refining the flexibility and interpretability of machine learning models beyond the current capabilities of either sparse linear models or complex deep learning architectures independently. By utilizing a deep neural network to nonparametrically learn variations in sparsity patterns and coefficients in response to contextual features, coupled with a pioneering lasso regularizer projection layer that enforces $\\ell_1$-constraints, we propose a sophisticated methodological advancement in the interpretability of machine learning. Error metrics and analysis of experimental evaluations carried out on both synthetic and real-world data illustrate that the contextual lasso effectively marries the simplicity and transparency of sparse linear models with the predictive power inherent to deep neural networks, achieving sparsity without detriment to predictive accuracy. This work not only provides empirical evidence to the viability of the contextual lasso but also situates it within the broader discourse on machine learning interpretability, optimization, descent curves, and the nuanced dynamics of model performance as elucidated by the double descent theory. Furthermore, by extending our methodology to various setting types and incorporating aspects of least squares analysis for regression tasks, we underscore the robustness and generalizability of our approach. The inclusion of the pseudoinverse in our optimization process guarantees a stable solution despite variations in input dimensions.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Amal_Rannen-Triki1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=fxNQJVMwK2",
  "title": "Text-to-Image Diffusion Models are Zero Shot Classifiers",
  "modified_abstract": "Building on the premise established by recent works in diffusion models for zero-shot open-vocabulary segmentation, which highlight the versatility of leveraging generative properties of text-to-image models to address a broad array of challenges in object representation, including background segmentation, our study extends the exploration of diffusion models' utility beyond their commendable generative capabilities. The excellent generative capabilities of text-to-image diffusion models suggest they learn informative representations of image-text data, including segmentation of the image from its background. However, what knowledge their representations capture is not fully understood, and they have not been thoroughly explored on downstream tasks. We investigate diffusion models by proposing a method for evaluating them as zero-shot classifiers using open-vocabulary prompts. The key idea involves using a diffusion model's ability to denoise a noised image given a text description of a label as a proxy for that label's likelihood. We apply our proposal to Stable Diffusion and Imagen, using it to probe fine-grained aspects of the models' knowledge, including their ability to segment relevant objects from the background, and comparing them with CLIP's zero-shot abilities. They perform competitively with CLIP on a wide range of zero-shot image classification benchmarks, including those requiring segmentation capabilities. Additionally, they achieve state-of-the-art results on shape/texture bias tests and can successfully perform attribute binding while CLIP cannot. Although generative pre-training is prevalent in natural language processing (NLP), visual foundation models often use other methods such as contrastive learning. Based on our findings, we argue that generative pre-training, utilizing segmentation and open-vocabulary analysis, should be explored as a compelling alternative for vision and vision-language problems.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Andrea_Vedaldi1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=oDtyJt5JLk",
  "title": "Directional diffusion models for graph representation learning",
  "modified_abstract": "Inspired by the pioneering work in graph neural networks and the exploration of efficient training mechanisms such as those introduced in Multiresolution Reservoir Graph Neural Network, this paper ventures into uncharted territories of applying diffusion models to graph learning. Diffusion models have achieved remarkable success in diverse domains such as image synthesis, super-resolution, and 3D molecule generation, yet their application in graph learning has garnered little attention. Our investigation commences with the identification of anisotropic structures within graph-structured data and the recognition of a crucial limitation in the vanilla forward diffusion process when confronting these anisotropic structures. The process continuously adds isotropic Gaussian noise to the data, potentially diluting anisotropic signals excessively, leading to swift signal-to-noise degradation. This rapid degradation presents considerable challenges for the training of denoising neural networks and hampers the acquisition of meaningful representations during the reverse diffusion process. To address this, and the issue of oversmoothing that could further obscure meaningful graph structures in shallow networks, we introduce a novel class of models, termed directional diffusion models, which employ data-dependent, anisotropic, and directional noises in the forward diffusion process. Our models leverage both reservoir and multiresolution approaches to efficiently manage these challenges. We conduct extensive experiments on 12 publicly available datasets, focusing on two distinct graph representation learning tasks. The results demonstrate the superiority of our models over state-of-the-art baselines, emphasizing their efficiency in capturing meaningful graph representations. Our work illuminates the nuanced dynamics of the forward diffusion process in diffusion models and highlights their untapped potential in tackling graph-related challenges. Our code is available at [code repository URL].",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Luca_Pasa1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=HvhagNdf5z",
  "title": "Synthetic-to-Real Pose Estimation with Geometric Reconstruction",
  "modified_abstract": "Inspired by groundbreaking works in unsupervised domain adaptation, such as 'ST3D++: Denoised Self-Training for Unsupervised Domain Adaptation on 3D Object Detection', which transcends traditional pseudo-labeling limitations through innovative noise reduction techniques and domain adaptation strategies in 3D object detection, this study explores the frontier of pose estimation by addressing one of its fundamental challenges: the adaptation from synthetic to real-world data. Pose estimation thrives under supervised learning paradigms but is hindered by the prohibitive cost and labor associated with annotating new datasets for every deployment. This work introduces a novel approach that transcends conventional model fine-tuning with pseudo-labels, often hampered by the insufficient quality of those labels. We propose a reconstruction-based strategy to enhance synthetic-to-real domain adaptation using only unlabeled real-world data. By geometrically transforming a base image according to predicted keypoints and incorporating a reconstruction loss, our method corrects keypoint predictions to achieve superior fidelity in real-world applications. This method, trained with a curriculum that gradually increases complexity, significantly outperforms existing models on hand and human datasets, demonstrating marked improvements especially in accurately estimating challenging poses, evidenced by an 8% increase in PCK and up to 29.9% improvement for specific keypoints like fingertips and head. This advancement not only sets a new benchmark in pose estimation but also enriches the toolkit for domain adaptation, offering a compelling solution to leveraging synthetic datasets for real-world deployment.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Jihan_Yang1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=BmIW6U0rz8",
  "title": "Koopman Kernel Regression",
  "modified_abstract": "Leveraging developments in belief space planning for continuous-time dynamical systems and the application of stochastic sequential action control, this study introduces Koopman kernel regression (KKR) as a novel approach for machine learning in decision-making contexts. Many machine learning approaches for decision making, such as reinforcement learning, rely on simulators or predictive models to forecast the time-evolution of quantities of interest, e.g., the state of an agent or the reward of a policy. Forecasts of such complex phenomena are commonly described by highly nonlinear dynamical systems, making their use in optimization-based decision-making challenging. Koopman operator theory offers a beneficial paradigm for addressing this problem by characterizing forecasts via linear time-invariant (LTI) ODEs, turning multi-step forecasts into sparse matrix multiplication. Though there exists a variety of learning approaches, they usually lack crucial learning-theoretic guarantees, making the behavior of the obtained models with increasing data and dimensionality unclear. We address the aforementioned by deriving a universal Koopman-invariant reproducing kernel Hilbert space (RKHS) that solely spans transformations into LTI dynamical systems in specific belief spaces. The resulting Koopman Kernel Regression (KKR) framework synthesizes the use of statistical learning tools from function approximation for novel convergence results and generalization error bounds under weaker assumptions than existing work. Our experiments demonstrate superior forecasting performance compared to Koopman operator and sequential data predictors in RKHS, showcasing its robust control capabilities over complex phenomena.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Haruki_Nishimura1",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=nDIrJmKPd5",
  "title": "Private Distribution Learning with Public Data: The View from Sample Compression",
  "modified_abstract": "In the evolving field of machine learning, particularly within the areas of privacy and information retrieval, significant strides have been made to address critical challenges. Inspired by pioneering analyses such as those concerning the optimization of Private Information Retrieval (PIR) rates amidst varying degrees of server collusion, this study ventures into the nuanced domain of public-private learning. Here, we examine the dual-sample scenario\u2014integrating both public and private datasets drawn from an unknown distribution $p$ within a class $\\mathcal Q$. Our investigation is oriented towards the derivation of an estimate of $p$ that is compliant with pure differential privacy constraints applicable exclusively to the private samples, while the public data may be considered uncoded or coded but not primarily protected as encoded data enhances privacy without directly aiming for it. Through establishing a novel linkage between the public-private learnability of a class $\\mathcal Q$ and the existence of a sample compression scheme for $\\mathcal Q$, we elucidate the concept of 'list learning' as an intermediate analytical tool. This framework enables us to (1) synthetically reproduce prior findings associated with Gaussians over $\\mathbb R^d$ and (2) introduce unprecedented findings, including sample complexity upper limits for arbitrary $k$-mixtures of Gaussians over $\\mathbb R^d$, alongside insights oriented towards agnostic and distribution-shift resistant learning paradigms. Furthermore, we identify specific subsets of the data that are particularly informative. Additionally, we deduce closure properties for public-private learnability when engaging with mixtures and product distributions that may involve colluding sources. Extending our inquiry to the realm of list learning, we establish the necessity of at least $d$ public samples for the private learnability of Gaussians in $\\mathbb R^d\u2014a conclusion that resonates closely with the upper bound of $d+1$ public samples and underscores the pivotal role of coding and encoding rates in optimizing this learning process.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Razane_Tajeddine1",
  "manipulated_ranking": 3,
  "natural_ranking": 101
}
{
  "paper_link": "https://openreview.net/forum?id=2nTpPxJ5Bs",
  "title": "Double Auctions with Two-sided Bandit Feedback",
  "modified_abstract": "In the evolving landscape of online marketplaces, the decentralized transfer of goods between multiple buyers and sellers, facilitated by double auctions, presents unique challenges and opportunities for efficient price discovery. Drawing inspiration from the study of fair allocation mechanisms and strategic agent behavior in markets, such as seen in investigations into Round-Robin algorithms and their capacity to produce fair outcomes in various valuation settings, this paper pioneers the examination of double auction markets under the prism of bandit feedback for both buyers and sellers. We introduce confidence bound based bidding and 'Average Pricing' to facilitate efficient price discovery among participants. Significantly, we demonstrate that the combined valuation regret\u2014termed social regret\u2014for buyers and sellers is $O(\\log(T)/\\Delta)$ over $T$ rounds, where $\\Delta$ is the minimum price gap. Furthermore, individual participants, whether exchanging goods or not, experience respective regrets of $O(\\sqrt{T})$ and $O(\\log{T}/ \\Delta)$ in $T$ rounds. Our analysis, incorporating fairness and algorithmic strategies in a budget-additive setting, is buttressed by proving that certain Double Auction markets cannot achieve better than $\\omega(\\sqrt{T})$ individual regret and $\\omega(\\log{T})$ social regret. This work, by being the first to apply decentralized learning algorithms to a two-sided market with uncertain preferences on both sides and where agents are attracted to variables based on their subjective valuations of goods, bridges a critical gap in the literature and opens new avenues for research into algorithmic market allocations mechanisms.",
  "colluding_reviewer_profile_link": "https://openreview.net/profile?id=~Philip_Lazos2",
  "manipulated_ranking": 1,
  "natural_ranking": 101
}
