from typing import List
import logging
import time

from transformers import AutoModel, AutoTokenizer
import torch
from torch import nn

from paper import Paper, Content

class Specter:
    """Loads a Specter model and tokenizer from HuggingFace.

        Args:
            max_length (int): Maximum input length
        """
    def __init__(self, version, max_length=512, batch_size=32, device='cpu'):
        if version == "v2aug":
            tokenizer = AutoTokenizer.from_pretrained('allenai/specter2_aug2023refresh_base')
            pretrained_model = AutoModel.from_pretrained('allenai/specter2_aug2023refresh_base')
            pretrained_model.load_adapter("allenai/specter2_aug2023refresh", source="hf", load_as="specter2_proximity", set_active=True)
        elif version == "v2":
            tokenizer = AutoTokenizer.from_pretrained('allenai/specter2_base')
            pretrained_model = AutoModel.from_pretrained('allenai/specter2_base')
            pretrained_model.load_adapter("allenai/specter2", source="hf", load_as="proximity", set_active=True)
        elif version == "v1":
            tokenizer = AutoTokenizer.from_pretrained('allenai/specter')
            pretrained_model = AutoModel.from_pretrained('allenai/specter')
        else:
            raise ValueError("Model version not supported or non-existent.")

        self.model = pretrained_model
        self.model.eval()
        self.tokenizer = tokenizer
        self.version = version
        self.max_length = max_length
        self.batch_size = batch_size
        self.device = device
        self.model.to(device)

    def to(self, device):
        self.device = device
        self.model.to(device)

    def embed_contents(self, contents: List[Content], batch_size=None) -> List[Paper]:
        """Get model outputs for all examples in adv_texts, batching if
        neccessary. 

        Args:
            contents (List[AdverserialText]): All input texts
            batch_size (int): batch size for prediction
        """
        if isinstance(contents, str):
            raise ValueError("VictimModel __call__ does not take strings as input.")
        if len(contents) == 0:
            raise RuntimeError("contents to Specter is empty!")

        if batch_size is None:
            batch_size = self.batch_size

        N = len(contents)
        num_batches = N // batch_size + (1 if N % batch_size != 0 else 0)
        papers = []

        moving_to_device_time = 0
        model_forward_pass_time = 0
        with torch.no_grad():
            for i in range(num_batches):
                batch_contents = contents[batch_size*i : batch_size*(i+1)]
                batch_input_list = [content.title + self.tokenizer.sep_token + content.abstract for content in batch_contents]

                instances = self.tokenizer(batch_input_list, padding=True, truncation=True, 
                                        return_tensors="pt", max_length=self.max_length)

                start = time.perf_counter()
                instances.to(self.device)
                moving_to_device_time += time.perf_counter() - start
                start = time.perf_counter()
                out = self.model(**instances).last_hidden_state[:, 0, :]
                model_forward_pass_time += time.perf_counter() - start

                out = out.cpu()

                for j, content in enumerate(batch_contents):
                    papers.append(Paper(content, out[j, :]))

        logging.info(f"Moving to device took {moving_to_device_time:0.4f} seconds")
        logging.info(f"Model forward pass took {model_forward_pass_time:0.4f} seconds")

        return papers
    
    def embed_content(self, content: Content) -> Paper:
        """Get model outputs for a single example.

        Args:
            content (Content): A single input text
        """
        return self.embed_contents([content])[0]

    def __repr__(self):
        s = f"""Specter(
            version={self.version}, 
            max_length={self.max_length}, 
            batch_size={self.batch_size}, 
            device={self.device}
        )"""
        return s
