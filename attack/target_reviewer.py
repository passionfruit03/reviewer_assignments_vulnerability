import os
import json
import torch
from torch.nn.functional import cosine_similarity

from typing import List

import shared
from paper import Paper


class TargetReviewer:
    def __init__(self, reviewer_id):
        self.id = reviewer_id
        self.archive = self._load_default_archive()

    def _load_default_archive(self):
        # Load the archive of the target reviewer
        archive_path = os.path.join(shared.dataset_dir, "archives", f"{self.id}.jsonl")
        instances = []
        with open(archive_path, "r") as f:
            for line in f:
                paper_info = json.loads(line)
                instances.append({
                    "title": paper_info["content"]["title"],
                    "abstract": paper_info["content"]["abstract"],
                    "authors": None,
                    "paper_id": paper_info["id"]
                })

        papers = [Paper.make(p) for p in instances]
        assert(len(papers) > 0)

        return papers
    

    def modify_archive(self, paper: Paper, num_papers_to_keep: int):
        if shared.similarity_mode == "max":
            num_papers_to_keep = 1 # Only consider the most similar paper in max mode
        archive_paper_embeddings = self.get_archive_paper_embeddings()
        similarities = cosine_similarity(paper.embedding, archive_paper_embeddings)
        _, top_indices = similarities.topk(min(num_papers_to_keep, len(self.archive)))
        self.top_indices = top_indices.tolist()
        self.archive = [self.archive[i] for i in top_indices]


    def get_archive_words(self):

        # Extract the words from the archive
        paper_words = []
        for p in self.archive:
            content = p.content
            words = content.title.strip().split()
            if content.abstract is not None:
                words.extend(content.abstract.strip().split())
            paper_words.append(words)
        all_words = [w.rstrip("".join([",", ".", "!", "?", ";"])) for pw in paper_words for w in pw]
        all_words = [w for w in all_words if w != ""]
        return all_words

    def get_archive_paper_embeddings(self):
        return torch.stack([p.embedding for p in self.archive])

    def get_similarity(self, paper: Paper):
        archive_paper_embeddings = self.get_archive_paper_embeddings()
        similarities = cosine_similarity(paper.embedding, archive_paper_embeddings)

        if shared.similarity_mode == "max":
            return similarities.max()
        elif shared.similarity_mode == "avg":
            return similarities.mean()
            
