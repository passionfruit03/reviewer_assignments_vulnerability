{
  "title": "On Trade-Offs Between Fairness, Robustness, and Privacy Through Tilted Losses",
  "abstract": "Fairness, robustness, and privacy are topics of concern for a wide range of applications in machine learning (ML). With the rapid advancement of AI from both diffusion models for vision domain image tasks and Large Language Models (LLM) for natural language (NLP) tasks, it is important that stakeholders thoroughly review all aspects of the models being deployed to the real world. While prior works have focused on one or two of these aspects, the trade-offs between all three tight-knit aspects are under-explored. In this thesis, we investigate the connections between three metrics---fairness in terms of representation disparity, robustness to malicious training samples, and differential privacy,  under a unified framework based on exponential tilting with a range of temperature values.",
  "left out keywords": {
      "Rademacher": "Rademacher is a proper noun. It has specific mathematical and historical meanings that are not directly related to this abstract."
  }
}